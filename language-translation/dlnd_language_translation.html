<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="#Language-Translation">&#182;</a></h1><p>In this project, youre going to take a peek into the realm of neural network machine translation.  Youll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of sentences: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in a sentence: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;English sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;French sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 227
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l&#39; automne , et il est neigeux en avril .
les tats-unis est gnralement froid en juillet , et il gle habituellement en novembre .
california est gnralement calme en mars , et il est gnralement chaud en juin .
les tats-unis est parfois lgre en juin , et il fait froid en septembre .
votre moins aim fruit est le raisin , mais mon moins aim est la pomme .
son fruit prfr est l&#39;orange , mais mon prfr est le raisin .
paris est relaxant en dcembre , mais il est gnralement froid en juillet .
new jersey est occup au printemps , et il est jamais chaude en mars .
notre fruit est moins aim le citron , mais mon moins aim est le raisin .
les tats-unis est parfois occup en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="#Implement-Preprocessing-Function">&#182;</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="#Text-to-Word-Ids">&#182;</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">eos</span> <span class="o">=</span> <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
    <span class="n">source</span> <span class="o">=</span> <span class="p">[[</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)]</span>
    <span class="n">target</span> <span class="o">=</span> <span class="p">[[</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span> <span class="o">+</span> <span class="p">[</span><span class="n">eos</span><span class="p">]</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">source</span><span class="p">,</span> <span class="n">target</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers.core</span> <span class="k">import</span> <span class="n">Dense</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.1&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.1 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.1.0
Default GPU Device: /gpu:0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoder_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
<li>Target sequence length placeholder named "target_sequence_length" with rank 1</li>
<li>Max target sequence length tensor named "max_target_len" getting its value from applying tf.reduce_max on the target_sequence_length placeholder. Rank 0.</li>
<li>Source sequence length placeholder named "source_sequence_length" with rank 1</li>
</ul>
<p>Return the placeholders in the following the tuple (input, targets, learning rate, keep probability, target sequence length, max target sequence length, source sequence length)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,</span>
<span class="sd">    max target sequence length, source sequence length)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;target_sequence_length&#39;</span><span class="p">)</span>
    <span class="n">max_target_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;max_target_len&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;source_sequence_length&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
            <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoder-Input">Process Decoder Input<a class="anchor-link" href="#Process-Decoder-Input">&#182;</a></h3><p>Implement <code>process_decoder_input</code> by removing the last word id from each batch in <code>target_data</code> and concat the GO ID to the begining of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess target data for encoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">go</span> <span class="o">=</span> <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">]</span>
    <span class="n">ending</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strided_slice</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">go</span><span class="p">),</span> <span class="n">ending</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_encoding_input</span><span class="p">(</span><span class="n">process_decoder_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer:</p>
<ul>
<li>Embed the encoder input using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence"><code>tf.contrib.layers.embed_sequence</code></a></li>
<li>Construct a <a href="https://github.com/tensorflow/tensorflow/blob/6947f65a374ebf29e74bb71e36fd82760056d82c/tensorflow/docs_src/tutorials/recurrent.md#stacking-multiple-lstms">stacked</a> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"><code>tf.contrib.rnn.LSTMCell</code></a> wrapped in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"><code>tf.contrib.rnn.DropoutWrapper</code></a></li>
<li>Pass cell and embedded input to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">imp</span> <span class="k">import</span> <span class="n">reload</span>
<span class="n">reload</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">encoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param source_sequence_length: a list of the lengths of each sequence in the batch</span>
<span class="sd">    :param source_vocab_size: vocabulary size of source data</span>
<span class="sd">    :param encoding_embedding_size: embedding size of source data</span>
<span class="sd">    :return: tuple (RNN output, RNN state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Encoder embedding</span>
    <span class="n">encoder_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">encoding_embedding_size</span><span class="p">)</span>

    <span class="c1"># RNN cell</span>
    <span class="k">def</span> <span class="nf">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">):</span>
        <span class="n">encoder_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span>
                                           <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">encoder_cell</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>

    <span class="n">encoder_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span> <span class="n">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    
    <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">encoder_cell</span><span class="p">,</span> <span class="n">encoder_embed_input</span><span class="p">,</span> 
                                              <span class="n">sequence_length</span><span class="o">=</span><span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">encoder_output</span><span class="p">,</span> <span class="n">encoder_state</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Create a training decoding layer:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper"><code>tf.contrib.seq2seq.TrainingHelper</code></a> </li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                         <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_summary_length</span><span class="p">,</span> 
                         <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_summary_length: The length of the longest sequence in the batch</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing training logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
    <span class="n">helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span><span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">)</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">drop</span><span class="p">,</span> <span class="n">helper</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">)</span>
    <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> 
                                                                   <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                                   <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_summary_length</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">training_decoder_output</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Create inference decoder:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper"><code>tf.contrib.seq2seq.GreedyEmbeddingHelper</code></a></li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                         <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                         <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param start_of_sequence_id: GO ID</span>
<span class="sd">    :param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param vocab_size: Size of decoder/target vocabulary</span>
<span class="sd">    :param decoding_scope: TenorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param batch_size: Batch size</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing inference logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
    <span class="n">start_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">start_of_sequence_id</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;start_tokens&#39;</span><span class="p">)</span>
    <span class="n">infer_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_tokens</span><span class="p">,</span> <span class="n">end_of_sequence_id</span><span class="p">)</span>
    <span class="c1"># Basic decoder</span>
    <span class="n">infer_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">drop</span><span class="p">,</span> <span class="n">infer_helper</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">)</span>
    <span class="n">infer_decoder_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">infer_decoder</span><span class="p">,</span>
                                                            <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                            <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">infer_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="#Build-the-Decoding-Layer">&#182;</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Embed the target sequences</li>
<li>Construct the decoder LSTM cell (just like you constructed the encoder cell above)</li>
<li>Create an output layer to map the outputs of the decoder to the elements of our vocabulary</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, max_target_sequence_length, vocab_size, output_layer, batch_size, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_input: Decoder input</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param target_vocab_size: Size of target vocabulary</span>
<span class="sd">    :param batch_size: The size of the batch</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1. Decoder Embedding</span>
    <span class="n">dec_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">]))</span>
    <span class="n">dec_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>
    
    <span class="c1"># 2. Construct the decoder cell</span>
    <span class="k">def</span> <span class="nf">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">):</span>
        <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span>
                                           <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>

    <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    
    <span class="c1"># 3. Dense layer to translate the decoder&#39;s output at each time </span>
    <span class="c1"># step into a choice from the target vocabulary</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span>
                         <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    
    <span class="c1"># 4. Set up a training decoder and an inference decoder</span>
    <span class="c1"># Training Decoder</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">):</span>
        <span class="n">training_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                                                       <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                        <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="c1"># 5. Inference Decoder</span>
    <span class="c1"># Reuses the same parameters trained by the training process</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> 
                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">],</span> 
                             <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>


    <span class="k">return</span> <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Apply embedding to the input data for the encoder.</li>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob,  source_sequence_length, source_vocab_size, encoding_embedding_size)</code>.</li>
<li>Process target data using your <code>process_decoder_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Apply embedding to the target data for the decoder.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)</code> function.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                  <span class="n">max_target_sentence_length</span><span class="p">,</span>
                  <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span>
                  <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param source_sequence_length: Sequence Lengths of source sequences in the batch</span>
<span class="sd">    :param target_sequence_length: Sequence Lengths of target sequences in the batch</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Pass the input data through the encoder. ignore the encoder output, but use the state</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">enc_state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> 
                                  <span class="n">rnn_size</span><span class="p">,</span> 
                                  <span class="n">num_layers</span><span class="p">,</span> 
                                  <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">source_sequence_length</span><span class="p">,</span>
                                  <span class="n">source_vocab_size</span> <span class="o">=</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                                  <span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="n">enc_embedding_size</span><span class="p">,</span>
                                  <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="c1"># Prepare the target sequences we&#39;ll feed to the decoder in training mode</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="c1"># Pass encoder state and decoder inputs to the decoders</span>
    <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> 
                                                                       <span class="n">enc_state</span><span class="p">,</span>
                                                                       <span class="n">target_sequence_length</span><span class="p">,</span>
                                                                       <span class="n">max_target_sentence_length</span><span class="p">,</span>
                                                                       <span class="n">rnn_size</span><span class="p">,</span> 
                                                                       <span class="n">num_layers</span><span class="p">,</span> 
                                                                       <span class="n">target_vocab_to_int</span><span class="p">,</span>
                                                                       <span class="n">target_vocab_size</span><span class="p">,</span>
                                                                       <span class="n">batch_size</span><span class="p">,</span>
                                                                       <span class="n">keep_prob</span><span class="p">,</span>
                                                                       <span class="n">dec_embedding_size</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
<li>Set <code>display_step</code> to state how many steps between each debug output statement</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">60</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">15</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_target_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>

    <span class="c1">#sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name=&#39;sequence_length&#39;)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                                   <span class="n">targets</span><span class="p">,</span>
                                                   <span class="n">keep_prob</span><span class="p">,</span>
                                                   <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">source_sequence_length</span><span class="p">,</span>
                                                   <span class="n">target_sequence_length</span><span class="p">,</span>
                                                   <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
                                                   <span class="n">encoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">decoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">rnn_size</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">target_vocab_to_int</span><span class="p">)</span>


    <span class="n">training_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">train_logits</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="o">.</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>

    <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;masks&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">training_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch and pad the source and target sequences</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">pad_sentence_batch</span><span class="p">(</span><span class="n">sentence_batch</span><span class="p">,</span> <span class="n">pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pad sentences with &lt;PAD&gt; so that each sentence of a batch has the same length&quot;&quot;&quot;</span>
    <span class="n">max_sentence</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_int</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sentence</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Batch targets, sources, and the lengths of their sentences together&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="n">batch_i</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="c1"># Slice the right amount for the batch</span>
        <span class="n">sources_batch</span> <span class="o">=</span> <span class="n">sources</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">targets_batch</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="c1"># Pad</span>
        <span class="n">pad_sources_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">sources_batch</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">))</span>
        <span class="n">pad_targets_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">targets_batch</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">))</span>

        <span class="c1"># Need the lengths for the _lengths parameters</span>
        <span class="n">pad_targets_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pad_targets_batch</span><span class="p">:</span>
            <span class="n">pad_targets_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>

        <span class="n">pad_source_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">pad_sources_batch</span><span class="p">:</span>
            <span class="n">pad_source_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>

        <span class="k">yield</span> <span class="n">pad_sources_batch</span><span class="p">,</span> <span class="n">pad_targets_batch</span><span class="p">,</span> <span class="n">pad_source_lengths</span><span class="p">,</span> <span class="n">pad_targets_lengths</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>

<span class="c1"># Split data to training and validation sets</span>
<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">valid_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">(</span><span class="n">valid_sources_batch</span><span class="p">,</span> <span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">valid_sources_lengths</span><span class="p">,</span> <span class="n">valid_targets_lengths</span> <span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">get_batches</span><span class="p">(</span><span class="n">valid_source</span><span class="p">,</span>
                                                                                                             <span class="n">valid_target</span><span class="p">,</span>
                                                                                                             <span class="n">batch_size</span><span class="p">,</span>
                                                                                                             <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                                                                                                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">]))</span>                                                                                                  
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">sources_lengths</span><span class="p">,</span> <span class="n">targets_lengths</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">get_batches</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">])):</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                 <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>


            <span class="k">if</span> <span class="n">batch_i</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>


                <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>


                <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_sources_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">valid_sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">valid_targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>

                <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>

                <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">batch_valid_logits</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.4f}</span><span class="s1">&#39;</span>
                      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch   20/1077 - Train Accuracy: 0.2316, Validation Accuracy: 0.3050, Loss: 4.6358
Epoch   0 Batch   40/1077 - Train Accuracy: 0.2316, Validation Accuracy: 0.3050, Loss: 3.7600
Epoch   0 Batch   60/1077 - Train Accuracy: 0.2958, Validation Accuracy: 0.3356, Loss: 3.4023
Epoch   0 Batch   80/1077 - Train Accuracy: 0.2707, Validation Accuracy: 0.3363, Loss: 3.3756
Epoch   0 Batch  100/1077 - Train Accuracy: 0.2617, Validation Accuracy: 0.3363, Loss: 3.3328
Epoch   0 Batch  120/1077 - Train Accuracy: 0.2875, Validation Accuracy: 0.3505, Loss: 3.2398
Epoch   0 Batch  140/1077 - Train Accuracy: 0.2603, Validation Accuracy: 0.3590, Loss: 3.3185
Epoch   0 Batch  160/1077 - Train Accuracy: 0.3059, Validation Accuracy: 0.3633, Loss: 3.0719
Epoch   0 Batch  180/1077 - Train Accuracy: 0.3449, Validation Accuracy: 0.4031, Loss: 3.0272
Epoch   0 Batch  200/1077 - Train Accuracy: 0.3570, Validation Accuracy: 0.4158, Loss: 2.9599
Epoch   0 Batch  220/1077 - Train Accuracy: 0.3372, Validation Accuracy: 0.4183, Loss: 2.9914
Epoch   0 Batch  240/1077 - Train Accuracy: 0.3812, Validation Accuracy: 0.4237, Loss: 2.7845
Epoch   0 Batch  260/1077 - Train Accuracy: 0.3969, Validation Accuracy: 0.4300, Loss: 2.6809
Epoch   0 Batch  280/1077 - Train Accuracy: 0.3809, Validation Accuracy: 0.4308, Loss: 2.7117
Epoch   0 Batch  300/1077 - Train Accuracy: 0.3376, Validation Accuracy: 0.4261, Loss: 2.8143
Epoch   0 Batch  320/1077 - Train Accuracy: 0.3863, Validation Accuracy: 0.4322, Loss: 2.6397
Epoch   0 Batch  340/1077 - Train Accuracy: 0.3635, Validation Accuracy: 0.4407, Loss: 2.7027
Epoch   0 Batch  360/1077 - Train Accuracy: 0.4074, Validation Accuracy: 0.4474, Loss: 2.5388
Epoch   0 Batch  380/1077 - Train Accuracy: 0.4160, Validation Accuracy: 0.4510, Loss: 2.4418
Epoch   0 Batch  400/1077 - Train Accuracy: 0.4105, Validation Accuracy: 0.4641, Loss: 2.4783
Epoch   0 Batch  420/1077 - Train Accuracy: 0.4164, Validation Accuracy: 0.4659, Loss: 2.4035
Epoch   0 Batch  440/1077 - Train Accuracy: 0.4195, Validation Accuracy: 0.4645, Loss: 2.3531
Epoch   0 Batch  460/1077 - Train Accuracy: 0.4199, Validation Accuracy: 0.4762, Loss: 2.3541
Epoch   0 Batch  480/1077 - Train Accuracy: 0.4206, Validation Accuracy: 0.4830, Loss: 2.2945
Epoch   0 Batch  500/1077 - Train Accuracy: 0.4461, Validation Accuracy: 0.4808, Loss: 2.1834
Epoch   0 Batch  520/1077 - Train Accuracy: 0.4829, Validation Accuracy: 0.4993, Loss: 2.0599
Epoch   0 Batch  540/1077 - Train Accuracy: 0.4461, Validation Accuracy: 0.4833, Loss: 2.0483
Epoch   0 Batch  560/1077 - Train Accuracy: 0.4512, Validation Accuracy: 0.4936, Loss: 2.0287
Epoch   0 Batch  580/1077 - Train Accuracy: 0.4866, Validation Accuracy: 0.4830, Loss: 1.9422
Epoch   0 Batch  600/1077 - Train Accuracy: 0.4929, Validation Accuracy: 0.4989, Loss: 1.8980
Epoch   0 Batch  620/1077 - Train Accuracy: 0.4562, Validation Accuracy: 0.5014, Loss: 1.9655
Epoch   0 Batch  640/1077 - Train Accuracy: 0.4665, Validation Accuracy: 0.5043, Loss: 1.8908
Epoch   0 Batch  660/1077 - Train Accuracy: 0.4109, Validation Accuracy: 0.4659, Loss: 1.9327
Epoch   0 Batch  680/1077 - Train Accuracy: 0.4557, Validation Accuracy: 0.4996, Loss: 1.8328
Epoch   0 Batch  700/1077 - Train Accuracy: 0.4195, Validation Accuracy: 0.4830, Loss: 1.8088
Epoch   0 Batch  720/1077 - Train Accuracy: 0.4367, Validation Accuracy: 0.4886, Loss: 1.9112
Epoch   0 Batch  740/1077 - Train Accuracy: 0.4703, Validation Accuracy: 0.4957, Loss: 1.7591
Epoch   0 Batch  760/1077 - Train Accuracy: 0.4402, Validation Accuracy: 0.4815, Loss: 1.7739
Epoch   0 Batch  780/1077 - Train Accuracy: 0.4437, Validation Accuracy: 0.4812, Loss: 1.7487
Epoch   0 Batch  800/1077 - Train Accuracy: 0.4504, Validation Accuracy: 0.5004, Loss: 1.7555
Epoch   0 Batch  820/1077 - Train Accuracy: 0.4164, Validation Accuracy: 0.4719, Loss: 1.7365
Epoch   0 Batch  840/1077 - Train Accuracy: 0.4414, Validation Accuracy: 0.4972, Loss: 1.6587
Epoch   0 Batch  860/1077 - Train Accuracy: 0.4710, Validation Accuracy: 0.4872, Loss: 1.6033
Epoch   0 Batch  880/1077 - Train Accuracy: 0.4766, Validation Accuracy: 0.5000, Loss: 1.5749
Epoch   0 Batch  900/1077 - Train Accuracy: 0.4473, Validation Accuracy: 0.4893, Loss: 1.6630
Epoch   0 Batch  920/1077 - Train Accuracy: 0.4660, Validation Accuracy: 0.5021, Loss: 1.5983
Epoch   0 Batch  940/1077 - Train Accuracy: 0.4473, Validation Accuracy: 0.5053, Loss: 1.6119
Epoch   0 Batch  960/1077 - Train Accuracy: 0.4732, Validation Accuracy: 0.4862, Loss: 1.4725
Epoch   0 Batch  980/1077 - Train Accuracy: 0.4926, Validation Accuracy: 0.5064, Loss: 1.4886
Epoch   0 Batch 1000/1077 - Train Accuracy: 0.5093, Validation Accuracy: 0.4940, Loss: 1.4325
Epoch   0 Batch 1020/1077 - Train Accuracy: 0.4781, Validation Accuracy: 0.5060, Loss: 1.4704
Epoch   0 Batch 1040/1077 - Train Accuracy: 0.4560, Validation Accuracy: 0.5096, Loss: 1.5348
Epoch   0 Batch 1060/1077 - Train Accuracy: 0.4516, Validation Accuracy: 0.4933, Loss: 1.4353
Epoch   1 Batch   20/1077 - Train Accuracy: 0.4602, Validation Accuracy: 0.5039, Loss: 1.3718
Epoch   1 Batch   40/1077 - Train Accuracy: 0.4473, Validation Accuracy: 0.4854, Loss: 1.3995
Epoch   1 Batch   60/1077 - Train Accuracy: 0.4501, Validation Accuracy: 0.4830, Loss: 1.3361
Epoch   1 Batch   80/1077 - Train Accuracy: 0.4371, Validation Accuracy: 0.4709, Loss: 1.3636
Epoch   1 Batch  100/1077 - Train Accuracy: 0.4258, Validation Accuracy: 0.4627, Loss: 1.3315
Epoch   1 Batch  120/1077 - Train Accuracy: 0.4168, Validation Accuracy: 0.4712, Loss: 1.3275
Epoch   1 Batch  140/1077 - Train Accuracy: 0.3935, Validation Accuracy: 0.4631, Loss: 1.3808
Epoch   1 Batch  160/1077 - Train Accuracy: 0.4430, Validation Accuracy: 0.4698, Loss: 1.2665
Epoch   1 Batch  180/1077 - Train Accuracy: 0.4117, Validation Accuracy: 0.4524, Loss: 1.2545
Epoch   1 Batch  200/1077 - Train Accuracy: 0.3852, Validation Accuracy: 0.4478, Loss: 1.2584
Epoch   1 Batch  220/1077 - Train Accuracy: 0.3754, Validation Accuracy: 0.4442, Loss: 1.2637
Epoch   1 Batch  240/1077 - Train Accuracy: 0.4094, Validation Accuracy: 0.4361, Loss: 1.1942
Epoch   1 Batch  260/1077 - Train Accuracy: 0.4055, Validation Accuracy: 0.4290, Loss: 1.1475
Epoch   1 Batch  280/1077 - Train Accuracy: 0.3672, Validation Accuracy: 0.4332, Loss: 1.2076
Epoch   1 Batch  300/1077 - Train Accuracy: 0.3894, Validation Accuracy: 0.4581, Loss: 1.2405
Epoch   1 Batch  320/1077 - Train Accuracy: 0.4051, Validation Accuracy: 0.4471, Loss: 1.1841
Epoch   1 Batch  340/1077 - Train Accuracy: 0.4141, Validation Accuracy: 0.4666, Loss: 1.1874
Epoch   1 Batch  360/1077 - Train Accuracy: 0.4184, Validation Accuracy: 0.4592, Loss: 1.1367
Epoch   1 Batch  380/1077 - Train Accuracy: 0.4434, Validation Accuracy: 0.4680, Loss: 1.1105
Epoch   1 Batch  400/1077 - Train Accuracy: 0.4375, Validation Accuracy: 0.4624, Loss: 1.1447
Epoch   1 Batch  420/1077 - Train Accuracy: 0.4215, Validation Accuracy: 0.4663, Loss: 1.1199
Epoch   1 Batch  440/1077 - Train Accuracy: 0.4281, Validation Accuracy: 0.4688, Loss: 1.1282
Epoch   1 Batch  460/1077 - Train Accuracy: 0.3836, Validation Accuracy: 0.4570, Loss: 1.1106
Epoch   1 Batch  480/1077 - Train Accuracy: 0.4190, Validation Accuracy: 0.4819, Loss: 1.1165
Epoch   1 Batch  500/1077 - Train Accuracy: 0.4355, Validation Accuracy: 0.4790, Loss: 1.0721
Epoch   1 Batch  520/1077 - Train Accuracy: 0.4836, Validation Accuracy: 0.4858, Loss: 1.0044
Epoch   1 Batch  540/1077 - Train Accuracy: 0.4465, Validation Accuracy: 0.5032, Loss: 1.0247
Epoch   1 Batch  560/1077 - Train Accuracy: 0.4602, Validation Accuracy: 0.5128, Loss: 1.0180
Epoch   1 Batch  580/1077 - Train Accuracy: 0.5056, Validation Accuracy: 0.5092, Loss: 0.9671
Epoch   1 Batch  600/1077 - Train Accuracy: 0.4777, Validation Accuracy: 0.5050, Loss: 0.9673
Epoch   1 Batch  620/1077 - Train Accuracy: 0.4500, Validation Accuracy: 0.5170, Loss: 1.0123
Epoch   1 Batch  640/1077 - Train Accuracy: 0.4673, Validation Accuracy: 0.5014, Loss: 0.9730
Epoch   1 Batch  660/1077 - Train Accuracy: 0.4793, Validation Accuracy: 0.5245, Loss: 1.0239
Epoch   1 Batch  680/1077 - Train Accuracy: 0.4598, Validation Accuracy: 0.5036, Loss: 0.9770
Epoch   1 Batch  700/1077 - Train Accuracy: 0.4766, Validation Accuracy: 0.5025, Loss: 0.9589
Epoch   1 Batch  720/1077 - Train Accuracy: 0.4597, Validation Accuracy: 0.4911, Loss: 1.0335
Epoch   1 Batch  740/1077 - Train Accuracy: 0.5074, Validation Accuracy: 0.5192, Loss: 0.9431
Epoch   1 Batch  760/1077 - Train Accuracy: 0.5035, Validation Accuracy: 0.5202, Loss: 0.9648
Epoch   1 Batch  780/1077 - Train Accuracy: 0.4734, Validation Accuracy: 0.5227, Loss: 0.9610
Epoch   1 Batch  800/1077 - Train Accuracy: 0.4496, Validation Accuracy: 0.5312, Loss: 0.9534
Epoch   1 Batch  820/1077 - Train Accuracy: 0.4500, Validation Accuracy: 0.5320, Loss: 0.9660
Epoch   1 Batch  840/1077 - Train Accuracy: 0.5027, Validation Accuracy: 0.5167, Loss: 0.9169
Epoch   1 Batch  860/1077 - Train Accuracy: 0.4985, Validation Accuracy: 0.5213, Loss: 0.9055
Epoch   1 Batch  880/1077 - Train Accuracy: 0.5184, Validation Accuracy: 0.5291, Loss: 0.9061
Epoch   1 Batch  900/1077 - Train Accuracy: 0.4891, Validation Accuracy: 0.5138, Loss: 0.9163
Epoch   1 Batch  920/1077 - Train Accuracy: 0.4777, Validation Accuracy: 0.5266, Loss: 0.9119
Epoch   1 Batch  940/1077 - Train Accuracy: 0.4895, Validation Accuracy: 0.5245, Loss: 0.9063
Epoch   1 Batch  960/1077 - Train Accuracy: 0.5223, Validation Accuracy: 0.5128, Loss: 0.8573
Epoch   1 Batch  980/1077 - Train Accuracy: 0.5266, Validation Accuracy: 0.5320, Loss: 0.8780
Epoch   1 Batch 1000/1077 - Train Accuracy: 0.5640, Validation Accuracy: 0.5387, Loss: 0.8278
Epoch   1 Batch 1020/1077 - Train Accuracy: 0.5211, Validation Accuracy: 0.5298, Loss: 0.8556
Epoch   1 Batch 1040/1077 - Train Accuracy: 0.4975, Validation Accuracy: 0.5320, Loss: 0.8923
Epoch   1 Batch 1060/1077 - Train Accuracy: 0.4922, Validation Accuracy: 0.5291, Loss: 0.8449
Epoch   2 Batch   20/1077 - Train Accuracy: 0.5137, Validation Accuracy: 0.5266, Loss: 0.8402
Epoch   2 Batch   40/1077 - Train Accuracy: 0.4715, Validation Accuracy: 0.5224, Loss: 0.8623
Epoch   2 Batch   60/1077 - Train Accuracy: 0.5160, Validation Accuracy: 0.5245, Loss: 0.8230
Epoch   2 Batch   80/1077 - Train Accuracy: 0.4832, Validation Accuracy: 0.5181, Loss: 0.8595
Epoch   2 Batch  100/1077 - Train Accuracy: 0.5098, Validation Accuracy: 0.5366, Loss: 0.8449
Epoch   2 Batch  120/1077 - Train Accuracy: 0.5172, Validation Accuracy: 0.5472, Loss: 0.8403
Epoch   2 Batch  140/1077 - Train Accuracy: 0.4918, Validation Accuracy: 0.5352, Loss: 0.8564
Epoch   2 Batch  160/1077 - Train Accuracy: 0.5379, Validation Accuracy: 0.5415, Loss: 0.8138
Epoch   2 Batch  180/1077 - Train Accuracy: 0.5199, Validation Accuracy: 0.5316, Loss: 0.8084
Epoch   2 Batch  200/1077 - Train Accuracy: 0.4969, Validation Accuracy: 0.5238, Loss: 0.8240
Epoch   2 Batch  220/1077 - Train Accuracy: 0.5119, Validation Accuracy: 0.5249, Loss: 0.8209
Epoch   2 Batch  240/1077 - Train Accuracy: 0.5027, Validation Accuracy: 0.5320, Loss: 0.7793
Epoch   2 Batch  260/1077 - Train Accuracy: 0.5268, Validation Accuracy: 0.5178, Loss: 0.7560
Epoch   2 Batch  280/1077 - Train Accuracy: 0.5043, Validation Accuracy: 0.5128, Loss: 0.8104
Epoch   2 Batch  300/1077 - Train Accuracy: 0.5123, Validation Accuracy: 0.5515, Loss: 0.8179
Epoch   2 Batch  320/1077 - Train Accuracy: 0.5129, Validation Accuracy: 0.5320, Loss: 0.7785
Epoch   2 Batch  340/1077 - Train Accuracy: 0.5008, Validation Accuracy: 0.5494, Loss: 0.7840
Epoch   2 Batch  360/1077 - Train Accuracy: 0.5387, Validation Accuracy: 0.5373, Loss: 0.7740
Epoch   2 Batch  380/1077 - Train Accuracy: 0.5496, Validation Accuracy: 0.5561, Loss: 0.7512
Epoch   2 Batch  400/1077 - Train Accuracy: 0.5109, Validation Accuracy: 0.5469, Loss: 0.7774
Epoch   2 Batch  420/1077 - Train Accuracy: 0.5180, Validation Accuracy: 0.5472, Loss: 0.7449
Epoch   2 Batch  440/1077 - Train Accuracy: 0.5020, Validation Accuracy: 0.5597, Loss: 0.7813
Epoch   2 Batch  460/1077 - Train Accuracy: 0.4668, Validation Accuracy: 0.5284, Loss: 0.7759
Epoch   2 Batch  480/1077 - Train Accuracy: 0.5333, Validation Accuracy: 0.5636, Loss: 0.7688
Epoch   2 Batch  500/1077 - Train Accuracy: 0.5270, Validation Accuracy: 0.5625, Loss: 0.7492
Epoch   2 Batch  520/1077 - Train Accuracy: 0.5789, Validation Accuracy: 0.5678, Loss: 0.6970
Epoch   2 Batch  540/1077 - Train Accuracy: 0.4887, Validation Accuracy: 0.5458, Loss: 0.7008
Epoch   2 Batch  560/1077 - Train Accuracy: 0.5445, Validation Accuracy: 0.5728, Loss: 0.7116
Epoch   2 Batch  580/1077 - Train Accuracy: 0.5551, Validation Accuracy: 0.5611, Loss: 0.6743
Epoch   2 Batch  600/1077 - Train Accuracy: 0.5644, Validation Accuracy: 0.5692, Loss: 0.6815
Epoch   2 Batch  620/1077 - Train Accuracy: 0.5531, Validation Accuracy: 0.5664, Loss: 0.7146
Epoch   2 Batch  640/1077 - Train Accuracy: 0.4981, Validation Accuracy: 0.5795, Loss: 0.7045
Epoch   2 Batch  660/1077 - Train Accuracy: 0.5418, Validation Accuracy: 0.5671, Loss: 0.7452
Epoch   2 Batch  680/1077 - Train Accuracy: 0.5461, Validation Accuracy: 0.5753, Loss: 0.7002
Epoch   2 Batch  700/1077 - Train Accuracy: 0.5223, Validation Accuracy: 0.5582, Loss: 0.7038
Epoch   2 Batch  720/1077 - Train Accuracy: 0.5629, Validation Accuracy: 0.5678, Loss: 0.7605
Epoch   2 Batch  740/1077 - Train Accuracy: 0.5832, Validation Accuracy: 0.5717, Loss: 0.6957
Epoch   2 Batch  760/1077 - Train Accuracy: 0.5523, Validation Accuracy: 0.5639, Loss: 0.7028
Epoch   2 Batch  780/1077 - Train Accuracy: 0.5465, Validation Accuracy: 0.5739, Loss: 0.7087
Epoch   2 Batch  800/1077 - Train Accuracy: 0.5047, Validation Accuracy: 0.5845, Loss: 0.7070
Epoch   2 Batch  820/1077 - Train Accuracy: 0.5391, Validation Accuracy: 0.5753, Loss: 0.7351
Epoch   2 Batch  840/1077 - Train Accuracy: 0.5691, Validation Accuracy: 0.5671, Loss: 0.6775
Epoch   2 Batch  860/1077 - Train Accuracy: 0.5673, Validation Accuracy: 0.5810, Loss: 0.6770
Epoch   2 Batch  880/1077 - Train Accuracy: 0.5750, Validation Accuracy: 0.5746, Loss: 0.6826
Epoch   2 Batch  900/1077 - Train Accuracy: 0.5723, Validation Accuracy: 0.5661, Loss: 0.6792
Epoch   2 Batch  920/1077 - Train Accuracy: 0.5371, Validation Accuracy: 0.5639, Loss: 0.6943
Epoch   2 Batch  940/1077 - Train Accuracy: 0.5484, Validation Accuracy: 0.5682, Loss: 0.6816
Epoch   2 Batch  960/1077 - Train Accuracy: 0.5978, Validation Accuracy: 0.5767, Loss: 0.6540
Epoch   2 Batch  980/1077 - Train Accuracy: 0.5883, Validation Accuracy: 0.5795, Loss: 0.6700
Epoch   2 Batch 1000/1077 - Train Accuracy: 0.6228, Validation Accuracy: 0.5749, Loss: 0.6149
Epoch   2 Batch 1020/1077 - Train Accuracy: 0.5512, Validation Accuracy: 0.5703, Loss: 0.6437
Epoch   2 Batch 1040/1077 - Train Accuracy: 0.5535, Validation Accuracy: 0.5746, Loss: 0.6761
Epoch   2 Batch 1060/1077 - Train Accuracy: 0.5633, Validation Accuracy: 0.5771, Loss: 0.6484
Epoch   3 Batch   20/1077 - Train Accuracy: 0.5566, Validation Accuracy: 0.5934, Loss: 0.6437
Epoch   3 Batch   40/1077 - Train Accuracy: 0.5629, Validation Accuracy: 0.5813, Loss: 0.6598
Epoch   3 Batch   60/1077 - Train Accuracy: 0.5781, Validation Accuracy: 0.5721, Loss: 0.6284
Epoch   3 Batch   80/1077 - Train Accuracy: 0.5789, Validation Accuracy: 0.5572, Loss: 0.6649
Epoch   3 Batch  100/1077 - Train Accuracy: 0.5988, Validation Accuracy: 0.5827, Loss: 0.6545
Epoch   3 Batch  120/1077 - Train Accuracy: 0.5633, Validation Accuracy: 0.5604, Loss: 0.6480
Epoch   3 Batch  140/1077 - Train Accuracy: 0.5473, Validation Accuracy: 0.5760, Loss: 0.6553
Epoch   3 Batch  160/1077 - Train Accuracy: 0.5977, Validation Accuracy: 0.5888, Loss: 0.6239
Epoch   3 Batch  180/1077 - Train Accuracy: 0.5543, Validation Accuracy: 0.5920, Loss: 0.6196
Epoch   3 Batch  200/1077 - Train Accuracy: 0.5594, Validation Accuracy: 0.5980, Loss: 0.6432
Epoch   3 Batch  220/1077 - Train Accuracy: 0.5650, Validation Accuracy: 0.5930, Loss: 0.6376
Epoch   3 Batch  240/1077 - Train Accuracy: 0.6031, Validation Accuracy: 0.5902, Loss: 0.5991
Epoch   3 Batch  260/1077 - Train Accuracy: 0.5889, Validation Accuracy: 0.5696, Loss: 0.5893
Epoch   3 Batch  280/1077 - Train Accuracy: 0.5871, Validation Accuracy: 0.6030, Loss: 0.6295
Epoch   3 Batch  300/1077 - Train Accuracy: 0.5798, Validation Accuracy: 0.5856, Loss: 0.6373
Epoch   3 Batch  320/1077 - Train Accuracy: 0.6023, Validation Accuracy: 0.5863, Loss: 0.6025
Epoch   3 Batch  340/1077 - Train Accuracy: 0.5596, Validation Accuracy: 0.5803, Loss: 0.6087
Epoch   3 Batch  360/1077 - Train Accuracy: 0.5637, Validation Accuracy: 0.5774, Loss: 0.6076
Epoch   3 Batch  380/1077 - Train Accuracy: 0.5777, Validation Accuracy: 0.5973, Loss: 0.5922
Epoch   3 Batch  400/1077 - Train Accuracy: 0.5965, Validation Accuracy: 0.5717, Loss: 0.6108
Epoch   3 Batch  420/1077 - Train Accuracy: 0.5816, Validation Accuracy: 0.5955, Loss: 0.5824
Epoch   3 Batch  440/1077 - Train Accuracy: 0.5871, Validation Accuracy: 0.5838, Loss: 0.6074
Epoch   3 Batch  460/1077 - Train Accuracy: 0.5668, Validation Accuracy: 0.5980, Loss: 0.6097
Epoch   3 Batch  480/1077 - Train Accuracy: 0.5814, Validation Accuracy: 0.5962, Loss: 0.6079
Epoch   3 Batch  500/1077 - Train Accuracy: 0.5613, Validation Accuracy: 0.5863, Loss: 0.5962
Epoch   3 Batch  520/1077 - Train Accuracy: 0.6376, Validation Accuracy: 0.5920, Loss: 0.5505
Epoch   3 Batch  540/1077 - Train Accuracy: 0.5941, Validation Accuracy: 0.5906, Loss: 0.5480
Epoch   3 Batch  560/1077 - Train Accuracy: 0.5707, Validation Accuracy: 0.6076, Loss: 0.5713
Epoch   3 Batch  580/1077 - Train Accuracy: 0.6209, Validation Accuracy: 0.5778, Loss: 0.5355
Epoch   3 Batch  600/1077 - Train Accuracy: 0.5971, Validation Accuracy: 0.5724, Loss: 0.5380
Epoch   3 Batch  620/1077 - Train Accuracy: 0.5910, Validation Accuracy: 0.5870, Loss: 0.5676
Epoch   3 Batch  640/1077 - Train Accuracy: 0.5733, Validation Accuracy: 0.5969, Loss: 0.5658
Epoch   3 Batch  660/1077 - Train Accuracy: 0.5961, Validation Accuracy: 0.5884, Loss: 0.5945
Epoch   3 Batch  680/1077 - Train Accuracy: 0.5740, Validation Accuracy: 0.5810, Loss: 0.5572
Epoch   3 Batch  700/1077 - Train Accuracy: 0.5723, Validation Accuracy: 0.5984, Loss: 0.5562
Epoch   3 Batch  720/1077 - Train Accuracy: 0.5728, Validation Accuracy: 0.5490, Loss: 0.6227
Epoch   3 Batch  740/1077 - Train Accuracy: 0.5613, Validation Accuracy: 0.6016, Loss: 0.5598
Epoch   3 Batch  760/1077 - Train Accuracy: 0.5512, Validation Accuracy: 0.6080, Loss: 0.5749
Epoch   3 Batch  780/1077 - Train Accuracy: 0.5863, Validation Accuracy: 0.5994, Loss: 0.5740
Epoch   3 Batch  800/1077 - Train Accuracy: 0.5348, Validation Accuracy: 0.5629, Loss: 0.5647
Epoch   3 Batch  820/1077 - Train Accuracy: 0.5766, Validation Accuracy: 0.5948, Loss: 0.5919
Epoch   3 Batch  840/1077 - Train Accuracy: 0.5969, Validation Accuracy: 0.5877, Loss: 0.5435
Epoch   3 Batch  860/1077 - Train Accuracy: 0.5945, Validation Accuracy: 0.6023, Loss: 0.5472
Epoch   3 Batch  880/1077 - Train Accuracy: 0.6016, Validation Accuracy: 0.5998, Loss: 0.5430
Epoch   3 Batch  900/1077 - Train Accuracy: 0.6023, Validation Accuracy: 0.5874, Loss: 0.5559
Epoch   3 Batch  920/1077 - Train Accuracy: 0.5770, Validation Accuracy: 0.5923, Loss: 0.5654
Epoch   3 Batch  940/1077 - Train Accuracy: 0.5730, Validation Accuracy: 0.5934, Loss: 0.5449
Epoch   3 Batch  960/1077 - Train Accuracy: 0.5871, Validation Accuracy: 0.5962, Loss: 0.5202
Epoch   3 Batch  980/1077 - Train Accuracy: 0.5801, Validation Accuracy: 0.5909, Loss: 0.5358
Epoch   3 Batch 1000/1077 - Train Accuracy: 0.6265, Validation Accuracy: 0.5962, Loss: 0.4931
Epoch   3 Batch 1020/1077 - Train Accuracy: 0.5762, Validation Accuracy: 0.5941, Loss: 0.5134
Epoch   3 Batch 1040/1077 - Train Accuracy: 0.5662, Validation Accuracy: 0.6001, Loss: 0.5438
Epoch   3 Batch 1060/1077 - Train Accuracy: 0.5836, Validation Accuracy: 0.5643, Loss: 0.5463
Epoch   4 Batch   20/1077 - Train Accuracy: 0.5617, Validation Accuracy: 0.5842, Loss: 0.5190
Epoch   4 Batch   40/1077 - Train Accuracy: 0.5766, Validation Accuracy: 0.6133, Loss: 0.5315
Epoch   4 Batch   60/1077 - Train Accuracy: 0.5945, Validation Accuracy: 0.6161, Loss: 0.5059
Epoch   4 Batch   80/1077 - Train Accuracy: 0.5125, Validation Accuracy: 0.5678, Loss: 0.5332
Epoch   4 Batch  100/1077 - Train Accuracy: 0.5883, Validation Accuracy: 0.5835, Loss: 0.5299
Epoch   4 Batch  120/1077 - Train Accuracy: 0.6055, Validation Accuracy: 0.6222, Loss: 0.5301
Epoch   4 Batch  140/1077 - Train Accuracy: 0.5781, Validation Accuracy: 0.5923, Loss: 0.5306
Epoch   4 Batch  160/1077 - Train Accuracy: 0.6047, Validation Accuracy: 0.6261, Loss: 0.5008
Epoch   4 Batch  180/1077 - Train Accuracy: 0.6008, Validation Accuracy: 0.6254, Loss: 0.4952
Epoch   4 Batch  200/1077 - Train Accuracy: 0.5801, Validation Accuracy: 0.6172, Loss: 0.5222
Epoch   4 Batch  220/1077 - Train Accuracy: 0.5905, Validation Accuracy: 0.5856, Loss: 0.5181
Epoch   4 Batch  240/1077 - Train Accuracy: 0.6137, Validation Accuracy: 0.6214, Loss: 0.4769
Epoch   4 Batch  260/1077 - Train Accuracy: 0.6045, Validation Accuracy: 0.5987, Loss: 0.4671
Epoch   4 Batch  280/1077 - Train Accuracy: 0.6121, Validation Accuracy: 0.6303, Loss: 0.5084
Epoch   4 Batch  300/1077 - Train Accuracy: 0.6312, Validation Accuracy: 0.6168, Loss: 0.5100
Epoch   4 Batch  320/1077 - Train Accuracy: 0.6180, Validation Accuracy: 0.6186, Loss: 0.4866
Epoch   4 Batch  340/1077 - Train Accuracy: 0.5826, Validation Accuracy: 0.6346, Loss: 0.4802
Epoch   4 Batch  360/1077 - Train Accuracy: 0.6109, Validation Accuracy: 0.6069, Loss: 0.4910
Epoch   4 Batch  380/1077 - Train Accuracy: 0.5844, Validation Accuracy: 0.6175, Loss: 0.4832
Epoch   4 Batch  400/1077 - Train Accuracy: 0.5883, Validation Accuracy: 0.5874, Loss: 0.5066
Epoch   4 Batch  420/1077 - Train Accuracy: 0.6375, Validation Accuracy: 0.6175, Loss: 0.4726
Epoch   4 Batch  440/1077 - Train Accuracy: 0.5840, Validation Accuracy: 0.6108, Loss: 0.4945
Epoch   4 Batch  460/1077 - Train Accuracy: 0.6129, Validation Accuracy: 0.6129, Loss: 0.4965
Epoch   4 Batch  480/1077 - Train Accuracy: 0.6295, Validation Accuracy: 0.6200, Loss: 0.4914
Epoch   4 Batch  500/1077 - Train Accuracy: 0.5816, Validation Accuracy: 0.5852, Loss: 0.4780
Epoch   4 Batch  520/1077 - Train Accuracy: 0.6138, Validation Accuracy: 0.6204, Loss: 0.4404
Epoch   4 Batch  540/1077 - Train Accuracy: 0.6281, Validation Accuracy: 0.5987, Loss: 0.4409
Epoch   4 Batch  560/1077 - Train Accuracy: 0.6098, Validation Accuracy: 0.6190, Loss: 0.4649
Epoch   4 Batch  580/1077 - Train Accuracy: 0.6317, Validation Accuracy: 0.5945, Loss: 0.4362
Epoch   4 Batch  600/1077 - Train Accuracy: 0.6280, Validation Accuracy: 0.6048, Loss: 0.4395
Epoch   4 Batch  620/1077 - Train Accuracy: 0.6051, Validation Accuracy: 0.6147, Loss: 0.4587
Epoch   4 Batch  640/1077 - Train Accuracy: 0.6343, Validation Accuracy: 0.6339, Loss: 0.4602
Epoch   4 Batch  660/1077 - Train Accuracy: 0.6133, Validation Accuracy: 0.6271, Loss: 0.4858
Epoch   4 Batch  680/1077 - Train Accuracy: 0.6112, Validation Accuracy: 0.6214, Loss: 0.4558
Epoch   4 Batch  700/1077 - Train Accuracy: 0.5699, Validation Accuracy: 0.6097, Loss: 0.4504
Epoch   4 Batch  720/1077 - Train Accuracy: 0.5921, Validation Accuracy: 0.6190, Loss: 0.4963
Epoch   4 Batch  740/1077 - Train Accuracy: 0.5973, Validation Accuracy: 0.6257, Loss: 0.4604
Epoch   4 Batch  760/1077 - Train Accuracy: 0.6117, Validation Accuracy: 0.6207, Loss: 0.4696
Epoch   4 Batch  780/1077 - Train Accuracy: 0.6020, Validation Accuracy: 0.6442, Loss: 0.4682
Epoch   4 Batch  800/1077 - Train Accuracy: 0.6035, Validation Accuracy: 0.6278, Loss: 0.4578
Epoch   4 Batch  820/1077 - Train Accuracy: 0.5930, Validation Accuracy: 0.6424, Loss: 0.4764
Epoch   4 Batch  840/1077 - Train Accuracy: 0.6723, Validation Accuracy: 0.6339, Loss: 0.4399
Epoch   4 Batch  860/1077 - Train Accuracy: 0.5952, Validation Accuracy: 0.6175, Loss: 0.4401
Epoch   4 Batch  880/1077 - Train Accuracy: 0.6227, Validation Accuracy: 0.6314, Loss: 0.4363
Epoch   4 Batch  900/1077 - Train Accuracy: 0.6379, Validation Accuracy: 0.6502, Loss: 0.4511
Epoch   4 Batch  920/1077 - Train Accuracy: 0.6246, Validation Accuracy: 0.6396, Loss: 0.4609
Epoch   4 Batch  940/1077 - Train Accuracy: 0.6223, Validation Accuracy: 0.6232, Loss: 0.4406
Epoch   4 Batch  960/1077 - Train Accuracy: 0.6451, Validation Accuracy: 0.6399, Loss: 0.4151
Epoch   4 Batch  980/1077 - Train Accuracy: 0.6031, Validation Accuracy: 0.6385, Loss: 0.4362
Epoch   4 Batch 1000/1077 - Train Accuracy: 0.6544, Validation Accuracy: 0.6278, Loss: 0.3989
Epoch   4 Batch 1020/1077 - Train Accuracy: 0.6250, Validation Accuracy: 0.6339, Loss: 0.4181
Epoch   4 Batch 1040/1077 - Train Accuracy: 0.6464, Validation Accuracy: 0.6325, Loss: 0.4353
Epoch   4 Batch 1060/1077 - Train Accuracy: 0.6250, Validation Accuracy: 0.6364, Loss: 0.4460
Epoch   5 Batch   20/1077 - Train Accuracy: 0.6145, Validation Accuracy: 0.6300, Loss: 0.4087
Epoch   5 Batch   40/1077 - Train Accuracy: 0.6156, Validation Accuracy: 0.6452, Loss: 0.4248
Epoch   5 Batch   60/1077 - Train Accuracy: 0.6269, Validation Accuracy: 0.6364, Loss: 0.4061
Epoch   5 Batch   80/1077 - Train Accuracy: 0.6094, Validation Accuracy: 0.6396, Loss: 0.4236
Epoch   5 Batch  100/1077 - Train Accuracy: 0.6219, Validation Accuracy: 0.6388, Loss: 0.4226
Epoch   5 Batch  120/1077 - Train Accuracy: 0.6535, Validation Accuracy: 0.6339, Loss: 0.4255
Epoch   5 Batch  140/1077 - Train Accuracy: 0.6172, Validation Accuracy: 0.6413, Loss: 0.4272
Epoch   5 Batch  160/1077 - Train Accuracy: 0.6551, Validation Accuracy: 0.6431, Loss: 0.4012
Epoch   5 Batch  180/1077 - Train Accuracy: 0.6336, Validation Accuracy: 0.6548, Loss: 0.4015
Epoch   5 Batch  200/1077 - Train Accuracy: 0.6473, Validation Accuracy: 0.6456, Loss: 0.4203
Epoch   5 Batch  220/1077 - Train Accuracy: 0.6287, Validation Accuracy: 0.6261, Loss: 0.4243
Epoch   5 Batch  240/1077 - Train Accuracy: 0.7008, Validation Accuracy: 0.6381, Loss: 0.3861
Epoch   5 Batch  260/1077 - Train Accuracy: 0.6350, Validation Accuracy: 0.6428, Loss: 0.3800
Epoch   5 Batch  280/1077 - Train Accuracy: 0.6238, Validation Accuracy: 0.6488, Loss: 0.4135
Epoch   5 Batch  300/1077 - Train Accuracy: 0.6641, Validation Accuracy: 0.6541, Loss: 0.4141
Epoch   5 Batch  320/1077 - Train Accuracy: 0.6773, Validation Accuracy: 0.6435, Loss: 0.3971
Epoch   5 Batch  340/1077 - Train Accuracy: 0.6534, Validation Accuracy: 0.6321, Loss: 0.3927
Epoch   5 Batch  360/1077 - Train Accuracy: 0.6348, Validation Accuracy: 0.6307, Loss: 0.3981
Epoch   5 Batch  380/1077 - Train Accuracy: 0.6508, Validation Accuracy: 0.6445, Loss: 0.3899
Epoch   5 Batch  400/1077 - Train Accuracy: 0.6262, Validation Accuracy: 0.6364, Loss: 0.4158
Epoch   5 Batch  420/1077 - Train Accuracy: 0.6809, Validation Accuracy: 0.6410, Loss: 0.3859
Epoch   5 Batch  440/1077 - Train Accuracy: 0.6336, Validation Accuracy: 0.6388, Loss: 0.4041
Epoch   5 Batch  460/1077 - Train Accuracy: 0.6578, Validation Accuracy: 0.6477, Loss: 0.4096
Epoch   5 Batch  480/1077 - Train Accuracy: 0.6748, Validation Accuracy: 0.6456, Loss: 0.4001
Epoch   5 Batch  500/1077 - Train Accuracy: 0.6414, Validation Accuracy: 0.6531, Loss: 0.3885
Epoch   5 Batch  520/1077 - Train Accuracy: 0.6849, Validation Accuracy: 0.6562, Loss: 0.3560
Epoch   5 Batch  540/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.6360, Loss: 0.3586
Epoch   5 Batch  560/1077 - Train Accuracy: 0.6609, Validation Accuracy: 0.6367, Loss: 0.3826
Epoch   5 Batch  580/1077 - Train Accuracy: 0.6734, Validation Accuracy: 0.6481, Loss: 0.3616
Epoch   5 Batch  600/1077 - Train Accuracy: 0.6667, Validation Accuracy: 0.6367, Loss: 0.3523
Epoch   5 Batch  620/1077 - Train Accuracy: 0.6473, Validation Accuracy: 0.6523, Loss: 0.3678
Epoch   5 Batch  640/1077 - Train Accuracy: 0.6708, Validation Accuracy: 0.6552, Loss: 0.3822
Epoch   5 Batch  660/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6509, Loss: 0.3922
Epoch   5 Batch  680/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.6506, Loss: 0.3730
Epoch   5 Batch  700/1077 - Train Accuracy: 0.6277, Validation Accuracy: 0.6584, Loss: 0.3711
Epoch   5 Batch  720/1077 - Train Accuracy: 0.6386, Validation Accuracy: 0.6428, Loss: 0.4076
Epoch   5 Batch  740/1077 - Train Accuracy: 0.6562, Validation Accuracy: 0.6474, Loss: 0.3651
Epoch   5 Batch  760/1077 - Train Accuracy: 0.6656, Validation Accuracy: 0.6541, Loss: 0.3885
Epoch   5 Batch  780/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6594, Loss: 0.3836
Epoch   5 Batch  800/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.6637, Loss: 0.3741
Epoch   5 Batch  820/1077 - Train Accuracy: 0.6547, Validation Accuracy: 0.6651, Loss: 0.3927
Epoch   5 Batch  840/1077 - Train Accuracy: 0.6746, Validation Accuracy: 0.6719, Loss: 0.3623
Epoch   5 Batch  860/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.6612, Loss: 0.3639
Epoch   5 Batch  880/1077 - Train Accuracy: 0.6551, Validation Accuracy: 0.6495, Loss: 0.3604
Epoch   5 Batch  900/1077 - Train Accuracy: 0.6926, Validation Accuracy: 0.6584, Loss: 0.3729
Epoch   5 Batch  920/1077 - Train Accuracy: 0.6590, Validation Accuracy: 0.6495, Loss: 0.3840
Epoch   5 Batch  940/1077 - Train Accuracy: 0.6605, Validation Accuracy: 0.6527, Loss: 0.3594
Epoch   5 Batch  960/1077 - Train Accuracy: 0.7068, Validation Accuracy: 0.6552, Loss: 0.3466
Epoch   5 Batch  980/1077 - Train Accuracy: 0.6590, Validation Accuracy: 0.6665, Loss: 0.3672
Epoch   5 Batch 1000/1077 - Train Accuracy: 0.6942, Validation Accuracy: 0.6658, Loss: 0.3306
Epoch   5 Batch 1020/1077 - Train Accuracy: 0.6637, Validation Accuracy: 0.6541, Loss: 0.3462
Epoch   5 Batch 1040/1077 - Train Accuracy: 0.6974, Validation Accuracy: 0.6552, Loss: 0.3627
Epoch   5 Batch 1060/1077 - Train Accuracy: 0.6746, Validation Accuracy: 0.6580, Loss: 0.3639
Epoch   6 Batch   20/1077 - Train Accuracy: 0.6855, Validation Accuracy: 0.6584, Loss: 0.3369
Epoch   6 Batch   40/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6598, Loss: 0.3492
Epoch   6 Batch   60/1077 - Train Accuracy: 0.6968, Validation Accuracy: 0.6602, Loss: 0.3396
Epoch   6 Batch   80/1077 - Train Accuracy: 0.6582, Validation Accuracy: 0.6552, Loss: 0.3501
Epoch   6 Batch  100/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.6896, Loss: 0.3453
Epoch   6 Batch  120/1077 - Train Accuracy: 0.7047, Validation Accuracy: 0.6594, Loss: 0.3600
Epoch   6 Batch  140/1077 - Train Accuracy: 0.6299, Validation Accuracy: 0.6641, Loss: 0.3537
Epoch   6 Batch  160/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.6520, Loss: 0.3364
Epoch   6 Batch  180/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6570, Loss: 0.3340
Epoch   6 Batch  200/1077 - Train Accuracy: 0.6633, Validation Accuracy: 0.6520, Loss: 0.3509
Epoch   6 Batch  220/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.6509, Loss: 0.3519
Epoch   6 Batch  240/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.6662, Loss: 0.3179
Epoch   6 Batch  260/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.6527, Loss: 0.3178
Epoch   6 Batch  280/1077 - Train Accuracy: 0.6598, Validation Accuracy: 0.6644, Loss: 0.3451
Epoch   6 Batch  300/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.6651, Loss: 0.3364
Epoch   6 Batch  320/1077 - Train Accuracy: 0.7051, Validation Accuracy: 0.6641, Loss: 0.3288
Epoch   6 Batch  340/1077 - Train Accuracy: 0.7171, Validation Accuracy: 0.6545, Loss: 0.3274
Epoch   6 Batch  360/1077 - Train Accuracy: 0.6961, Validation Accuracy: 0.6538, Loss: 0.3241
Epoch   6 Batch  380/1077 - Train Accuracy: 0.6855, Validation Accuracy: 0.6570, Loss: 0.3209
Epoch   6 Batch  400/1077 - Train Accuracy: 0.6395, Validation Accuracy: 0.6729, Loss: 0.3461
Epoch   6 Batch  420/1077 - Train Accuracy: 0.6883, Validation Accuracy: 0.6637, Loss: 0.3175
Epoch   6 Batch  440/1077 - Train Accuracy: 0.6680, Validation Accuracy: 0.6403, Loss: 0.3436
Epoch   6 Batch  460/1077 - Train Accuracy: 0.6973, Validation Accuracy: 0.6559, Loss: 0.3389
Epoch   6 Batch  480/1077 - Train Accuracy: 0.6859, Validation Accuracy: 0.6598, Loss: 0.3307
Epoch   6 Batch  500/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6729, Loss: 0.3186
Epoch   6 Batch  520/1077 - Train Accuracy: 0.7403, Validation Accuracy: 0.6644, Loss: 0.2990
Epoch   6 Batch  540/1077 - Train Accuracy: 0.7152, Validation Accuracy: 0.6612, Loss: 0.2953
Epoch   6 Batch  560/1077 - Train Accuracy: 0.6770, Validation Accuracy: 0.6488, Loss: 0.3194
Epoch   6 Batch  580/1077 - Train Accuracy: 0.7180, Validation Accuracy: 0.6751, Loss: 0.2952
Epoch   6 Batch  600/1077 - Train Accuracy: 0.7202, Validation Accuracy: 0.6658, Loss: 0.2883
Epoch   6 Batch  620/1077 - Train Accuracy: 0.6906, Validation Accuracy: 0.6669, Loss: 0.3034
Epoch   6 Batch  640/1077 - Train Accuracy: 0.7016, Validation Accuracy: 0.6697, Loss: 0.3187
Epoch   6 Batch  660/1077 - Train Accuracy: 0.7000, Validation Accuracy: 0.6651, Loss: 0.3296
Epoch   6 Batch  680/1077 - Train Accuracy: 0.6823, Validation Accuracy: 0.6715, Loss: 0.3147
Epoch   6 Batch  700/1077 - Train Accuracy: 0.6602, Validation Accuracy: 0.6520, Loss: 0.3101
Epoch   6 Batch  720/1077 - Train Accuracy: 0.6834, Validation Accuracy: 0.6474, Loss: 0.3519
Epoch   6 Batch  740/1077 - Train Accuracy: 0.7109, Validation Accuracy: 0.6541, Loss: 0.3081
Epoch   6 Batch  760/1077 - Train Accuracy: 0.6813, Validation Accuracy: 0.6829, Loss: 0.3272
Epoch   6 Batch  780/1077 - Train Accuracy: 0.6910, Validation Accuracy: 0.6797, Loss: 0.3211
Epoch   6 Batch  800/1077 - Train Accuracy: 0.7133, Validation Accuracy: 0.6662, Loss: 0.3094
Epoch   6 Batch  820/1077 - Train Accuracy: 0.6605, Validation Accuracy: 0.6857, Loss: 0.3334
Epoch   6 Batch  840/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.6932, Loss: 0.3007
Epoch   6 Batch  860/1077 - Train Accuracy: 0.6849, Validation Accuracy: 0.6591, Loss: 0.3051
Epoch   6 Batch  880/1077 - Train Accuracy: 0.7047, Validation Accuracy: 0.6751, Loss: 0.3031
Epoch   6 Batch  900/1077 - Train Accuracy: 0.7223, Validation Accuracy: 0.6690, Loss: 0.3097
Epoch   6 Batch  920/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.6861, Loss: 0.3103
Epoch   6 Batch  940/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.6861, Loss: 0.2942
Epoch   6 Batch  960/1077 - Train Accuracy: 0.7068, Validation Accuracy: 0.6701, Loss: 0.2893
Epoch   6 Batch  980/1077 - Train Accuracy: 0.6730, Validation Accuracy: 0.6978, Loss: 0.3119
Epoch   6 Batch 1000/1077 - Train Accuracy: 0.7370, Validation Accuracy: 0.6964, Loss: 0.2732
Epoch   6 Batch 1020/1077 - Train Accuracy: 0.7238, Validation Accuracy: 0.6857, Loss: 0.2858
Epoch   6 Batch 1040/1077 - Train Accuracy: 0.7085, Validation Accuracy: 0.6790, Loss: 0.3047
Epoch   6 Batch 1060/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.6854, Loss: 0.2951
Epoch   7 Batch   20/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.6889, Loss: 0.2829
Epoch   7 Batch   40/1077 - Train Accuracy: 0.7188, Validation Accuracy: 0.6982, Loss: 0.2949
Epoch   7 Batch   60/1077 - Train Accuracy: 0.6916, Validation Accuracy: 0.6896, Loss: 0.2856
Epoch   7 Batch   80/1077 - Train Accuracy: 0.6840, Validation Accuracy: 0.6804, Loss: 0.2963
Epoch   7 Batch  100/1077 - Train Accuracy: 0.7223, Validation Accuracy: 0.7173, Loss: 0.2915
Epoch   7 Batch  120/1077 - Train Accuracy: 0.7168, Validation Accuracy: 0.7099, Loss: 0.3060
Epoch   7 Batch  140/1077 - Train Accuracy: 0.7150, Validation Accuracy: 0.7031, Loss: 0.2952
Epoch   7 Batch  160/1077 - Train Accuracy: 0.7215, Validation Accuracy: 0.7070, Loss: 0.2838
Epoch   7 Batch  180/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.7102, Loss: 0.2784
Epoch   7 Batch  200/1077 - Train Accuracy: 0.7094, Validation Accuracy: 0.7042, Loss: 0.2931
Epoch   7 Batch  220/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.6911, Loss: 0.2948
Epoch   7 Batch  240/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.6893, Loss: 0.2634
Epoch   7 Batch  260/1077 - Train Accuracy: 0.7124, Validation Accuracy: 0.6999, Loss: 0.2657
Epoch   7 Batch  280/1077 - Train Accuracy: 0.6859, Validation Accuracy: 0.7085, Loss: 0.2922
Epoch   7 Batch  300/1077 - Train Accuracy: 0.7414, Validation Accuracy: 0.6911, Loss: 0.2798
Epoch   7 Batch  320/1077 - Train Accuracy: 0.7645, Validation Accuracy: 0.7273, Loss: 0.2732
Epoch   7 Batch  340/1077 - Train Accuracy: 0.7566, Validation Accuracy: 0.7035, Loss: 0.2726
Epoch   7 Batch  360/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7045, Loss: 0.2649
Epoch   7 Batch  380/1077 - Train Accuracy: 0.6980, Validation Accuracy: 0.7085, Loss: 0.2608
Epoch   7 Batch  400/1077 - Train Accuracy: 0.7207, Validation Accuracy: 0.7028, Loss: 0.2938
Epoch   7 Batch  420/1077 - Train Accuracy: 0.7441, Validation Accuracy: 0.7067, Loss: 0.2617
Epoch   7 Batch  440/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.7163, Loss: 0.2914
Epoch   7 Batch  460/1077 - Train Accuracy: 0.7320, Validation Accuracy: 0.7184, Loss: 0.2834
Epoch   7 Batch  480/1077 - Train Accuracy: 0.7286, Validation Accuracy: 0.7049, Loss: 0.2753
Epoch   7 Batch  500/1077 - Train Accuracy: 0.7113, Validation Accuracy: 0.6928, Loss: 0.2649
Epoch   7 Batch  520/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7376, Loss: 0.2480
Epoch   7 Batch  540/1077 - Train Accuracy: 0.7418, Validation Accuracy: 0.7131, Loss: 0.2474
Epoch   7 Batch  560/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.7212, Loss: 0.2631
Epoch   7 Batch  580/1077 - Train Accuracy: 0.7757, Validation Accuracy: 0.7266, Loss: 0.2443
Epoch   7 Batch  600/1077 - Train Accuracy: 0.7716, Validation Accuracy: 0.7060, Loss: 0.2399
Epoch   7 Batch  620/1077 - Train Accuracy: 0.7398, Validation Accuracy: 0.7113, Loss: 0.2509
Epoch   7 Batch  640/1077 - Train Accuracy: 0.7184, Validation Accuracy: 0.7273, Loss: 0.2621
Epoch   7 Batch  660/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.7173, Loss: 0.2754
Epoch   7 Batch  680/1077 - Train Accuracy: 0.7094, Validation Accuracy: 0.7063, Loss: 0.2671
Epoch   7 Batch  700/1077 - Train Accuracy: 0.7199, Validation Accuracy: 0.7198, Loss: 0.2511
Epoch   7 Batch  720/1077 - Train Accuracy: 0.7122, Validation Accuracy: 0.6882, Loss: 0.2951
Epoch   7 Batch  740/1077 - Train Accuracy: 0.7516, Validation Accuracy: 0.7113, Loss: 0.2536
Epoch   7 Batch  760/1077 - Train Accuracy: 0.7102, Validation Accuracy: 0.7141, Loss: 0.2731
Epoch   7 Batch  780/1077 - Train Accuracy: 0.7344, Validation Accuracy: 0.7262, Loss: 0.2707
Epoch   7 Batch  800/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7273, Loss: 0.2539
Epoch   7 Batch  820/1077 - Train Accuracy: 0.6758, Validation Accuracy: 0.7227, Loss: 0.2802
Epoch   7 Batch  840/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7393, Loss: 0.2497
Epoch   7 Batch  860/1077 - Train Accuracy: 0.7098, Validation Accuracy: 0.7212, Loss: 0.2583
Epoch   7 Batch  880/1077 - Train Accuracy: 0.7465, Validation Accuracy: 0.7422, Loss: 0.2513
Epoch   7 Batch  900/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7283, Loss: 0.2626
Epoch   7 Batch  920/1077 - Train Accuracy: 0.7578, Validation Accuracy: 0.7319, Loss: 0.2572
Epoch   7 Batch  940/1077 - Train Accuracy: 0.7395, Validation Accuracy: 0.7173, Loss: 0.2438
Epoch   7 Batch  960/1077 - Train Accuracy: 0.7284, Validation Accuracy: 0.7259, Loss: 0.2388
Epoch   7 Batch  980/1077 - Train Accuracy: 0.7293, Validation Accuracy: 0.7351, Loss: 0.2624
Epoch   7 Batch 1000/1077 - Train Accuracy: 0.7753, Validation Accuracy: 0.7259, Loss: 0.2264
Epoch   7 Batch 1020/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7205, Loss: 0.2377
Epoch   7 Batch 1040/1077 - Train Accuracy: 0.7718, Validation Accuracy: 0.7383, Loss: 0.2562
Epoch   7 Batch 1060/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.7234, Loss: 0.2398
Epoch   8 Batch   20/1077 - Train Accuracy: 0.6848, Validation Accuracy: 0.7362, Loss: 0.2391
Epoch   8 Batch   40/1077 - Train Accuracy: 0.7492, Validation Accuracy: 0.7333, Loss: 0.2472
Epoch   8 Batch   60/1077 - Train Accuracy: 0.7251, Validation Accuracy: 0.7418, Loss: 0.2381
Epoch   8 Batch   80/1077 - Train Accuracy: 0.7270, Validation Accuracy: 0.7273, Loss: 0.2497
Epoch   8 Batch  100/1077 - Train Accuracy: 0.7488, Validation Accuracy: 0.7401, Loss: 0.2439
Epoch   8 Batch  120/1077 - Train Accuracy: 0.7508, Validation Accuracy: 0.7546, Loss: 0.2568
Epoch   8 Batch  140/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7369, Loss: 0.2426
Epoch   8 Batch  160/1077 - Train Accuracy: 0.7758, Validation Accuracy: 0.7479, Loss: 0.2413
Epoch   8 Batch  180/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7564, Loss: 0.2315
Epoch   8 Batch  200/1077 - Train Accuracy: 0.7285, Validation Accuracy: 0.7504, Loss: 0.2460
Epoch   8 Batch  220/1077 - Train Accuracy: 0.7438, Validation Accuracy: 0.7401, Loss: 0.2468
Epoch   8 Batch  240/1077 - Train Accuracy: 0.7879, Validation Accuracy: 0.7468, Loss: 0.2153
Epoch   8 Batch  260/1077 - Train Accuracy: 0.7444, Validation Accuracy: 0.7333, Loss: 0.2186
Epoch   8 Batch  280/1077 - Train Accuracy: 0.7512, Validation Accuracy: 0.7301, Loss: 0.2394
Epoch   8 Batch  300/1077 - Train Accuracy: 0.7952, Validation Accuracy: 0.7273, Loss: 0.2285
Epoch   8 Batch  320/1077 - Train Accuracy: 0.7930, Validation Accuracy: 0.7699, Loss: 0.2274
Epoch   8 Batch  340/1077 - Train Accuracy: 0.7833, Validation Accuracy: 0.7337, Loss: 0.2245
Epoch   8 Batch  360/1077 - Train Accuracy: 0.7730, Validation Accuracy: 0.7170, Loss: 0.2147
Epoch   8 Batch  380/1077 - Train Accuracy: 0.7539, Validation Accuracy: 0.7305, Loss: 0.2133
Epoch   8 Batch  400/1077 - Train Accuracy: 0.7273, Validation Accuracy: 0.7315, Loss: 0.2456
Epoch   8 Batch  420/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7464, Loss: 0.2107
Epoch   8 Batch  440/1077 - Train Accuracy: 0.7660, Validation Accuracy: 0.7280, Loss: 0.2453
Epoch   8 Batch  460/1077 - Train Accuracy: 0.7824, Validation Accuracy: 0.7404, Loss: 0.2348
Epoch   8 Batch  480/1077 - Train Accuracy: 0.7747, Validation Accuracy: 0.7408, Loss: 0.2250
Epoch   8 Batch  500/1077 - Train Accuracy: 0.7387, Validation Accuracy: 0.7347, Loss: 0.2153
Epoch   8 Batch  520/1077 - Train Accuracy: 0.7999, Validation Accuracy: 0.7571, Loss: 0.2045
Epoch   8 Batch  540/1077 - Train Accuracy: 0.7652, Validation Accuracy: 0.7383, Loss: 0.2039
Epoch   8 Batch  560/1077 - Train Accuracy: 0.7473, Validation Accuracy: 0.7340, Loss: 0.2197
Epoch   8 Batch  580/1077 - Train Accuracy: 0.8147, Validation Accuracy: 0.7603, Loss: 0.1980
Epoch   8 Batch  600/1077 - Train Accuracy: 0.7812, Validation Accuracy: 0.7401, Loss: 0.1973
Epoch   8 Batch  620/1077 - Train Accuracy: 0.7715, Validation Accuracy: 0.7354, Loss: 0.2066
Epoch   8 Batch  640/1077 - Train Accuracy: 0.7541, Validation Accuracy: 0.7670, Loss: 0.2146
Epoch   8 Batch  660/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7347, Loss: 0.2252
Epoch   8 Batch  680/1077 - Train Accuracy: 0.7407, Validation Accuracy: 0.7461, Loss: 0.2220
Epoch   8 Batch  700/1077 - Train Accuracy: 0.7633, Validation Accuracy: 0.7347, Loss: 0.1994
Epoch   8 Batch  720/1077 - Train Accuracy: 0.7467, Validation Accuracy: 0.7628, Loss: 0.2484
Epoch   8 Batch  740/1077 - Train Accuracy: 0.7594, Validation Accuracy: 0.7393, Loss: 0.1970
Epoch   8 Batch  760/1077 - Train Accuracy: 0.7602, Validation Accuracy: 0.7486, Loss: 0.2217
Epoch   8 Batch  780/1077 - Train Accuracy: 0.7262, Validation Accuracy: 0.7347, Loss: 0.2226
Epoch   8 Batch  800/1077 - Train Accuracy: 0.8051, Validation Accuracy: 0.7670, Loss: 0.2091
Epoch   8 Batch  820/1077 - Train Accuracy: 0.7227, Validation Accuracy: 0.7305, Loss: 0.2312
Epoch   8 Batch  840/1077 - Train Accuracy: 0.7680, Validation Accuracy: 0.7603, Loss: 0.2035
Epoch   8 Batch  860/1077 - Train Accuracy: 0.7496, Validation Accuracy: 0.7802, Loss: 0.2139
Epoch   8 Batch  880/1077 - Train Accuracy: 0.8133, Validation Accuracy: 0.7656, Loss: 0.1990
Epoch   8 Batch  900/1077 - Train Accuracy: 0.8082, Validation Accuracy: 0.7351, Loss: 0.2152
Epoch   8 Batch  920/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7227, Loss: 0.2104
Epoch   8 Batch  940/1077 - Train Accuracy: 0.7727, Validation Accuracy: 0.7351, Loss: 0.1991
Epoch   8 Batch  960/1077 - Train Accuracy: 0.7768, Validation Accuracy: 0.7305, Loss: 0.1950
Epoch   8 Batch  980/1077 - Train Accuracy: 0.7574, Validation Accuracy: 0.7621, Loss: 0.2140
Epoch   8 Batch 1000/1077 - Train Accuracy: 0.8263, Validation Accuracy: 0.7532, Loss: 0.1865
Epoch   8 Batch 1020/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7628, Loss: 0.1903
Epoch   8 Batch 1040/1077 - Train Accuracy: 0.7722, Validation Accuracy: 0.7614, Loss: 0.2114
Epoch   8 Batch 1060/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7791, Loss: 0.1879
Epoch   9 Batch   20/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7564, Loss: 0.1948
Epoch   9 Batch   40/1077 - Train Accuracy: 0.7750, Validation Accuracy: 0.7333, Loss: 0.2003
Epoch   9 Batch   60/1077 - Train Accuracy: 0.7783, Validation Accuracy: 0.7649, Loss: 0.1917
Epoch   9 Batch   80/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7830, Loss: 0.2001
Epoch   9 Batch  100/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7518, Loss: 0.1983
Epoch   9 Batch  120/1077 - Train Accuracy: 0.7820, Validation Accuracy: 0.7784, Loss: 0.2102
Epoch   9 Batch  140/1077 - Train Accuracy: 0.8215, Validation Accuracy: 0.7809, Loss: 0.1888
Epoch   9 Batch  160/1077 - Train Accuracy: 0.8078, Validation Accuracy: 0.7884, Loss: 0.1944
Epoch   9 Batch  180/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7695, Loss: 0.1878
Epoch   9 Batch  200/1077 - Train Accuracy: 0.8016, Validation Accuracy: 0.7695, Loss: 0.1984
Epoch   9 Batch  220/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7770, Loss: 0.1997
Epoch   9 Batch  240/1077 - Train Accuracy: 0.8406, Validation Accuracy: 0.7511, Loss: 0.1705
Epoch   9 Batch  260/1077 - Train Accuracy: 0.8054, Validation Accuracy: 0.7724, Loss: 0.1737
Epoch   9 Batch  280/1077 - Train Accuracy: 0.8059, Validation Accuracy: 0.7610, Loss: 0.1883
Epoch   9 Batch  300/1077 - Train Accuracy: 0.8294, Validation Accuracy: 0.7670, Loss: 0.1726
Epoch   9 Batch  320/1077 - Train Accuracy: 0.8355, Validation Accuracy: 0.7926, Loss: 0.1817
Epoch   9 Batch  340/1077 - Train Accuracy: 0.8302, Validation Accuracy: 0.7621, Loss: 0.1779
Epoch   9 Batch  360/1077 - Train Accuracy: 0.7910, Validation Accuracy: 0.7717, Loss: 0.1703
Epoch   9 Batch  380/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7514, Loss: 0.1669
Epoch   9 Batch  400/1077 - Train Accuracy: 0.8012, Validation Accuracy: 0.7827, Loss: 0.2007
Epoch   9 Batch  420/1077 - Train Accuracy: 0.8695, Validation Accuracy: 0.7592, Loss: 0.1674
Epoch   9 Batch  440/1077 - Train Accuracy: 0.7781, Validation Accuracy: 0.7514, Loss: 0.2028
Epoch   9 Batch  460/1077 - Train Accuracy: 0.8422, Validation Accuracy: 0.7713, Loss: 0.1855
Epoch   9 Batch  480/1077 - Train Accuracy: 0.8232, Validation Accuracy: 0.7532, Loss: 0.1800
Epoch   9 Batch  500/1077 - Train Accuracy: 0.7840, Validation Accuracy: 0.7649, Loss: 0.1697
Epoch   9 Batch  520/1077 - Train Accuracy: 0.8508, Validation Accuracy: 0.7820, Loss: 0.1601
Epoch   9 Batch  540/1077 - Train Accuracy: 0.8121, Validation Accuracy: 0.7440, Loss: 0.1633
Epoch   9 Batch  560/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.7670, Loss: 0.1761
Epoch   9 Batch  580/1077 - Train Accuracy: 0.8408, Validation Accuracy: 0.7763, Loss: 0.1574
Epoch   9 Batch  600/1077 - Train Accuracy: 0.8545, Validation Accuracy: 0.7862, Loss: 0.1621
Epoch   9 Batch  620/1077 - Train Accuracy: 0.8500, Validation Accuracy: 0.7710, Loss: 0.1610
Epoch   9 Batch  640/1077 - Train Accuracy: 0.7965, Validation Accuracy: 0.7798, Loss: 0.1682
Epoch   9 Batch  660/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7653, Loss: 0.1782
Epoch   9 Batch  680/1077 - Train Accuracy: 0.7876, Validation Accuracy: 0.7809, Loss: 0.1803
Epoch   9 Batch  700/1077 - Train Accuracy: 0.8148, Validation Accuracy: 0.7638, Loss: 0.1523
Epoch   9 Batch  720/1077 - Train Accuracy: 0.7940, Validation Accuracy: 0.8036, Loss: 0.2039
Epoch   9 Batch  740/1077 - Train Accuracy: 0.8293, Validation Accuracy: 0.7773, Loss: 0.1528
Epoch   9 Batch  760/1077 - Train Accuracy: 0.8301, Validation Accuracy: 0.7741, Loss: 0.1788
Epoch   9 Batch  780/1077 - Train Accuracy: 0.7980, Validation Accuracy: 0.7678, Loss: 0.1809
Epoch   9 Batch  800/1077 - Train Accuracy: 0.8379, Validation Accuracy: 0.7844, Loss: 0.1644
Epoch   9 Batch  820/1077 - Train Accuracy: 0.7594, Validation Accuracy: 0.7873, Loss: 0.1847
Epoch   9 Batch  840/1077 - Train Accuracy: 0.8352, Validation Accuracy: 0.7837, Loss: 0.1638
Epoch   9 Batch  860/1077 - Train Accuracy: 0.8077, Validation Accuracy: 0.8018, Loss: 0.1741
Epoch   9 Batch  880/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.7905, Loss: 0.1584
Epoch   9 Batch  900/1077 - Train Accuracy: 0.8461, Validation Accuracy: 0.7798, Loss: 0.1783
Epoch   9 Batch  920/1077 - Train Accuracy: 0.8238, Validation Accuracy: 0.7905, Loss: 0.1738
Epoch   9 Batch  940/1077 - Train Accuracy: 0.8430, Validation Accuracy: 0.7876, Loss: 0.1572
Epoch   9 Batch  960/1077 - Train Accuracy: 0.8166, Validation Accuracy: 0.7798, Loss: 0.1545
Epoch   9 Batch  980/1077 - Train Accuracy: 0.7891, Validation Accuracy: 0.7844, Loss: 0.1743
Epoch   9 Batch 1000/1077 - Train Accuracy: 0.8531, Validation Accuracy: 0.7699, Loss: 0.1526
Epoch   9 Batch 1020/1077 - Train Accuracy: 0.8570, Validation Accuracy: 0.7958, Loss: 0.1469
Epoch   9 Batch 1040/1077 - Train Accuracy: 0.8207, Validation Accuracy: 0.7891, Loss: 0.1696
Epoch   9 Batch 1060/1077 - Train Accuracy: 0.8137, Validation Accuracy: 0.7912, Loss: 0.1439
Epoch  10 Batch   20/1077 - Train Accuracy: 0.8199, Validation Accuracy: 0.8161, Loss: 0.1552
Epoch  10 Batch   40/1077 - Train Accuracy: 0.8297, Validation Accuracy: 0.7926, Loss: 0.1534
Epoch  10 Batch   60/1077 - Train Accuracy: 0.8207, Validation Accuracy: 0.7947, Loss: 0.1537
Epoch  10 Batch   80/1077 - Train Accuracy: 0.8535, Validation Accuracy: 0.7955, Loss: 0.1579
Epoch  10 Batch  100/1077 - Train Accuracy: 0.8539, Validation Accuracy: 0.8043, Loss: 0.1576
Epoch  10 Batch  120/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8107, Loss: 0.1694
Epoch  10 Batch  140/1077 - Train Accuracy: 0.8664, Validation Accuracy: 0.7887, Loss: 0.1488
Epoch  10 Batch  160/1077 - Train Accuracy: 0.8344, Validation Accuracy: 0.8018, Loss: 0.1528
Epoch  10 Batch  180/1077 - Train Accuracy: 0.8438, Validation Accuracy: 0.7937, Loss: 0.1499
Epoch  10 Batch  200/1077 - Train Accuracy: 0.8289, Validation Accuracy: 0.8026, Loss: 0.1597
Epoch  10 Batch  220/1077 - Train Accuracy: 0.8651, Validation Accuracy: 0.8121, Loss: 0.1619
Epoch  10 Batch  240/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8029, Loss: 0.1332
Epoch  10 Batch  260/1077 - Train Accuracy: 0.8438, Validation Accuracy: 0.8111, Loss: 0.1345
Epoch  10 Batch  280/1077 - Train Accuracy: 0.8383, Validation Accuracy: 0.7962, Loss: 0.1490
Epoch  10 Batch  300/1077 - Train Accuracy: 0.8635, Validation Accuracy: 0.7926, Loss: 0.1351
Epoch  10 Batch  320/1077 - Train Accuracy: 0.8711, Validation Accuracy: 0.8043, Loss: 0.1466
Epoch  10 Batch  340/1077 - Train Accuracy: 0.8771, Validation Accuracy: 0.7990, Loss: 0.1417
Epoch  10 Batch  360/1077 - Train Accuracy: 0.8445, Validation Accuracy: 0.7983, Loss: 0.1386
Epoch  10 Batch  380/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.7766, Loss: 0.1320
Epoch  10 Batch  400/1077 - Train Accuracy: 0.8410, Validation Accuracy: 0.7944, Loss: 0.1653
Epoch  10 Batch  420/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.7912, Loss: 0.1324
Epoch  10 Batch  440/1077 - Train Accuracy: 0.7984, Validation Accuracy: 0.8008, Loss: 0.1728
Epoch  10 Batch  460/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.7983, Loss: 0.1511
Epoch  10 Batch  480/1077 - Train Accuracy: 0.8569, Validation Accuracy: 0.7965, Loss: 0.1485
Epoch  10 Batch  500/1077 - Train Accuracy: 0.8633, Validation Accuracy: 0.7983, Loss: 0.1310
Epoch  10 Batch  520/1077 - Train Accuracy: 0.8795, Validation Accuracy: 0.8146, Loss: 0.1272
Epoch  10 Batch  540/1077 - Train Accuracy: 0.8328, Validation Accuracy: 0.7873, Loss: 0.1284
Epoch  10 Batch  560/1077 - Train Accuracy: 0.8348, Validation Accuracy: 0.7873, Loss: 0.1447
Epoch  10 Batch  580/1077 - Train Accuracy: 0.8702, Validation Accuracy: 0.8068, Loss: 0.1282
Epoch  10 Batch  600/1077 - Train Accuracy: 0.8709, Validation Accuracy: 0.8107, Loss: 0.1337
Epoch  10 Batch  620/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.7901, Loss: 0.1318
Epoch  10 Batch  640/1077 - Train Accuracy: 0.8363, Validation Accuracy: 0.8015, Loss: 0.1336
Epoch  10 Batch  660/1077 - Train Accuracy: 0.8707, Validation Accuracy: 0.7695, Loss: 0.1447
Epoch  10 Batch  680/1077 - Train Accuracy: 0.8047, Validation Accuracy: 0.8050, Loss: 0.1506
Epoch  10 Batch  700/1077 - Train Accuracy: 0.8527, Validation Accuracy: 0.7855, Loss: 0.1214
Epoch  10 Batch  720/1077 - Train Accuracy: 0.8326, Validation Accuracy: 0.8242, Loss: 0.1724
Epoch  10 Batch  740/1077 - Train Accuracy: 0.8457, Validation Accuracy: 0.7990, Loss: 0.1247
Epoch  10 Batch  760/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8011, Loss: 0.1508
Epoch  10 Batch  780/1077 - Train Accuracy: 0.8289, Validation Accuracy: 0.7873, Loss: 0.1513
Epoch  10 Batch  800/1077 - Train Accuracy: 0.8695, Validation Accuracy: 0.8260, Loss: 0.1317
Epoch  10 Batch  820/1077 - Train Accuracy: 0.8109, Validation Accuracy: 0.8114, Loss: 0.1505
Epoch  10 Batch  840/1077 - Train Accuracy: 0.8445, Validation Accuracy: 0.8089, Loss: 0.1330
Epoch  10 Batch  860/1077 - Train Accuracy: 0.8300, Validation Accuracy: 0.8093, Loss: 0.1463
Epoch  10 Batch  880/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.7962, Loss: 0.1334
Epoch  10 Batch  900/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8118, Loss: 0.1465
Epoch  10 Batch  920/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8136, Loss: 0.1474
Epoch  10 Batch  940/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.7830, Loss: 0.1251
Epoch  10 Batch  960/1077 - Train Accuracy: 0.8400, Validation Accuracy: 0.8011, Loss: 0.1267
Epoch  10 Batch  980/1077 - Train Accuracy: 0.8313, Validation Accuracy: 0.7976, Loss: 0.1462
Epoch  10 Batch 1000/1077 - Train Accuracy: 0.8798, Validation Accuracy: 0.8008, Loss: 0.1276
Epoch  10 Batch 1020/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8232, Loss: 0.1190
Epoch  10 Batch 1040/1077 - Train Accuracy: 0.8618, Validation Accuracy: 0.8153, Loss: 0.1376
Epoch  10 Batch 1060/1077 - Train Accuracy: 0.8641, Validation Accuracy: 0.7958, Loss: 0.1156
Epoch  11 Batch   20/1077 - Train Accuracy: 0.8555, Validation Accuracy: 0.8221, Loss: 0.1256
Epoch  11 Batch   40/1077 - Train Accuracy: 0.8770, Validation Accuracy: 0.8224, Loss: 0.1226
Epoch  11 Batch   60/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8146, Loss: 0.1282
Epoch  11 Batch   80/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8121, Loss: 0.1284
Epoch  11 Batch  100/1077 - Train Accuracy: 0.8539, Validation Accuracy: 0.8295, Loss: 0.1278
Epoch  11 Batch  120/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.8501, Loss: 0.1388
Epoch  11 Batch  140/1077 - Train Accuracy: 0.9038, Validation Accuracy: 0.8235, Loss: 0.1210
Epoch  11 Batch  160/1077 - Train Accuracy: 0.8441, Validation Accuracy: 0.8320, Loss: 0.1259
Epoch  11 Batch  180/1077 - Train Accuracy: 0.8648, Validation Accuracy: 0.8246, Loss: 0.1225
Epoch  11 Batch  200/1077 - Train Accuracy: 0.8246, Validation Accuracy: 0.8374, Loss: 0.1320
Epoch  11 Batch  220/1077 - Train Accuracy: 0.8721, Validation Accuracy: 0.8253, Loss: 0.1354
Epoch  11 Batch  240/1077 - Train Accuracy: 0.8809, Validation Accuracy: 0.8267, Loss: 0.1096
Epoch  11 Batch  260/1077 - Train Accuracy: 0.8750, Validation Accuracy: 0.8295, Loss: 0.1103
Epoch  11 Batch  280/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8175, Loss: 0.1252
Epoch  11 Batch  300/1077 - Train Accuracy: 0.8705, Validation Accuracy: 0.8136, Loss: 0.1088
Epoch  11 Batch  320/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8377, Loss: 0.1237
Epoch  11 Batch  340/1077 - Train Accuracy: 0.9013, Validation Accuracy: 0.8196, Loss: 0.1155
Epoch  11 Batch  360/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8395, Loss: 0.1139
Epoch  11 Batch  380/1077 - Train Accuracy: 0.8910, Validation Accuracy: 0.8118, Loss: 0.1073
Epoch  11 Batch  400/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8210, Loss: 0.1350
Epoch  11 Batch  420/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.8100, Loss: 0.1083
Epoch  11 Batch  440/1077 - Train Accuracy: 0.8102, Validation Accuracy: 0.8200, Loss: 0.1455
Epoch  11 Batch  460/1077 - Train Accuracy: 0.8895, Validation Accuracy: 0.8153, Loss: 0.1276
Epoch  11 Batch  480/1077 - Train Accuracy: 0.8660, Validation Accuracy: 0.8210, Loss: 0.1252
Epoch  11 Batch  500/1077 - Train Accuracy: 0.8867, Validation Accuracy: 0.8285, Loss: 0.1066
Epoch  11 Batch  520/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8299, Loss: 0.1052
Epoch  11 Batch  540/1077 - Train Accuracy: 0.8656, Validation Accuracy: 0.8256, Loss: 0.1048
Epoch  11 Batch  560/1077 - Train Accuracy: 0.8637, Validation Accuracy: 0.8256, Loss: 0.1165
Epoch  11 Batch  580/1077 - Train Accuracy: 0.8780, Validation Accuracy: 0.8519, Loss: 0.1095
Epoch  11 Batch  600/1077 - Train Accuracy: 0.8884, Validation Accuracy: 0.8409, Loss: 0.1132
Epoch  11 Batch  620/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8324, Loss: 0.1078
Epoch  11 Batch  640/1077 - Train Accuracy: 0.8601, Validation Accuracy: 0.8434, Loss: 0.1106
Epoch  11 Batch  660/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8054, Loss: 0.1209
Epoch  11 Batch  680/1077 - Train Accuracy: 0.8348, Validation Accuracy: 0.8228, Loss: 0.1297
Epoch  11 Batch  700/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8189, Loss: 0.1028
Epoch  11 Batch  720/1077 - Train Accuracy: 0.8573, Validation Accuracy: 0.8438, Loss: 0.1376
Epoch  11 Batch  740/1077 - Train Accuracy: 0.8867, Validation Accuracy: 0.8366, Loss: 0.1033
Epoch  11 Batch  760/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.8256, Loss: 0.1235
Epoch  11 Batch  780/1077 - Train Accuracy: 0.8445, Validation Accuracy: 0.8356, Loss: 0.1293
Epoch  11 Batch  800/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8612, Loss: 0.1089
Epoch  11 Batch  820/1077 - Train Accuracy: 0.8301, Validation Accuracy: 0.8494, Loss: 0.1266
Epoch  11 Batch  840/1077 - Train Accuracy: 0.8746, Validation Accuracy: 0.8292, Loss: 0.1118
Epoch  11 Batch  860/1077 - Train Accuracy: 0.8415, Validation Accuracy: 0.8494, Loss: 0.1255
Epoch  11 Batch  880/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8331, Loss: 0.1137
Epoch  11 Batch  900/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8281, Loss: 0.1231
Epoch  11 Batch  920/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8331, Loss: 0.1249
Epoch  11 Batch  940/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8139, Loss: 0.1055
Epoch  11 Batch  960/1077 - Train Accuracy: 0.8702, Validation Accuracy: 0.8317, Loss: 0.1073
Epoch  11 Batch  980/1077 - Train Accuracy: 0.8211, Validation Accuracy: 0.8370, Loss: 0.1253
Epoch  11 Batch 1000/1077 - Train Accuracy: 0.8940, Validation Accuracy: 0.8327, Loss: 0.1080
Epoch  11 Batch 1020/1077 - Train Accuracy: 0.8840, Validation Accuracy: 0.8381, Loss: 0.0998
Epoch  11 Batch 1040/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8466, Loss: 0.1154
Epoch  11 Batch 1060/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8263, Loss: 0.0955
Epoch  12 Batch   20/1077 - Train Accuracy: 0.8570, Validation Accuracy: 0.8381, Loss: 0.1040
Epoch  12 Batch   40/1077 - Train Accuracy: 0.9109, Validation Accuracy: 0.8327, Loss: 0.1021
Epoch  12 Batch   60/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8356, Loss: 0.1048
Epoch  12 Batch   80/1077 - Train Accuracy: 0.9031, Validation Accuracy: 0.8409, Loss: 0.1079
Epoch  12 Batch  100/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.8540, Loss: 0.1079
Epoch  12 Batch  120/1077 - Train Accuracy: 0.9164, Validation Accuracy: 0.8487, Loss: 0.1177
Epoch  12 Batch  140/1077 - Train Accuracy: 0.9198, Validation Accuracy: 0.8462, Loss: 0.1008
Epoch  12 Batch  160/1077 - Train Accuracy: 0.8648, Validation Accuracy: 0.8452, Loss: 0.1061
Epoch  12 Batch  180/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8469, Loss: 0.1018
Epoch  12 Batch  200/1077 - Train Accuracy: 0.8500, Validation Accuracy: 0.8416, Loss: 0.1121
Epoch  12 Batch  220/1077 - Train Accuracy: 0.8890, Validation Accuracy: 0.8594, Loss: 0.1182
Epoch  12 Batch  240/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8413, Loss: 0.0904
Epoch  12 Batch  260/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8569, Loss: 0.0914
Epoch  12 Batch  280/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8203, Loss: 0.1049
Epoch  12 Batch  300/1077 - Train Accuracy: 0.8791, Validation Accuracy: 0.8253, Loss: 0.0895
Epoch  12 Batch  320/1077 - Train Accuracy: 0.8969, Validation Accuracy: 0.8516, Loss: 0.1049
Epoch  12 Batch  340/1077 - Train Accuracy: 0.9215, Validation Accuracy: 0.8303, Loss: 0.0975
Epoch  12 Batch  360/1077 - Train Accuracy: 0.9027, Validation Accuracy: 0.8505, Loss: 0.0954
Epoch  12 Batch  380/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8317, Loss: 0.0898
Epoch  12 Batch  400/1077 - Train Accuracy: 0.8770, Validation Accuracy: 0.8271, Loss: 0.1178
Epoch  12 Batch  420/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.8331, Loss: 0.0922
Epoch  12 Batch  440/1077 - Train Accuracy: 0.8328, Validation Accuracy: 0.8207, Loss: 0.1251
Epoch  12 Batch  460/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8235, Loss: 0.1104
Epoch  12 Batch  480/1077 - Train Accuracy: 0.8775, Validation Accuracy: 0.8274, Loss: 0.1063
Epoch  12 Batch  500/1077 - Train Accuracy: 0.8949, Validation Accuracy: 0.8413, Loss: 0.0876
Epoch  12 Batch  520/1077 - Train Accuracy: 0.9100, Validation Accuracy: 0.8420, Loss: 0.0903
Epoch  12 Batch  540/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.8249, Loss: 0.0875
Epoch  12 Batch  560/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8324, Loss: 0.0962
Epoch  12 Batch  580/1077 - Train Accuracy: 0.8817, Validation Accuracy: 0.8572, Loss: 0.0879
Epoch  12 Batch  600/1077 - Train Accuracy: 0.9025, Validation Accuracy: 0.8438, Loss: 0.0932
Epoch  12 Batch  620/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8274, Loss: 0.0920
Epoch  12 Batch  640/1077 - Train Accuracy: 0.8624, Validation Accuracy: 0.8370, Loss: 0.0928
Epoch  12 Batch  660/1077 - Train Accuracy: 0.8922, Validation Accuracy: 0.8327, Loss: 0.1005
Epoch  12 Batch  680/1077 - Train Accuracy: 0.8464, Validation Accuracy: 0.8324, Loss: 0.1102
Epoch  12 Batch  700/1077 - Train Accuracy: 0.8953, Validation Accuracy: 0.8210, Loss: 0.0850
Epoch  12 Batch  720/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8438, Loss: 0.1146
Epoch  12 Batch  740/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8377, Loss: 0.0840
Epoch  12 Batch  760/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8299, Loss: 0.1042
Epoch  12 Batch  780/1077 - Train Accuracy: 0.8586, Validation Accuracy: 0.8430, Loss: 0.1117
Epoch  12 Batch  800/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8533, Loss: 0.0907
Epoch  12 Batch  820/1077 - Train Accuracy: 0.8309, Validation Accuracy: 0.8512, Loss: 0.1064
Epoch  12 Batch  840/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8349, Loss: 0.0935
Epoch  12 Batch  860/1077 - Train Accuracy: 0.8583, Validation Accuracy: 0.8462, Loss: 0.1104
Epoch  12 Batch  880/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8363, Loss: 0.0972
Epoch  12 Batch  900/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8352, Loss: 0.1080
Epoch  12 Batch  920/1077 - Train Accuracy: 0.8848, Validation Accuracy: 0.8445, Loss: 0.1063
Epoch  12 Batch  940/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8288, Loss: 0.0911
Epoch  12 Batch  960/1077 - Train Accuracy: 0.8810, Validation Accuracy: 0.8466, Loss: 0.0937
Epoch  12 Batch  980/1077 - Train Accuracy: 0.8340, Validation Accuracy: 0.8473, Loss: 0.1101
Epoch  12 Batch 1000/1077 - Train Accuracy: 0.8981, Validation Accuracy: 0.8537, Loss: 0.0953
Epoch  12 Batch 1020/1077 - Train Accuracy: 0.8918, Validation Accuracy: 0.8381, Loss: 0.0842
Epoch  12 Batch 1040/1077 - Train Accuracy: 0.9054, Validation Accuracy: 0.8366, Loss: 0.0964
Epoch  12 Batch 1060/1077 - Train Accuracy: 0.8770, Validation Accuracy: 0.8232, Loss: 0.0826
Epoch  13 Batch   20/1077 - Train Accuracy: 0.8645, Validation Accuracy: 0.8484, Loss: 0.0894
Epoch  13 Batch   40/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.8423, Loss: 0.0877
Epoch  13 Batch   60/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.8505, Loss: 0.0870
Epoch  13 Batch   80/1077 - Train Accuracy: 0.9176, Validation Accuracy: 0.8512, Loss: 0.0939
Epoch  13 Batch  100/1077 - Train Accuracy: 0.8793, Validation Accuracy: 0.8633, Loss: 0.0909
Epoch  13 Batch  120/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.8320, Loss: 0.1012
Epoch  13 Batch  140/1077 - Train Accuracy: 0.9215, Validation Accuracy: 0.8445, Loss: 0.0839
Epoch  13 Batch  160/1077 - Train Accuracy: 0.8805, Validation Accuracy: 0.8462, Loss: 0.0903
Epoch  13 Batch  180/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8501, Loss: 0.0855
Epoch  13 Batch  200/1077 - Train Accuracy: 0.8609, Validation Accuracy: 0.8455, Loss: 0.0930
Epoch  13 Batch  220/1077 - Train Accuracy: 0.8972, Validation Accuracy: 0.8643, Loss: 0.1048
Epoch  13 Batch  240/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.8462, Loss: 0.0745
Epoch  13 Batch  260/1077 - Train Accuracy: 0.9022, Validation Accuracy: 0.8409, Loss: 0.0772
Epoch  13 Batch  280/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.8310, Loss: 0.0898
Epoch  13 Batch  300/1077 - Train Accuracy: 0.9046, Validation Accuracy: 0.8395, Loss: 0.0751
Epoch  13 Batch  320/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8473, Loss: 0.0914
Epoch  13 Batch  340/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.8331, Loss: 0.0794
Epoch  13 Batch  360/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.8551, Loss: 0.0796
Epoch  13 Batch  380/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8438, Loss: 0.0756
Epoch  13 Batch  400/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8288, Loss: 0.1019
Epoch  13 Batch  420/1077 - Train Accuracy: 0.9340, Validation Accuracy: 0.8526, Loss: 0.0772
Epoch  13 Batch  440/1077 - Train Accuracy: 0.8547, Validation Accuracy: 0.8338, Loss: 0.1097
Epoch  13 Batch  460/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8271, Loss: 0.0941
Epoch  13 Batch  480/1077 - Train Accuracy: 0.8701, Validation Accuracy: 0.8285, Loss: 0.0888
Epoch  13 Batch  500/1077 - Train Accuracy: 0.9082, Validation Accuracy: 0.8377, Loss: 0.0726
Epoch  13 Batch  520/1077 - Train Accuracy: 0.9193, Validation Accuracy: 0.8555, Loss: 0.0781
Epoch  13 Batch  540/1077 - Train Accuracy: 0.8980, Validation Accuracy: 0.8391, Loss: 0.0735
Epoch  13 Batch  560/1077 - Train Accuracy: 0.8934, Validation Accuracy: 0.8434, Loss: 0.0796
Epoch  13 Batch  580/1077 - Train Accuracy: 0.9033, Validation Accuracy: 0.8448, Loss: 0.0734
Epoch  13 Batch  600/1077 - Train Accuracy: 0.9163, Validation Accuracy: 0.8505, Loss: 0.0797
Epoch  13 Batch  620/1077 - Train Accuracy: 0.8926, Validation Accuracy: 0.8434, Loss: 0.0793
Epoch  13 Batch  640/1077 - Train Accuracy: 0.8847, Validation Accuracy: 0.8580, Loss: 0.0775
Epoch  13 Batch  660/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.8413, Loss: 0.0842
Epoch  13 Batch  680/1077 - Train Accuracy: 0.8367, Validation Accuracy: 0.8540, Loss: 0.0926
Epoch  13 Batch  700/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.8409, Loss: 0.0707
Epoch  13 Batch  720/1077 - Train Accuracy: 0.9038, Validation Accuracy: 0.8477, Loss: 0.0973
Epoch  13 Batch  740/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.8445, Loss: 0.0715
Epoch  13 Batch  760/1077 - Train Accuracy: 0.9035, Validation Accuracy: 0.8324, Loss: 0.0900
Epoch  13 Batch  780/1077 - Train Accuracy: 0.8734, Validation Accuracy: 0.8487, Loss: 0.0965
Epoch  13 Batch  800/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8597, Loss: 0.0760
Epoch  13 Batch  820/1077 - Train Accuracy: 0.8539, Validation Accuracy: 0.8420, Loss: 0.0881
Epoch  13 Batch  840/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8494, Loss: 0.0797
Epoch  13 Batch  860/1077 - Train Accuracy: 0.8925, Validation Accuracy: 0.8445, Loss: 0.0970
Epoch  13 Batch  880/1077 - Train Accuracy: 0.9215, Validation Accuracy: 0.8388, Loss: 0.0823
Epoch  13 Batch  900/1077 - Train Accuracy: 0.9242, Validation Accuracy: 0.8494, Loss: 0.0952
Epoch  13 Batch  920/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8562, Loss: 0.0898
Epoch  13 Batch  940/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.8370, Loss: 0.0784
Epoch  13 Batch  960/1077 - Train Accuracy: 0.8776, Validation Accuracy: 0.8491, Loss: 0.0781
Epoch  13 Batch  980/1077 - Train Accuracy: 0.8520, Validation Accuracy: 0.8434, Loss: 0.0956
Epoch  13 Batch 1000/1077 - Train Accuracy: 0.8728, Validation Accuracy: 0.8572, Loss: 0.0808
Epoch  13 Batch 1020/1077 - Train Accuracy: 0.8930, Validation Accuracy: 0.8430, Loss: 0.0740
Epoch  13 Batch 1040/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8548, Loss: 0.0824
Epoch  13 Batch 1060/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8274, Loss: 0.0728
Epoch  14 Batch   20/1077 - Train Accuracy: 0.8844, Validation Accuracy: 0.8509, Loss: 0.0745
Epoch  14 Batch   40/1077 - Train Accuracy: 0.9191, Validation Accuracy: 0.8477, Loss: 0.0728
Epoch  14 Batch   60/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8505, Loss: 0.0725
Epoch  14 Batch   80/1077 - Train Accuracy: 0.9258, Validation Accuracy: 0.8661, Loss: 0.0773
Epoch  14 Batch  100/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8540, Loss: 0.0747
Epoch  14 Batch  120/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.8548, Loss: 0.0846
Epoch  14 Batch  140/1077 - Train Accuracy: 0.9354, Validation Accuracy: 0.8491, Loss: 0.0694
Epoch  14 Batch  160/1077 - Train Accuracy: 0.8809, Validation Accuracy: 0.8377, Loss: 0.0766
Epoch  14 Batch  180/1077 - Train Accuracy: 0.9199, Validation Accuracy: 0.8604, Loss: 0.0734
Epoch  14 Batch  200/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8526, Loss: 0.0779
Epoch  14 Batch  220/1077 - Train Accuracy: 0.9182, Validation Accuracy: 0.8739, Loss: 0.0922
Epoch  14 Batch  240/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.8402, Loss: 0.0624
Epoch  14 Batch  260/1077 - Train Accuracy: 0.9029, Validation Accuracy: 0.8558, Loss: 0.0663
Epoch  14 Batch  280/1077 - Train Accuracy: 0.8836, Validation Accuracy: 0.8423, Loss: 0.0768
Epoch  14 Batch  300/1077 - Train Accuracy: 0.9100, Validation Accuracy: 0.8484, Loss: 0.0652
Epoch  14 Batch  320/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.8480, Loss: 0.0793
Epoch  14 Batch  340/1077 - Train Accuracy: 0.9396, Validation Accuracy: 0.8391, Loss: 0.0716
Epoch  14 Batch  360/1077 - Train Accuracy: 0.9187, Validation Accuracy: 0.8718, Loss: 0.0677
Epoch  14 Batch  380/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.8445, Loss: 0.0642
Epoch  14 Batch  400/1077 - Train Accuracy: 0.8812, Validation Accuracy: 0.8452, Loss: 0.0883
Epoch  14 Batch  420/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.8594, Loss: 0.0650
Epoch  14 Batch  440/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8459, Loss: 0.0969
Epoch  14 Batch  460/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.8413, Loss: 0.0809
Epoch  14 Batch  480/1077 - Train Accuracy: 0.8960, Validation Accuracy: 0.8406, Loss: 0.0772
Epoch  14 Batch  500/1077 - Train Accuracy: 0.9273, Validation Accuracy: 0.8530, Loss: 0.0625
Epoch  14 Batch  520/1077 - Train Accuracy: 0.9330, Validation Accuracy: 0.8469, Loss: 0.0671
Epoch  14 Batch  540/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.8466, Loss: 0.0636
Epoch  14 Batch  560/1077 - Train Accuracy: 0.8926, Validation Accuracy: 0.8395, Loss: 0.0681
Epoch  14 Batch  580/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8413, Loss: 0.0598
Epoch  14 Batch  600/1077 - Train Accuracy: 0.9182, Validation Accuracy: 0.8594, Loss: 0.0687
Epoch  14 Batch  620/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8374, Loss: 0.0677
Epoch  14 Batch  640/1077 - Train Accuracy: 0.8906, Validation Accuracy: 0.8430, Loss: 0.0667
Epoch  14 Batch  660/1077 - Train Accuracy: 0.9250, Validation Accuracy: 0.8526, Loss: 0.0724
Epoch  14 Batch  680/1077 - Train Accuracy: 0.8657, Validation Accuracy: 0.8342, Loss: 0.0757
Epoch  14 Batch  700/1077 - Train Accuracy: 0.9207, Validation Accuracy: 0.8462, Loss: 0.0596
Epoch  14 Batch  720/1077 - Train Accuracy: 0.9054, Validation Accuracy: 0.8576, Loss: 0.0804
Epoch  14 Batch  740/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8317, Loss: 0.0638
Epoch  14 Batch  760/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.8409, Loss: 0.0780
Epoch  14 Batch  780/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8576, Loss: 0.0834
Epoch  14 Batch  800/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8700, Loss: 0.0646
Epoch  14 Batch  820/1077 - Train Accuracy: 0.8574, Validation Accuracy: 0.8384, Loss: 0.0744
Epoch  14 Batch  840/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8498, Loss: 0.0698
Epoch  14 Batch  860/1077 - Train Accuracy: 0.9040, Validation Accuracy: 0.8452, Loss: 0.0846
Epoch  14 Batch  880/1077 - Train Accuracy: 0.9262, Validation Accuracy: 0.8576, Loss: 0.0706
Epoch  14 Batch  900/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.8608, Loss: 0.0806
Epoch  14 Batch  920/1077 - Train Accuracy: 0.9090, Validation Accuracy: 0.8565, Loss: 0.0756
Epoch  14 Batch  940/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8423, Loss: 0.0694
Epoch  14 Batch  960/1077 - Train Accuracy: 0.8966, Validation Accuracy: 0.8537, Loss: 0.0674
Epoch  14 Batch  980/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.8540, Loss: 0.0834
Epoch  14 Batch 1000/1077 - Train Accuracy: 0.8839, Validation Accuracy: 0.8501, Loss: 0.0726
Epoch  14 Batch 1020/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8384, Loss: 0.0627
Epoch  14 Batch 1040/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8750, Loss: 0.0706
Epoch  14 Batch 1060/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.8523, Loss: 0.0651
Epoch  15 Batch   20/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8406, Loss: 0.0629
Epoch  15 Batch   40/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.8398, Loss: 0.0636
Epoch  15 Batch   60/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8512, Loss: 0.0613
Epoch  15 Batch   80/1077 - Train Accuracy: 0.9363, Validation Accuracy: 0.8757, Loss: 0.0673
Epoch  15 Batch  100/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8654, Loss: 0.0625
Epoch  15 Batch  120/1077 - Train Accuracy: 0.9223, Validation Accuracy: 0.8612, Loss: 0.0762
Epoch  15 Batch  140/1077 - Train Accuracy: 0.9346, Validation Accuracy: 0.8477, Loss: 0.0578
Epoch  15 Batch  160/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8438, Loss: 0.0677
Epoch  15 Batch  180/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8661, Loss: 0.0633
Epoch  15 Batch  200/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.8576, Loss: 0.0672
Epoch  15 Batch  220/1077 - Train Accuracy: 0.9248, Validation Accuracy: 0.8761, Loss: 0.0805
Epoch  15 Batch  240/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.8612, Loss: 0.0532
Epoch  15 Batch  260/1077 - Train Accuracy: 0.9048, Validation Accuracy: 0.8494, Loss: 0.0571
Epoch  15 Batch  280/1077 - Train Accuracy: 0.8855, Validation Accuracy: 0.8434, Loss: 0.0662
Epoch  15 Batch  300/1077 - Train Accuracy: 0.9178, Validation Accuracy: 0.8615, Loss: 0.0584
Epoch  15 Batch  320/1077 - Train Accuracy: 0.9340, Validation Accuracy: 0.8626, Loss: 0.0641
Epoch  15 Batch  340/1077 - Train Accuracy: 0.9400, Validation Accuracy: 0.8327, Loss: 0.0568
Epoch  15 Batch  360/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.8594, Loss: 0.0565
Epoch  15 Batch  380/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.8519, Loss: 0.0540
Epoch  15 Batch  400/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8409, Loss: 0.0791
Epoch  15 Batch  420/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.8455, Loss: 0.0545
Epoch  15 Batch  440/1077 - Train Accuracy: 0.8957, Validation Accuracy: 0.8498, Loss: 0.0803
Epoch  15 Batch  460/1077 - Train Accuracy: 0.9180, Validation Accuracy: 0.8516, Loss: 0.0743
Epoch  15 Batch  480/1077 - Train Accuracy: 0.9067, Validation Accuracy: 0.8491, Loss: 0.0660
Epoch  15 Batch  500/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.8430, Loss: 0.0554
Epoch  15 Batch  520/1077 - Train Accuracy: 0.9490, Validation Accuracy: 0.8427, Loss: 0.0584
Epoch  15 Batch  540/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8526, Loss: 0.0548
Epoch  15 Batch  560/1077 - Train Accuracy: 0.8973, Validation Accuracy: 0.8583, Loss: 0.0589
Epoch  15 Batch  580/1077 - Train Accuracy: 0.9256, Validation Accuracy: 0.8572, Loss: 0.0515
Epoch  15 Batch  600/1077 - Train Accuracy: 0.9312, Validation Accuracy: 0.8516, Loss: 0.0586
Epoch  15 Batch  620/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.8544, Loss: 0.0563
Epoch  15 Batch  640/1077 - Train Accuracy: 0.9003, Validation Accuracy: 0.8391, Loss: 0.0570
Epoch  15 Batch  660/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8590, Loss: 0.0637
Epoch  15 Batch  680/1077 - Train Accuracy: 0.8776, Validation Accuracy: 0.8509, Loss: 0.0656
Epoch  15 Batch  700/1077 - Train Accuracy: 0.9180, Validation Accuracy: 0.8537, Loss: 0.0524
Epoch  15 Batch  720/1077 - Train Accuracy: 0.9108, Validation Accuracy: 0.8643, Loss: 0.0658
Epoch  15 Batch  740/1077 - Train Accuracy: 0.9082, Validation Accuracy: 0.8569, Loss: 0.0559
Epoch  15 Batch  760/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.8640, Loss: 0.0659
Epoch  15 Batch  780/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8643, Loss: 0.0737
Epoch  15 Batch  800/1077 - Train Accuracy: 0.9164, Validation Accuracy: 0.8711, Loss: 0.0574
Epoch  15 Batch  820/1077 - Train Accuracy: 0.8719, Validation Accuracy: 0.8509, Loss: 0.0664
Epoch  15 Batch  840/1077 - Train Accuracy: 0.9187, Validation Accuracy: 0.8608, Loss: 0.0594
Epoch  15 Batch  860/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8622, Loss: 0.0753
Epoch  15 Batch  880/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.8629, Loss: 0.0630
Epoch  15 Batch  900/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.8626, Loss: 0.0715
Epoch  15 Batch  920/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8626, Loss: 0.0639
Epoch  15 Batch  940/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.8704, Loss: 0.0628
Epoch  15 Batch  960/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8501, Loss: 0.0582
Epoch  15 Batch  980/1077 - Train Accuracy: 0.8777, Validation Accuracy: 0.8675, Loss: 0.0723
Epoch  15 Batch 1000/1077 - Train Accuracy: 0.8891, Validation Accuracy: 0.8505, Loss: 0.0627
Epoch  15 Batch 1020/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8512, Loss: 0.0547
Epoch  15 Batch 1040/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.8714, Loss: 0.0624
Epoch  15 Batch 1060/1077 - Train Accuracy: 0.9207, Validation Accuracy: 0.8509, Loss: 0.0579
Epoch  16 Batch   20/1077 - Train Accuracy: 0.9086, Validation Accuracy: 0.8629, Loss: 0.0552
Epoch  16 Batch   40/1077 - Train Accuracy: 0.9352, Validation Accuracy: 0.8551, Loss: 0.0553
Epoch  16 Batch   60/1077 - Train Accuracy: 0.9036, Validation Accuracy: 0.8551, Loss: 0.0525
Epoch  16 Batch   80/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.8690, Loss: 0.0588
Epoch  16 Batch  100/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.8643, Loss: 0.0550
Epoch  16 Batch  120/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8651, Loss: 0.0690
Epoch  16 Batch  140/1077 - Train Accuracy: 0.9424, Validation Accuracy: 0.8594, Loss: 0.0498
Epoch  16 Batch  160/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8562, Loss: 0.0599
Epoch  16 Batch  180/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.8672, Loss: 0.0557
Epoch  16 Batch  200/1077 - Train Accuracy: 0.8941, Validation Accuracy: 0.8597, Loss: 0.0591
Epoch  16 Batch  220/1077 - Train Accuracy: 0.9313, Validation Accuracy: 0.8768, Loss: 0.0712
Epoch  16 Batch  240/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.8771, Loss: 0.0465
Epoch  16 Batch  260/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8601, Loss: 0.0498
Epoch  16 Batch  280/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.8612, Loss: 0.0594
Epoch  16 Batch  300/1077 - Train Accuracy: 0.9149, Validation Accuracy: 0.8668, Loss: 0.0488
Epoch  16 Batch  320/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.8754, Loss: 0.0578
Epoch  16 Batch  340/1077 - Train Accuracy: 0.9433, Validation Accuracy: 0.8551, Loss: 0.0482
Epoch  16 Batch  360/1077 - Train Accuracy: 0.9355, Validation Accuracy: 0.8544, Loss: 0.0501
Epoch  16 Batch  380/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.8601, Loss: 0.0468
Epoch  16 Batch  400/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8498, Loss: 0.0711
Epoch  16 Batch  420/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.8509, Loss: 0.0463
Epoch  16 Batch  440/1077 - Train Accuracy: 0.8883, Validation Accuracy: 0.8629, Loss: 0.0736
Epoch  16 Batch  460/1077 - Train Accuracy: 0.9109, Validation Accuracy: 0.8622, Loss: 0.0694
Epoch  16 Batch  480/1077 - Train Accuracy: 0.9079, Validation Accuracy: 0.8626, Loss: 0.0585
Epoch  16 Batch  500/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.8707, Loss: 0.0498
Epoch  16 Batch  520/1077 - Train Accuracy: 0.9494, Validation Accuracy: 0.8551, Loss: 0.0527
Epoch  16 Batch  540/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.8608, Loss: 0.0489
Epoch  16 Batch  560/1077 - Train Accuracy: 0.9070, Validation Accuracy: 0.8544, Loss: 0.0521
Epoch  16 Batch  580/1077 - Train Accuracy: 0.9330, Validation Accuracy: 0.8533, Loss: 0.0469
Epoch  16 Batch  600/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.8491, Loss: 0.0520
Epoch  16 Batch  620/1077 - Train Accuracy: 0.9332, Validation Accuracy: 0.8732, Loss: 0.0508
Epoch  16 Batch  640/1077 - Train Accuracy: 0.9018, Validation Accuracy: 0.8537, Loss: 0.0497
Epoch  16 Batch  660/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.8661, Loss: 0.0541
Epoch  16 Batch  680/1077 - Train Accuracy: 0.8806, Validation Accuracy: 0.8608, Loss: 0.0565
Epoch  16 Batch  700/1077 - Train Accuracy: 0.9164, Validation Accuracy: 0.8615, Loss: 0.0456
Epoch  16 Batch  720/1077 - Train Accuracy: 0.9248, Validation Accuracy: 0.8697, Loss: 0.0605
Epoch  16 Batch  740/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.8672, Loss: 0.0494
Epoch  16 Batch  760/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8814, Loss: 0.0593
Epoch  16 Batch  780/1077 - Train Accuracy: 0.8875, Validation Accuracy: 0.8714, Loss: 0.0687
Epoch  16 Batch  800/1077 - Train Accuracy: 0.9258, Validation Accuracy: 0.8906, Loss: 0.0517
Epoch  16 Batch  820/1077 - Train Accuracy: 0.8859, Validation Accuracy: 0.8540, Loss: 0.0626
Epoch  16 Batch  840/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8707, Loss: 0.0540
Epoch  16 Batch  860/1077 - Train Accuracy: 0.9040, Validation Accuracy: 0.8743, Loss: 0.0697
Epoch  16 Batch  880/1077 - Train Accuracy: 0.9352, Validation Accuracy: 0.8782, Loss: 0.0570
Epoch  16 Batch  900/1077 - Train Accuracy: 0.9363, Validation Accuracy: 0.8562, Loss: 0.0657
Epoch  16 Batch  920/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.8665, Loss: 0.0573
Epoch  16 Batch  940/1077 - Train Accuracy: 0.9199, Validation Accuracy: 0.8729, Loss: 0.0578
Epoch  16 Batch  960/1077 - Train Accuracy: 0.9260, Validation Accuracy: 0.8558, Loss: 0.0510
Epoch  16 Batch  980/1077 - Train Accuracy: 0.8953, Validation Accuracy: 0.8732, Loss: 0.0633
Epoch  16 Batch 1000/1077 - Train Accuracy: 0.8984, Validation Accuracy: 0.8551, Loss: 0.0546
Epoch  16 Batch 1020/1077 - Train Accuracy: 0.9242, Validation Accuracy: 0.8640, Loss: 0.0465
Epoch  16 Batch 1040/1077 - Train Accuracy: 0.9157, Validation Accuracy: 0.8690, Loss: 0.0562
Epoch  16 Batch 1060/1077 - Train Accuracy: 0.9199, Validation Accuracy: 0.8604, Loss: 0.0457
Epoch  17 Batch   20/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.8718, Loss: 0.0478
Epoch  17 Batch   40/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.8750, Loss: 0.0491
Epoch  17 Batch   60/1077 - Train Accuracy: 0.9085, Validation Accuracy: 0.8604, Loss: 0.0464
Epoch  17 Batch   80/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.8711, Loss: 0.0532
Epoch  17 Batch  100/1077 - Train Accuracy: 0.9262, Validation Accuracy: 0.8928, Loss: 0.0510
Epoch  17 Batch  120/1077 - Train Accuracy: 0.9230, Validation Accuracy: 0.8732, Loss: 0.0617
Epoch  17 Batch  140/1077 - Train Accuracy: 0.9354, Validation Accuracy: 0.8555, Loss: 0.0443
Epoch  17 Batch  160/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8714, Loss: 0.0536
Epoch  17 Batch  180/1077 - Train Accuracy: 0.9246, Validation Accuracy: 0.8714, Loss: 0.0492
Epoch  17 Batch  200/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8686, Loss: 0.0543
Epoch  17 Batch  220/1077 - Train Accuracy: 0.9338, Validation Accuracy: 0.8867, Loss: 0.0626
Epoch  17 Batch  240/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.8942, Loss: 0.0427
Epoch  17 Batch  260/1077 - Train Accuracy: 0.9077, Validation Accuracy: 0.8675, Loss: 0.0448
Epoch  17 Batch  280/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8739, Loss: 0.0546
Epoch  17 Batch  300/1077 - Train Accuracy: 0.9252, Validation Accuracy: 0.8867, Loss: 0.0439
Epoch  17 Batch  320/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.8771, Loss: 0.0555
Epoch  17 Batch  340/1077 - Train Accuracy: 0.9507, Validation Accuracy: 0.8661, Loss: 0.0434
Epoch  17 Batch  360/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.8743, Loss: 0.0434
Epoch  17 Batch  380/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.8817, Loss: 0.0408
Epoch  17 Batch  400/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8612, Loss: 0.0636
Epoch  17 Batch  420/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.8704, Loss: 0.0415
Epoch  17 Batch  440/1077 - Train Accuracy: 0.9027, Validation Accuracy: 0.8768, Loss: 0.0610
Epoch  17 Batch  460/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.8619, Loss: 0.0626
Epoch  17 Batch  480/1077 - Train Accuracy: 0.9104, Validation Accuracy: 0.8864, Loss: 0.0507
Epoch  17 Batch  500/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.8722, Loss: 0.0422
Epoch  17 Batch  520/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.8661, Loss: 0.0473
Epoch  17 Batch  540/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.8817, Loss: 0.0452
Epoch  17 Batch  560/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.8725, Loss: 0.0478
Epoch  17 Batch  580/1077 - Train Accuracy: 0.9278, Validation Accuracy: 0.8732, Loss: 0.0420
Epoch  17 Batch  600/1077 - Train Accuracy: 0.9435, Validation Accuracy: 0.8675, Loss: 0.0465
Epoch  17 Batch  620/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.8981, Loss: 0.0467
Epoch  17 Batch  640/1077 - Train Accuracy: 0.8981, Validation Accuracy: 0.8761, Loss: 0.0437
Epoch  17 Batch  660/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.8764, Loss: 0.0474
Epoch  17 Batch  680/1077 - Train Accuracy: 0.8936, Validation Accuracy: 0.8857, Loss: 0.0510
Epoch  17 Batch  700/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.8729, Loss: 0.0415
Epoch  17 Batch  720/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8771, Loss: 0.0561
Epoch  17 Batch  740/1077 - Train Accuracy: 0.9203, Validation Accuracy: 0.8913, Loss: 0.0454
Epoch  17 Batch  760/1077 - Train Accuracy: 0.9191, Validation Accuracy: 0.8960, Loss: 0.0541
Epoch  17 Batch  780/1077 - Train Accuracy: 0.9176, Validation Accuracy: 0.8906, Loss: 0.0624
Epoch  17 Batch  800/1077 - Train Accuracy: 0.9281, Validation Accuracy: 0.8885, Loss: 0.0458
Epoch  17 Batch  820/1077 - Train Accuracy: 0.8887, Validation Accuracy: 0.8693, Loss: 0.0568
Epoch  17 Batch  840/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.8867, Loss: 0.0503
Epoch  17 Batch  860/1077 - Train Accuracy: 0.9174, Validation Accuracy: 0.8881, Loss: 0.0621
Epoch  17 Batch  880/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.8768, Loss: 0.0523
Epoch  17 Batch  900/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.8782, Loss: 0.0611
Epoch  17 Batch  920/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.8786, Loss: 0.0529
Epoch  17 Batch  940/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.8796, Loss: 0.0577
Epoch  17 Batch  960/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.8750, Loss: 0.0552
Epoch  17 Batch  980/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8835, Loss: 0.0577
Epoch  17 Batch 1000/1077 - Train Accuracy: 0.9327, Validation Accuracy: 0.8729, Loss: 0.0495
Epoch  17 Batch 1020/1077 - Train Accuracy: 0.9293, Validation Accuracy: 0.8817, Loss: 0.0398
Epoch  17 Batch 1040/1077 - Train Accuracy: 0.9206, Validation Accuracy: 0.8775, Loss: 0.0509
Epoch  17 Batch 1060/1077 - Train Accuracy: 0.9207, Validation Accuracy: 0.8892, Loss: 0.0407
Epoch  18 Batch   20/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.9073, Loss: 0.0427
Epoch  18 Batch   40/1077 - Train Accuracy: 0.9336, Validation Accuracy: 0.8796, Loss: 0.0457
Epoch  18 Batch   60/1077 - Train Accuracy: 0.9118, Validation Accuracy: 0.8857, Loss: 0.0410
Epoch  18 Batch   80/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.8754, Loss: 0.0506
Epoch  18 Batch  100/1077 - Train Accuracy: 0.9223, Validation Accuracy: 0.8881, Loss: 0.0483
Epoch  18 Batch  120/1077 - Train Accuracy: 0.9199, Validation Accuracy: 0.8789, Loss: 0.0554
Epoch  18 Batch  140/1077 - Train Accuracy: 0.9412, Validation Accuracy: 0.8764, Loss: 0.0422
Epoch  18 Batch  160/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.8778, Loss: 0.0470
Epoch  18 Batch  180/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.8860, Loss: 0.0435
Epoch  18 Batch  200/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8896, Loss: 0.0459
Epoch  18 Batch  220/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.8931, Loss: 0.0626
Epoch  18 Batch  240/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.8967, Loss: 0.0386
Epoch  18 Batch  260/1077 - Train Accuracy: 0.9074, Validation Accuracy: 0.8874, Loss: 0.0408
Epoch  18 Batch  280/1077 - Train Accuracy: 0.8965, Validation Accuracy: 0.8913, Loss: 0.0532
Epoch  18 Batch  300/1077 - Train Accuracy: 0.9334, Validation Accuracy: 0.9034, Loss: 0.0407
Epoch  18 Batch  320/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.8906, Loss: 0.0482
Epoch  18 Batch  340/1077 - Train Accuracy: 0.9511, Validation Accuracy: 0.8832, Loss: 0.0412
Epoch  18 Batch  360/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.8725, Loss: 0.0390
Epoch  18 Batch  380/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.8789, Loss: 0.0384
Epoch  18 Batch  400/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8842, Loss: 0.0574
Epoch  18 Batch  420/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.8828, Loss: 0.0365
Epoch  18 Batch  440/1077 - Train Accuracy: 0.9105, Validation Accuracy: 0.8906, Loss: 0.0549
Epoch  18 Batch  460/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.8960, Loss: 0.0574
Epoch  18 Batch  480/1077 - Train Accuracy: 0.9235, Validation Accuracy: 0.8860, Loss: 0.0460
Epoch  18 Batch  500/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.8764, Loss: 0.0392
Epoch  18 Batch  520/1077 - Train Accuracy: 0.9658, Validation Accuracy: 0.8743, Loss: 0.0434
Epoch  18 Batch  540/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.8913, Loss: 0.0381
Epoch  18 Batch  560/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.8910, Loss: 0.0432
Epoch  18 Batch  580/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.8814, Loss: 0.0384
Epoch  18 Batch  600/1077 - Train Accuracy: 0.9479, Validation Accuracy: 0.8857, Loss: 0.0413
Epoch  18 Batch  620/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9027, Loss: 0.0419
Epoch  18 Batch  640/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8928, Loss: 0.0407
Epoch  18 Batch  660/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.8842, Loss: 0.0437
Epoch  18 Batch  680/1077 - Train Accuracy: 0.9103, Validation Accuracy: 0.9141, Loss: 0.0473
Epoch  18 Batch  700/1077 - Train Accuracy: 0.9184, Validation Accuracy: 0.8952, Loss: 0.0380
Epoch  18 Batch  720/1077 - Train Accuracy: 0.9248, Validation Accuracy: 0.8881, Loss: 0.0528
Epoch  18 Batch  740/1077 - Train Accuracy: 0.9328, Validation Accuracy: 0.9055, Loss: 0.0405
Epoch  18 Batch  760/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.8917, Loss: 0.0507
Epoch  18 Batch  780/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.8935, Loss: 0.0569
Epoch  18 Batch  800/1077 - Train Accuracy: 0.9340, Validation Accuracy: 0.9002, Loss: 0.0409
Epoch  18 Batch  820/1077 - Train Accuracy: 0.8988, Validation Accuracy: 0.8917, Loss: 0.0505
Epoch  18 Batch  840/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.8842, Loss: 0.0476
Epoch  18 Batch  860/1077 - Train Accuracy: 0.9338, Validation Accuracy: 0.9094, Loss: 0.0566
Epoch  18 Batch  880/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.8867, Loss: 0.0490
Epoch  18 Batch  900/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.8817, Loss: 0.0508
Epoch  18 Batch  920/1077 - Train Accuracy: 0.9223, Validation Accuracy: 0.8750, Loss: 0.0455
Epoch  18 Batch  940/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.8920, Loss: 0.0444
Epoch  18 Batch  960/1077 - Train Accuracy: 0.9260, Validation Accuracy: 0.8764, Loss: 0.0442
Epoch  18 Batch  980/1077 - Train Accuracy: 0.8531, Validation Accuracy: 0.8800, Loss: 0.0702
Epoch  18 Batch 1000/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.8864, Loss: 0.0461
Epoch  18 Batch 1020/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8778, Loss: 0.0358
Epoch  18 Batch 1040/1077 - Train Accuracy: 0.9190, Validation Accuracy: 0.8938, Loss: 0.0454
Epoch  18 Batch 1060/1077 - Train Accuracy: 0.9281, Validation Accuracy: 0.8981, Loss: 0.0369
Epoch  19 Batch   20/1077 - Train Accuracy: 0.9227, Validation Accuracy: 0.9073, Loss: 0.0392
Epoch  19 Batch   40/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.9038, Loss: 0.0413
Epoch  19 Batch   60/1077 - Train Accuracy: 0.9185, Validation Accuracy: 0.9013, Loss: 0.0361
Epoch  19 Batch   80/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.8892, Loss: 0.0452
Epoch  19 Batch  100/1077 - Train Accuracy: 0.9258, Validation Accuracy: 0.8881, Loss: 0.0440
Epoch  19 Batch  120/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.9066, Loss: 0.0532
Epoch  19 Batch  140/1077 - Train Accuracy: 0.9482, Validation Accuracy: 0.8817, Loss: 0.0394
Epoch  19 Batch  160/1077 - Train Accuracy: 0.9215, Validation Accuracy: 0.8995, Loss: 0.0426
Epoch  19 Batch  180/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.8995, Loss: 0.0401
Epoch  19 Batch  200/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.9038, Loss: 0.0420
Epoch  19 Batch  220/1077 - Train Accuracy: 0.9420, Validation Accuracy: 0.9006, Loss: 0.0555
Epoch  19 Batch  240/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.8981, Loss: 0.0359
Epoch  19 Batch  260/1077 - Train Accuracy: 0.9122, Validation Accuracy: 0.8960, Loss: 0.0374
Epoch  19 Batch  280/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.8999, Loss: 0.0498
Epoch  19 Batch  300/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9087, Loss: 0.0381
Epoch  19 Batch  320/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9055, Loss: 0.0434
Epoch  19 Batch  340/1077 - Train Accuracy: 0.9519, Validation Accuracy: 0.8860, Loss: 0.0375
Epoch  19 Batch  360/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.8864, Loss: 0.0353
Epoch  19 Batch  380/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.8931, Loss: 0.0330
Epoch  19 Batch  400/1077 - Train Accuracy: 0.9336, Validation Accuracy: 0.8974, Loss: 0.0520
Epoch  19 Batch  420/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.8729, Loss: 0.0319
Epoch  19 Batch  440/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.9009, Loss: 0.0511
Epoch  19 Batch  460/1077 - Train Accuracy: 0.9199, Validation Accuracy: 0.9045, Loss: 0.0520
Epoch  19 Batch  480/1077 - Train Accuracy: 0.9268, Validation Accuracy: 0.9013, Loss: 0.0422
Epoch  19 Batch  500/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.8825, Loss: 0.0355
Epoch  19 Batch  520/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.8910, Loss: 0.0399
Epoch  19 Batch  540/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9059, Loss: 0.0357
Epoch  19 Batch  560/1077 - Train Accuracy: 0.9285, Validation Accuracy: 0.9006, Loss: 0.0402
Epoch  19 Batch  580/1077 - Train Accuracy: 0.9427, Validation Accuracy: 0.9002, Loss: 0.0333
Epoch  19 Batch  600/1077 - Train Accuracy: 0.9479, Validation Accuracy: 0.9123, Loss: 0.0380
Epoch  19 Batch  620/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.8995, Loss: 0.0378
Epoch  19 Batch  640/1077 - Train Accuracy: 0.8966, Validation Accuracy: 0.9087, Loss: 0.0384
Epoch  19 Batch  660/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.8849, Loss: 0.0394
Epoch  19 Batch  680/1077 - Train Accuracy: 0.9115, Validation Accuracy: 0.9130, Loss: 0.0436
Epoch  19 Batch  700/1077 - Train Accuracy: 0.9262, Validation Accuracy: 0.9116, Loss: 0.0369
Epoch  19 Batch  720/1077 - Train Accuracy: 0.9252, Validation Accuracy: 0.8960, Loss: 0.0466
Epoch  19 Batch  740/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9144, Loss: 0.0404
Epoch  19 Batch  760/1077 - Train Accuracy: 0.9176, Validation Accuracy: 0.9055, Loss: 0.0448
Epoch  19 Batch  780/1077 - Train Accuracy: 0.9102, Validation Accuracy: 0.9034, Loss: 0.0539
Epoch  19 Batch  800/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9009, Loss: 0.0372
Epoch  19 Batch  820/1077 - Train Accuracy: 0.9195, Validation Accuracy: 0.8949, Loss: 0.0443
Epoch  19 Batch  840/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.8984, Loss: 0.0414
Epoch  19 Batch  860/1077 - Train Accuracy: 0.9475, Validation Accuracy: 0.9055, Loss: 0.0531
Epoch  19 Batch  880/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.8938, Loss: 0.0471
Epoch  19 Batch  900/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9016, Loss: 0.0485
Epoch  19 Batch  920/1077 - Train Accuracy: 0.9313, Validation Accuracy: 0.8896, Loss: 0.0415
Epoch  19 Batch  940/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.8952, Loss: 0.0494
Epoch  19 Batch  960/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.8931, Loss: 0.0402
Epoch  19 Batch  980/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.9190, Loss: 0.0495
Epoch  19 Batch 1000/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.9002, Loss: 0.0410
Epoch  19 Batch 1020/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.8974, Loss: 0.0330
Epoch  19 Batch 1040/1077 - Train Accuracy: 0.9387, Validation Accuracy: 0.8981, Loss: 0.0416
Epoch  19 Batch 1060/1077 - Train Accuracy: 0.9320, Validation Accuracy: 0.8977, Loss: 0.0363
Epoch  20 Batch   20/1077 - Train Accuracy: 0.9398, Validation Accuracy: 0.9155, Loss: 0.0359
Epoch  20 Batch   40/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9020, Loss: 0.0383
Epoch  20 Batch   60/1077 - Train Accuracy: 0.9241, Validation Accuracy: 0.9130, Loss: 0.0336
Epoch  20 Batch   80/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.8913, Loss: 0.0419
Epoch  20 Batch  100/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.8931, Loss: 0.0428
Epoch  20 Batch  120/1077 - Train Accuracy: 0.9316, Validation Accuracy: 0.9066, Loss: 0.0494
Epoch  20 Batch  140/1077 - Train Accuracy: 0.9502, Validation Accuracy: 0.8881, Loss: 0.0347
Epoch  20 Batch  160/1077 - Train Accuracy: 0.9246, Validation Accuracy: 0.9038, Loss: 0.0404
Epoch  20 Batch  180/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.8991, Loss: 0.0369
Epoch  20 Batch  200/1077 - Train Accuracy: 0.9230, Validation Accuracy: 0.9059, Loss: 0.0401
Epoch  20 Batch  220/1077 - Train Accuracy: 0.9474, Validation Accuracy: 0.9052, Loss: 0.0536
Epoch  20 Batch  240/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.9027, Loss: 0.0332
Epoch  20 Batch  260/1077 - Train Accuracy: 0.9092, Validation Accuracy: 0.8970, Loss: 0.0347
Epoch  20 Batch  280/1077 - Train Accuracy: 0.9172, Validation Accuracy: 0.9023, Loss: 0.0466
Epoch  20 Batch  300/1077 - Train Accuracy: 0.9564, Validation Accuracy: 0.9105, Loss: 0.0347
Epoch  20 Batch  320/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9059, Loss: 0.0420
Epoch  20 Batch  340/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.8991, Loss: 0.0364
Epoch  20 Batch  360/1077 - Train Accuracy: 0.9363, Validation Accuracy: 0.8931, Loss: 0.0323
Epoch  20 Batch  380/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.8960, Loss: 0.0304
Epoch  20 Batch  400/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.8970, Loss: 0.0482
Epoch  20 Batch  420/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.8970, Loss: 0.0293
Epoch  20 Batch  440/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.9013, Loss: 0.0477
Epoch  20 Batch  460/1077 - Train Accuracy: 0.9227, Validation Accuracy: 0.9098, Loss: 0.0483
Epoch  20 Batch  480/1077 - Train Accuracy: 0.9322, Validation Accuracy: 0.8991, Loss: 0.0394
Epoch  20 Batch  500/1077 - Train Accuracy: 0.9348, Validation Accuracy: 0.8874, Loss: 0.0337
Epoch  20 Batch  520/1077 - Train Accuracy: 0.9710, Validation Accuracy: 0.8974, Loss: 0.0369
Epoch  20 Batch  540/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9205, Loss: 0.0326
Epoch  20 Batch  560/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.8995, Loss: 0.0388
Epoch  20 Batch  580/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9045, Loss: 0.0307
Epoch  20 Batch  600/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9109, Loss: 0.0352
Epoch  20 Batch  620/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9034, Loss: 0.0347
Epoch  20 Batch  640/1077 - Train Accuracy: 0.9178, Validation Accuracy: 0.8924, Loss: 0.0347
Epoch  20 Batch  660/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.8810, Loss: 0.0363
Epoch  20 Batch  680/1077 - Train Accuracy: 0.9193, Validation Accuracy: 0.9112, Loss: 0.0412
Epoch  20 Batch  700/1077 - Train Accuracy: 0.9328, Validation Accuracy: 0.9141, Loss: 0.0346
Epoch  20 Batch  720/1077 - Train Accuracy: 0.9157, Validation Accuracy: 0.9148, Loss: 0.0423
Epoch  20 Batch  740/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.9119, Loss: 0.0409
Epoch  20 Batch  760/1077 - Train Accuracy: 0.9203, Validation Accuracy: 0.9158, Loss: 0.0426
Epoch  20 Batch  780/1077 - Train Accuracy: 0.9168, Validation Accuracy: 0.9059, Loss: 0.0518
Epoch  20 Batch  800/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9013, Loss: 0.0337
Epoch  20 Batch  820/1077 - Train Accuracy: 0.9199, Validation Accuracy: 0.8960, Loss: 0.0425
Epoch  20 Batch  840/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9105, Loss: 0.0386
Epoch  20 Batch  860/1077 - Train Accuracy: 0.9464, Validation Accuracy: 0.9066, Loss: 0.0508
Epoch  20 Batch  880/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.8899, Loss: 0.0444
Epoch  20 Batch  900/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9084, Loss: 0.0439
Epoch  20 Batch  920/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.9070, Loss: 0.0385
Epoch  20 Batch  940/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.9144, Loss: 0.0391
Epoch  20 Batch  960/1077 - Train Accuracy: 0.9423, Validation Accuracy: 0.9027, Loss: 0.0362
Epoch  20 Batch  980/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.9073, Loss: 0.0442
Epoch  20 Batch 1000/1077 - Train Accuracy: 0.9401, Validation Accuracy: 0.8963, Loss: 0.0410
Epoch  20 Batch 1020/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9141, Loss: 0.0314
Epoch  20 Batch 1040/1077 - Train Accuracy: 0.9387, Validation Accuracy: 0.9066, Loss: 0.0400
Epoch  20 Batch 1060/1077 - Train Accuracy: 0.9387, Validation Accuracy: 0.8991, Loss: 0.0332
Epoch  21 Batch   20/1077 - Train Accuracy: 0.9480, Validation Accuracy: 0.9169, Loss: 0.0334
Epoch  21 Batch   40/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9112, Loss: 0.0347
Epoch  21 Batch   60/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.9158, Loss: 0.0310
Epoch  21 Batch   80/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.8949, Loss: 0.0389
Epoch  21 Batch  100/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9016, Loss: 0.0407
Epoch  21 Batch  120/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.9073, Loss: 0.0467
Epoch  21 Batch  140/1077 - Train Accuracy: 0.9593, Validation Accuracy: 0.8956, Loss: 0.0328
Epoch  21 Batch  160/1077 - Train Accuracy: 0.9313, Validation Accuracy: 0.8981, Loss: 0.0362
Epoch  21 Batch  180/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.8821, Loss: 0.0349
Epoch  21 Batch  200/1077 - Train Accuracy: 0.9254, Validation Accuracy: 0.9112, Loss: 0.0377
Epoch  21 Batch  220/1077 - Train Accuracy: 0.9486, Validation Accuracy: 0.8952, Loss: 0.0517
Epoch  21 Batch  240/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9205, Loss: 0.0309
Epoch  21 Batch  260/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.8991, Loss: 0.0332
Epoch  21 Batch  280/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.9023, Loss: 0.0460
Epoch  21 Batch  300/1077 - Train Accuracy: 0.9519, Validation Accuracy: 0.9183, Loss: 0.0319
Epoch  21 Batch  320/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9126, Loss: 0.0393
Epoch  21 Batch  340/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9091, Loss: 0.0338
Epoch  21 Batch  360/1077 - Train Accuracy: 0.9332, Validation Accuracy: 0.8995, Loss: 0.0299
Epoch  21 Batch  380/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.8924, Loss: 0.0282
Epoch  21 Batch  400/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.8991, Loss: 0.0457
Epoch  21 Batch  420/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.8942, Loss: 0.0273
Epoch  21 Batch  440/1077 - Train Accuracy: 0.9047, Validation Accuracy: 0.9066, Loss: 0.0453
Epoch  21 Batch  460/1077 - Train Accuracy: 0.9242, Validation Accuracy: 0.9052, Loss: 0.0451
Epoch  21 Batch  480/1077 - Train Accuracy: 0.9342, Validation Accuracy: 0.9091, Loss: 0.0372
Epoch  21 Batch  500/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.9038, Loss: 0.0311
Epoch  21 Batch  520/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9144, Loss: 0.0346
Epoch  21 Batch  540/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9205, Loss: 0.0303
Epoch  21 Batch  560/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9052, Loss: 0.0383
Epoch  21 Batch  580/1077 - Train Accuracy: 0.9498, Validation Accuracy: 0.9084, Loss: 0.0289
Epoch  21 Batch  600/1077 - Train Accuracy: 0.9394, Validation Accuracy: 0.9162, Loss: 0.0337
Epoch  21 Batch  620/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9169, Loss: 0.0336
Epoch  21 Batch  640/1077 - Train Accuracy: 0.9226, Validation Accuracy: 0.9155, Loss: 0.0320
Epoch  21 Batch  660/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.8977, Loss: 0.0335
Epoch  21 Batch  680/1077 - Train Accuracy: 0.9260, Validation Accuracy: 0.9190, Loss: 0.0389
Epoch  21 Batch  700/1077 - Train Accuracy: 0.9281, Validation Accuracy: 0.9077, Loss: 0.0335
Epoch  21 Batch  720/1077 - Train Accuracy: 0.9243, Validation Accuracy: 0.9098, Loss: 0.0400
Epoch  21 Batch  740/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9219, Loss: 0.0326
Epoch  21 Batch  760/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9116, Loss: 0.0402
Epoch  21 Batch  780/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.9077, Loss: 0.0479
Epoch  21 Batch  800/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9162, Loss: 0.0318
Epoch  21 Batch  820/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9006, Loss: 0.0399
Epoch  21 Batch  840/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9123, Loss: 0.0393
Epoch  21 Batch  860/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9038, Loss: 0.0464
Epoch  21 Batch  880/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9041, Loss: 0.0416
Epoch  21 Batch  900/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9023, Loss: 0.0402
Epoch  21 Batch  920/1077 - Train Accuracy: 0.9363, Validation Accuracy: 0.9020, Loss: 0.0355
Epoch  21 Batch  940/1077 - Train Accuracy: 0.9328, Validation Accuracy: 0.9187, Loss: 0.0356
Epoch  21 Batch  960/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9183, Loss: 0.0330
Epoch  21 Batch  980/1077 - Train Accuracy: 0.9125, Validation Accuracy: 0.9116, Loss: 0.0424
Epoch  21 Batch 1000/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9009, Loss: 0.0367
Epoch  21 Batch 1020/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9158, Loss: 0.0281
Epoch  21 Batch 1040/1077 - Train Accuracy: 0.9420, Validation Accuracy: 0.9066, Loss: 0.0365
Epoch  21 Batch 1060/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9084, Loss: 0.0306
Epoch  22 Batch   20/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9247, Loss: 0.0294
Epoch  22 Batch   40/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9254, Loss: 0.0342
Epoch  22 Batch   60/1077 - Train Accuracy: 0.9338, Validation Accuracy: 0.9208, Loss: 0.0293
Epoch  22 Batch   80/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9109, Loss: 0.0364
Epoch  22 Batch  100/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9006, Loss: 0.0394
Epoch  22 Batch  120/1077 - Train Accuracy: 0.9184, Validation Accuracy: 0.9091, Loss: 0.0466
Epoch  22 Batch  140/1077 - Train Accuracy: 0.9659, Validation Accuracy: 0.8995, Loss: 0.0309
Epoch  22 Batch  160/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9041, Loss: 0.0338
Epoch  22 Batch  180/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.8995, Loss: 0.0334
Epoch  22 Batch  200/1077 - Train Accuracy: 0.9133, Validation Accuracy: 0.9034, Loss: 0.0344
Epoch  22 Batch  220/1077 - Train Accuracy: 0.9498, Validation Accuracy: 0.9116, Loss: 0.0484
Epoch  22 Batch  240/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9130, Loss: 0.0281
Epoch  22 Batch  260/1077 - Train Accuracy: 0.9118, Validation Accuracy: 0.8999, Loss: 0.0313
Epoch  22 Batch  280/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.9052, Loss: 0.0438
Epoch  22 Batch  300/1077 - Train Accuracy: 0.9638, Validation Accuracy: 0.9009, Loss: 0.0296
Epoch  22 Batch  320/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9251, Loss: 0.0419
Epoch  22 Batch  340/1077 - Train Accuracy: 0.9502, Validation Accuracy: 0.9222, Loss: 0.0312
Epoch  22 Batch  360/1077 - Train Accuracy: 0.9469, Validation Accuracy: 0.9102, Loss: 0.0294
Epoch  22 Batch  380/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9130, Loss: 0.0266
Epoch  22 Batch  400/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9038, Loss: 0.0411
Epoch  22 Batch  420/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9023, Loss: 0.0260
Epoch  22 Batch  440/1077 - Train Accuracy: 0.9191, Validation Accuracy: 0.9165, Loss: 0.0419
Epoch  22 Batch  460/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.9169, Loss: 0.0419
Epoch  22 Batch  480/1077 - Train Accuracy: 0.9338, Validation Accuracy: 0.9151, Loss: 0.0352
Epoch  22 Batch  500/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9112, Loss: 0.0290
Epoch  22 Batch  520/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9148, Loss: 0.0322
Epoch  22 Batch  540/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9219, Loss: 0.0283
Epoch  22 Batch  560/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9176, Loss: 0.0358
Epoch  22 Batch  580/1077 - Train Accuracy: 0.9435, Validation Accuracy: 0.9045, Loss: 0.0305
Epoch  22 Batch  600/1077 - Train Accuracy: 0.9479, Validation Accuracy: 0.9176, Loss: 0.0373
Epoch  22 Batch  620/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9212, Loss: 0.0320
Epoch  22 Batch  640/1077 - Train Accuracy: 0.9464, Validation Accuracy: 0.9194, Loss: 0.0298
Epoch  22 Batch  660/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9155, Loss: 0.0322
Epoch  22 Batch  680/1077 - Train Accuracy: 0.9315, Validation Accuracy: 0.9176, Loss: 0.0367
Epoch  22 Batch  700/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.9251, Loss: 0.0300
Epoch  22 Batch  720/1077 - Train Accuracy: 0.9243, Validation Accuracy: 0.9194, Loss: 0.0374
Epoch  22 Batch  740/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9226, Loss: 0.0324
Epoch  22 Batch  760/1077 - Train Accuracy: 0.9328, Validation Accuracy: 0.9219, Loss: 0.0379
Epoch  22 Batch  780/1077 - Train Accuracy: 0.9254, Validation Accuracy: 0.9066, Loss: 0.0461
Epoch  22 Batch  800/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9208, Loss: 0.0306
Epoch  22 Batch  820/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9073, Loss: 0.0379
Epoch  22 Batch  840/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.9102, Loss: 0.0357
Epoch  22 Batch  860/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.8999, Loss: 0.0452
Epoch  22 Batch  880/1077 - Train Accuracy: 0.9426, Validation Accuracy: 0.9105, Loss: 0.0385
Epoch  22 Batch  900/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9222, Loss: 0.0403
Epoch  22 Batch  920/1077 - Train Accuracy: 0.9367, Validation Accuracy: 0.9187, Loss: 0.0335
Epoch  22 Batch  940/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9165, Loss: 0.0347
Epoch  22 Batch  960/1077 - Train Accuracy: 0.9550, Validation Accuracy: 0.9130, Loss: 0.0304
Epoch  22 Batch  980/1077 - Train Accuracy: 0.9191, Validation Accuracy: 0.9226, Loss: 0.0387
Epoch  22 Batch 1000/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9094, Loss: 0.0338
Epoch  22 Batch 1020/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.9286, Loss: 0.0251
Epoch  22 Batch 1040/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9226, Loss: 0.0348
Epoch  22 Batch 1060/1077 - Train Accuracy: 0.9480, Validation Accuracy: 0.9144, Loss: 0.0300
Epoch  23 Batch   20/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9304, Loss: 0.0273
Epoch  23 Batch   40/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9300, Loss: 0.0312
Epoch  23 Batch   60/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.9208, Loss: 0.0270
Epoch  23 Batch   80/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.9165, Loss: 0.0346
Epoch  23 Batch  100/1077 - Train Accuracy: 0.9324, Validation Accuracy: 0.9123, Loss: 0.0373
Epoch  23 Batch  120/1077 - Train Accuracy: 0.9316, Validation Accuracy: 0.9219, Loss: 0.0421
Epoch  23 Batch  140/1077 - Train Accuracy: 0.9704, Validation Accuracy: 0.9013, Loss: 0.0294
Epoch  23 Batch  160/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9233, Loss: 0.0326
Epoch  23 Batch  180/1077 - Train Accuracy: 0.9387, Validation Accuracy: 0.9201, Loss: 0.0317
Epoch  23 Batch  200/1077 - Train Accuracy: 0.9109, Validation Accuracy: 0.9148, Loss: 0.0337
Epoch  23 Batch  220/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9165, Loss: 0.0469
Epoch  23 Batch  240/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9283, Loss: 0.0261
Epoch  23 Batch  260/1077 - Train Accuracy: 0.9163, Validation Accuracy: 0.9066, Loss: 0.0295
Epoch  23 Batch  280/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.9027, Loss: 0.0393
Epoch  23 Batch  300/1077 - Train Accuracy: 0.9618, Validation Accuracy: 0.9066, Loss: 0.0274
Epoch  23 Batch  320/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9197, Loss: 0.0367
Epoch  23 Batch  340/1077 - Train Accuracy: 0.9498, Validation Accuracy: 0.9176, Loss: 0.0320
Epoch  23 Batch  360/1077 - Train Accuracy: 0.9426, Validation Accuracy: 0.9116, Loss: 0.0262
Epoch  23 Batch  380/1077 - Train Accuracy: 0.9469, Validation Accuracy: 0.9180, Loss: 0.0265
Epoch  23 Batch  400/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9130, Loss: 0.0395
Epoch  23 Batch  420/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9208, Loss: 0.0249
Epoch  23 Batch  440/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.9194, Loss: 0.0399
Epoch  23 Batch  460/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.9183, Loss: 0.0394
Epoch  23 Batch  480/1077 - Train Accuracy: 0.9305, Validation Accuracy: 0.9215, Loss: 0.0328
Epoch  23 Batch  500/1077 - Train Accuracy: 0.9469, Validation Accuracy: 0.9165, Loss: 0.0277
Epoch  23 Batch  520/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9144, Loss: 0.0300
Epoch  23 Batch  540/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9180, Loss: 0.0260
Epoch  23 Batch  560/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9183, Loss: 0.0354
Epoch  23 Batch  580/1077 - Train Accuracy: 0.9587, Validation Accuracy: 0.9059, Loss: 0.0278
Epoch  23 Batch  600/1077 - Train Accuracy: 0.9505, Validation Accuracy: 0.9226, Loss: 0.0311
Epoch  23 Batch  620/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9311, Loss: 0.0318
Epoch  23 Batch  640/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9261, Loss: 0.0291
Epoch  23 Batch  660/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9151, Loss: 0.0303
Epoch  23 Batch  680/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9173, Loss: 0.0382
Epoch  23 Batch  700/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9244, Loss: 0.0275
Epoch  23 Batch  720/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.9258, Loss: 0.0370
Epoch  23 Batch  740/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9229, Loss: 0.0288
Epoch  23 Batch  760/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9276, Loss: 0.0359
Epoch  23 Batch  780/1077 - Train Accuracy: 0.9242, Validation Accuracy: 0.9190, Loss: 0.0438
Epoch  23 Batch  800/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9237, Loss: 0.0294
Epoch  23 Batch  820/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9165, Loss: 0.0360
Epoch  23 Batch  840/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9283, Loss: 0.0347
Epoch  23 Batch  860/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9137, Loss: 0.0431
Epoch  23 Batch  880/1077 - Train Accuracy: 0.9426, Validation Accuracy: 0.9141, Loss: 0.0363
Epoch  23 Batch  900/1077 - Train Accuracy: 0.9469, Validation Accuracy: 0.9119, Loss: 0.0419
Epoch  23 Batch  920/1077 - Train Accuracy: 0.9301, Validation Accuracy: 0.9215, Loss: 0.0341
Epoch  23 Batch  940/1077 - Train Accuracy: 0.9398, Validation Accuracy: 0.9208, Loss: 0.0344
Epoch  23 Batch  960/1077 - Train Accuracy: 0.9565, Validation Accuracy: 0.9194, Loss: 0.0290
Epoch  23 Batch  980/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.9290, Loss: 0.0379
Epoch  23 Batch 1000/1077 - Train Accuracy: 0.9420, Validation Accuracy: 0.9240, Loss: 0.0323
Epoch  23 Batch 1020/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9308, Loss: 0.0239
Epoch  23 Batch 1040/1077 - Train Accuracy: 0.9470, Validation Accuracy: 0.9308, Loss: 0.0338
Epoch  23 Batch 1060/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9151, Loss: 0.0284
Epoch  24 Batch   20/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9261, Loss: 0.0283
Epoch  24 Batch   40/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9347, Loss: 0.0293
Epoch  24 Batch   60/1077 - Train Accuracy: 0.9382, Validation Accuracy: 0.9208, Loss: 0.0263
Epoch  24 Batch   80/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9254, Loss: 0.0324
Epoch  24 Batch  100/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9148, Loss: 0.0364
Epoch  24 Batch  120/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.9272, Loss: 0.0387
Epoch  24 Batch  140/1077 - Train Accuracy: 0.9692, Validation Accuracy: 0.9148, Loss: 0.0276
Epoch  24 Batch  160/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9197, Loss: 0.0292
Epoch  24 Batch  180/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9276, Loss: 0.0276
Epoch  24 Batch  200/1077 - Train Accuracy: 0.9324, Validation Accuracy: 0.9336, Loss: 0.0320
Epoch  24 Batch  220/1077 - Train Accuracy: 0.9507, Validation Accuracy: 0.9144, Loss: 0.0471
Epoch  24 Batch  240/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9251, Loss: 0.0246
Epoch  24 Batch  260/1077 - Train Accuracy: 0.9103, Validation Accuracy: 0.9084, Loss: 0.0277
Epoch  24 Batch  280/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.9151, Loss: 0.0379
Epoch  24 Batch  300/1077 - Train Accuracy: 0.9638, Validation Accuracy: 0.9091, Loss: 0.0259
Epoch  24 Batch  320/1077 - Train Accuracy: 0.9469, Validation Accuracy: 0.9205, Loss: 0.0366
Epoch  24 Batch  340/1077 - Train Accuracy: 0.9519, Validation Accuracy: 0.9240, Loss: 0.0297
Epoch  24 Batch  360/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9165, Loss: 0.0245
Epoch  24 Batch  380/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9197, Loss: 0.0246
Epoch  24 Batch  400/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9222, Loss: 0.0365
Epoch  24 Batch  420/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9240, Loss: 0.0237
Epoch  24 Batch  440/1077 - Train Accuracy: 0.9187, Validation Accuracy: 0.9194, Loss: 0.0381
Epoch  24 Batch  460/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.9137, Loss: 0.0375
Epoch  24 Batch  480/1077 - Train Accuracy: 0.9420, Validation Accuracy: 0.9190, Loss: 0.0321
Epoch  24 Batch  500/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9268, Loss: 0.0263
Epoch  24 Batch  520/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9155, Loss: 0.0283
Epoch  24 Batch  540/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9165, Loss: 0.0246
Epoch  24 Batch  560/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9357, Loss: 0.0348
Epoch  24 Batch  580/1077 - Train Accuracy: 0.9464, Validation Accuracy: 0.9173, Loss: 0.0246
Epoch  24 Batch  600/1077 - Train Accuracy: 0.9501, Validation Accuracy: 0.9336, Loss: 0.0308
Epoch  24 Batch  620/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9350, Loss: 0.0286
Epoch  24 Batch  640/1077 - Train Accuracy: 0.9498, Validation Accuracy: 0.9393, Loss: 0.0274
Epoch  24 Batch  660/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9240, Loss: 0.0276
Epoch  24 Batch  680/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9194, Loss: 0.0336
Epoch  24 Batch  700/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.9190, Loss: 0.0266
Epoch  24 Batch  720/1077 - Train Accuracy: 0.9293, Validation Accuracy: 0.9265, Loss: 0.0344
Epoch  24 Batch  740/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9304, Loss: 0.0278
Epoch  24 Batch  760/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9375, Loss: 0.0334
Epoch  24 Batch  780/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.9137, Loss: 0.0430
Epoch  24 Batch  800/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9183, Loss: 0.0286
Epoch  24 Batch  820/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.8956, Loss: 0.0862
Epoch  24 Batch  840/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9066, Loss: 0.0441
Epoch  24 Batch  860/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.9197, Loss: 0.0440
Epoch  24 Batch  880/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9173, Loss: 0.0361
Epoch  24 Batch  900/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9226, Loss: 0.0308
Epoch  24 Batch  920/1077 - Train Accuracy: 0.9426, Validation Accuracy: 0.9237, Loss: 0.0297
Epoch  24 Batch  940/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9325, Loss: 0.0298
Epoch  24 Batch  960/1077 - Train Accuracy: 0.9479, Validation Accuracy: 0.9180, Loss: 0.0263
Epoch  24 Batch  980/1077 - Train Accuracy: 0.9340, Validation Accuracy: 0.9400, Loss: 0.0341
Epoch  24 Batch 1000/1077 - Train Accuracy: 0.9304, Validation Accuracy: 0.9226, Loss: 0.0306
Epoch  24 Batch 1020/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9201, Loss: 0.0220
Epoch  24 Batch 1040/1077 - Train Accuracy: 0.9502, Validation Accuracy: 0.9286, Loss: 0.0311
Epoch  24 Batch 1060/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9343, Loss: 0.0266
Epoch  25 Batch   20/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9308, Loss: 0.0272
Epoch  25 Batch   40/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9396, Loss: 0.0261
Epoch  25 Batch   60/1077 - Train Accuracy: 0.9524, Validation Accuracy: 0.9350, Loss: 0.0234
Epoch  25 Batch   80/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9162, Loss: 0.0302
Epoch  25 Batch  100/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9226, Loss: 0.0341
Epoch  25 Batch  120/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9322, Loss: 0.0391
Epoch  25 Batch  140/1077 - Train Accuracy: 0.9671, Validation Accuracy: 0.9368, Loss: 0.0268
Epoch  25 Batch  160/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9212, Loss: 0.0267
Epoch  25 Batch  180/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9268, Loss: 0.0276
Epoch  25 Batch  200/1077 - Train Accuracy: 0.9363, Validation Accuracy: 0.9368, Loss: 0.0302
Epoch  25 Batch  220/1077 - Train Accuracy: 0.9474, Validation Accuracy: 0.9254, Loss: 0.0449
Epoch  25 Batch  240/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9261, Loss: 0.0240
Epoch  25 Batch  260/1077 - Train Accuracy: 0.9141, Validation Accuracy: 0.9123, Loss: 0.0264
Epoch  25 Batch  280/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.9176, Loss: 0.0373
Epoch  25 Batch  300/1077 - Train Accuracy: 0.9679, Validation Accuracy: 0.9201, Loss: 0.0242
Epoch  25 Batch  320/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9332, Loss: 0.0326
Epoch  25 Batch  340/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9226, Loss: 0.0293
Epoch  25 Batch  360/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9322, Loss: 0.0245
Epoch  25 Batch  380/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.9183, Loss: 0.0243
Epoch  25 Batch  400/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9254, Loss: 0.0333
Epoch  25 Batch  420/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9251, Loss: 0.0218
Epoch  25 Batch  440/1077 - Train Accuracy: 0.9187, Validation Accuracy: 0.9144, Loss: 0.0360
Epoch  25 Batch  460/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.9229, Loss: 0.0360
Epoch  25 Batch  480/1077 - Train Accuracy: 0.9424, Validation Accuracy: 0.9336, Loss: 0.0291
Epoch  25 Batch  500/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9371, Loss: 0.0242
Epoch  25 Batch  520/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9311, Loss: 0.0267
Epoch  25 Batch  540/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9332, Loss: 0.0228
Epoch  25 Batch  560/1077 - Train Accuracy: 0.9480, Validation Accuracy: 0.9435, Loss: 0.0303
Epoch  25 Batch  580/1077 - Train Accuracy: 0.9591, Validation Accuracy: 0.9094, Loss: 0.0255
Epoch  25 Batch  600/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9251, Loss: 0.0313
Epoch  25 Batch  620/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9343, Loss: 0.0270
Epoch  25 Batch  640/1077 - Train Accuracy: 0.9561, Validation Accuracy: 0.9442, Loss: 0.0255
Epoch  25 Batch  660/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.9251, Loss: 0.0270
Epoch  25 Batch  680/1077 - Train Accuracy: 0.9494, Validation Accuracy: 0.9276, Loss: 0.0317
Epoch  25 Batch  700/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9205, Loss: 0.0249
Epoch  25 Batch  720/1077 - Train Accuracy: 0.9396, Validation Accuracy: 0.9247, Loss: 0.0326
Epoch  25 Batch  740/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.9283, Loss: 0.0278
Epoch  25 Batch  760/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9329, Loss: 0.0331
Epoch  25 Batch  780/1077 - Train Accuracy: 0.9301, Validation Accuracy: 0.9332, Loss: 0.0417
Epoch  25 Batch  800/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9418, Loss: 0.0269
Epoch  25 Batch  820/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9212, Loss: 0.0289
Epoch  25 Batch  840/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9332, Loss: 0.0324
Epoch  25 Batch  860/1077 - Train Accuracy: 0.9420, Validation Accuracy: 0.9226, Loss: 0.0385
Epoch  25 Batch  880/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9311, Loss: 0.0334
Epoch  25 Batch  900/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9237, Loss: 0.0370
Epoch  25 Batch  920/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9265, Loss: 0.0271
Epoch  25 Batch  940/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9286, Loss: 0.0276
Epoch  25 Batch  960/1077 - Train Accuracy: 0.9572, Validation Accuracy: 0.9297, Loss: 0.0249
Epoch  25 Batch  980/1077 - Train Accuracy: 0.9230, Validation Accuracy: 0.9393, Loss: 0.0329
Epoch  25 Batch 1000/1077 - Train Accuracy: 0.9442, Validation Accuracy: 0.9244, Loss: 0.0288
Epoch  25 Batch 1020/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9215, Loss: 0.0209
Epoch  25 Batch 1040/1077 - Train Accuracy: 0.9564, Validation Accuracy: 0.9272, Loss: 0.0283
Epoch  25 Batch 1060/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9354, Loss: 0.0248
Epoch  26 Batch   20/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9371, Loss: 0.0242
Epoch  26 Batch   40/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9492, Loss: 0.0248
Epoch  26 Batch   60/1077 - Train Accuracy: 0.9550, Validation Accuracy: 0.9393, Loss: 0.0221
Epoch  26 Batch   80/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9318, Loss: 0.0282
Epoch  26 Batch  100/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9290, Loss: 0.0326
Epoch  26 Batch  120/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9368, Loss: 0.0363
Epoch  26 Batch  140/1077 - Train Accuracy: 0.9745, Validation Accuracy: 0.9432, Loss: 0.0257
Epoch  26 Batch  160/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9393, Loss: 0.0257
Epoch  26 Batch  180/1077 - Train Accuracy: 0.9398, Validation Accuracy: 0.9325, Loss: 0.0256
Epoch  26 Batch  200/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.9382, Loss: 0.0282
Epoch  26 Batch  220/1077 - Train Accuracy: 0.9470, Validation Accuracy: 0.9265, Loss: 0.0434
Epoch  26 Batch  240/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9318, Loss: 0.0231
Epoch  26 Batch  260/1077 - Train Accuracy: 0.9129, Validation Accuracy: 0.9180, Loss: 0.0251
Epoch  26 Batch  280/1077 - Train Accuracy: 0.9055, Validation Accuracy: 0.9283, Loss: 0.0366
Epoch  26 Batch  300/1077 - Train Accuracy: 0.9663, Validation Accuracy: 0.9158, Loss: 0.0231
Epoch  26 Batch  320/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9254, Loss: 0.0335
Epoch  26 Batch  340/1077 - Train Accuracy: 0.9589, Validation Accuracy: 0.9290, Loss: 0.0295
Epoch  26 Batch  360/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9293, Loss: 0.0228
Epoch  26 Batch  380/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9205, Loss: 0.0236
Epoch  26 Batch  400/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9290, Loss: 0.0314
Epoch  26 Batch  420/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9233, Loss: 0.0209
Epoch  26 Batch  440/1077 - Train Accuracy: 0.9352, Validation Accuracy: 0.9155, Loss: 0.0356
Epoch  26 Batch  460/1077 - Train Accuracy: 0.9332, Validation Accuracy: 0.9283, Loss: 0.0341
Epoch  26 Batch  480/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9297, Loss: 0.0282
Epoch  26 Batch  500/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9428, Loss: 0.0235
Epoch  26 Batch  520/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9357, Loss: 0.0248
Epoch  26 Batch  540/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9290, Loss: 0.0225
Epoch  26 Batch  560/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9237, Loss: 0.0301
Epoch  26 Batch  580/1077 - Train Accuracy: 0.9587, Validation Accuracy: 0.9233, Loss: 0.0206
Epoch  26 Batch  600/1077 - Train Accuracy: 0.9568, Validation Accuracy: 0.9300, Loss: 0.0320
Epoch  26 Batch  620/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9442, Loss: 0.0270
Epoch  26 Batch  640/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9389, Loss: 0.0254
Epoch  26 Batch  660/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9297, Loss: 0.0258
Epoch  26 Batch  680/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9300, Loss: 0.0318
Epoch  26 Batch  700/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9258, Loss: 0.0245
Epoch  26 Batch  720/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9343, Loss: 0.0316
Epoch  26 Batch  740/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9268, Loss: 0.0269
Epoch  26 Batch  760/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9393, Loss: 0.0306
Epoch  26 Batch  780/1077 - Train Accuracy: 0.9348, Validation Accuracy: 0.9371, Loss: 0.0418
Epoch  26 Batch  800/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9361, Loss: 0.0258
Epoch  26 Batch  820/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9158, Loss: 0.0283
Epoch  26 Batch  840/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9308, Loss: 0.0300
Epoch  26 Batch  860/1077 - Train Accuracy: 0.9576, Validation Accuracy: 0.9336, Loss: 0.0365
Epoch  26 Batch  880/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9258, Loss: 0.0319
Epoch  26 Batch  900/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9279, Loss: 0.0359
Epoch  26 Batch  920/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9268, Loss: 0.0268
Epoch  26 Batch  940/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9279, Loss: 0.0263
Epoch  26 Batch  960/1077 - Train Accuracy: 0.9475, Validation Accuracy: 0.9272, Loss: 0.0266
Epoch  26 Batch  980/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.9389, Loss: 0.0314
Epoch  26 Batch 1000/1077 - Train Accuracy: 0.9468, Validation Accuracy: 0.9251, Loss: 0.0282
Epoch  26 Batch 1020/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9144, Loss: 0.0209
Epoch  26 Batch 1040/1077 - Train Accuracy: 0.9494, Validation Accuracy: 0.9343, Loss: 0.0327
Epoch  26 Batch 1060/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9446, Loss: 0.0277
Epoch  27 Batch   20/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9293, Loss: 0.0217
Epoch  27 Batch   40/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9425, Loss: 0.0239
Epoch  27 Batch   60/1077 - Train Accuracy: 0.9572, Validation Accuracy: 0.9386, Loss: 0.0220
Epoch  27 Batch   80/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9258, Loss: 0.0269
Epoch  27 Batch  100/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9435, Loss: 0.0315
Epoch  27 Batch  120/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9386, Loss: 0.0349
Epoch  27 Batch  140/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9414, Loss: 0.0242
Epoch  27 Batch  160/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9339, Loss: 0.0246
Epoch  27 Batch  180/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9265, Loss: 0.0245
Epoch  27 Batch  200/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9425, Loss: 0.0275
Epoch  27 Batch  220/1077 - Train Accuracy: 0.9486, Validation Accuracy: 0.9258, Loss: 0.0418
Epoch  27 Batch  240/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9357, Loss: 0.0209
Epoch  27 Batch  260/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.9251, Loss: 0.0237
Epoch  27 Batch  280/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.9208, Loss: 0.0338
Epoch  27 Batch  300/1077 - Train Accuracy: 0.9720, Validation Accuracy: 0.9201, Loss: 0.0225
Epoch  27 Batch  320/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.9276, Loss: 0.0309
Epoch  27 Batch  340/1077 - Train Accuracy: 0.9634, Validation Accuracy: 0.9286, Loss: 0.0277
Epoch  27 Batch  360/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9354, Loss: 0.0212
Epoch  27 Batch  380/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9251, Loss: 0.0234
Epoch  27 Batch  400/1077 - Train Accuracy: 0.9367, Validation Accuracy: 0.9368, Loss: 0.0298
Epoch  27 Batch  420/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9247, Loss: 0.0196
Epoch  27 Batch  440/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.9208, Loss: 0.0331
Epoch  27 Batch  460/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9371, Loss: 0.0320
Epoch  27 Batch  480/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9329, Loss: 0.0266
Epoch  27 Batch  500/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9432, Loss: 0.0220
Epoch  27 Batch  520/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9357, Loss: 0.0229
Epoch  27 Batch  540/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9322, Loss: 0.0207
Epoch  27 Batch  560/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9386, Loss: 0.0299
Epoch  27 Batch  580/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9258, Loss: 0.0198
Epoch  27 Batch  600/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9421, Loss: 0.0298
Epoch  27 Batch  620/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9407, Loss: 0.0243
Epoch  27 Batch  640/1077 - Train Accuracy: 0.9669, Validation Accuracy: 0.9439, Loss: 0.0231
Epoch  27 Batch  660/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9347, Loss: 0.0248
Epoch  27 Batch  680/1077 - Train Accuracy: 0.9509, Validation Accuracy: 0.9304, Loss: 0.0301
Epoch  27 Batch  700/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9361, Loss: 0.0233
Epoch  27 Batch  720/1077 - Train Accuracy: 0.9285, Validation Accuracy: 0.9403, Loss: 0.0306
Epoch  27 Batch  740/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9368, Loss: 0.0251
Epoch  27 Batch  760/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9425, Loss: 0.0287
Epoch  27 Batch  780/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9375, Loss: 0.0407
Epoch  27 Batch  800/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9418, Loss: 0.0267
Epoch  27 Batch  820/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9357, Loss: 0.0270
Epoch  27 Batch  840/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9300, Loss: 0.0302
Epoch  27 Batch  860/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9311, Loss: 0.0347
Epoch  27 Batch  880/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9318, Loss: 0.0300
Epoch  27 Batch  900/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.9329, Loss: 0.0318
Epoch  27 Batch  920/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9315, Loss: 0.0261
Epoch  27 Batch  940/1077 - Train Accuracy: 0.9426, Validation Accuracy: 0.9272, Loss: 0.0267
Epoch  27 Batch  960/1077 - Train Accuracy: 0.9472, Validation Accuracy: 0.9322, Loss: 0.0281
Epoch  27 Batch  980/1077 - Train Accuracy: 0.9281, Validation Accuracy: 0.9432, Loss: 0.0300
Epoch  27 Batch 1000/1077 - Train Accuracy: 0.9364, Validation Accuracy: 0.9293, Loss: 0.0289
Epoch  27 Batch 1020/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9222, Loss: 0.0198
Epoch  27 Batch 1040/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9300, Loss: 0.0278
Epoch  27 Batch 1060/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9482, Loss: 0.0240
Epoch  28 Batch   20/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9446, Loss: 0.0226
Epoch  28 Batch   40/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9428, Loss: 0.0224
Epoch  28 Batch   60/1077 - Train Accuracy: 0.9587, Validation Accuracy: 0.9446, Loss: 0.0197
Epoch  28 Batch   80/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9332, Loss: 0.0248
Epoch  28 Batch  100/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9439, Loss: 0.0302
Epoch  28 Batch  120/1077 - Train Accuracy: 0.9363, Validation Accuracy: 0.9460, Loss: 0.0314
Epoch  28 Batch  140/1077 - Train Accuracy: 0.9794, Validation Accuracy: 0.9517, Loss: 0.0239
Epoch  28 Batch  160/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9400, Loss: 0.0273
Epoch  28 Batch  180/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9382, Loss: 0.0266
Epoch  28 Batch  200/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.9513, Loss: 0.0270
Epoch  28 Batch  220/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9311, Loss: 0.0407
Epoch  28 Batch  240/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9435, Loss: 0.0211
Epoch  28 Batch  260/1077 - Train Accuracy: 0.9167, Validation Accuracy: 0.9279, Loss: 0.0233
Epoch  28 Batch  280/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.9311, Loss: 0.0334
Epoch  28 Batch  300/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9205, Loss: 0.0217
Epoch  28 Batch  320/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9311, Loss: 0.0289
Epoch  28 Batch  340/1077 - Train Accuracy: 0.9589, Validation Accuracy: 0.9318, Loss: 0.0275
Epoch  28 Batch  360/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9350, Loss: 0.0204
Epoch  28 Batch  380/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9247, Loss: 0.0228
Epoch  28 Batch  400/1077 - Train Accuracy: 0.9336, Validation Accuracy: 0.9290, Loss: 0.0283
Epoch  28 Batch  420/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9244, Loss: 0.0187
Epoch  28 Batch  440/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9261, Loss: 0.0312
Epoch  28 Batch  460/1077 - Train Accuracy: 0.9352, Validation Accuracy: 0.9268, Loss: 0.0330
Epoch  28 Batch  480/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9318, Loss: 0.0253
Epoch  28 Batch  500/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9421, Loss: 0.0217
Epoch  28 Batch  520/1077 - Train Accuracy: 0.9818, Validation Accuracy: 0.9339, Loss: 0.0210
Epoch  28 Batch  540/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9343, Loss: 0.0197
Epoch  28 Batch  560/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9428, Loss: 0.0269
Epoch  28 Batch  580/1077 - Train Accuracy: 0.9647, Validation Accuracy: 0.9361, Loss: 0.0198
Epoch  28 Batch  600/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9311, Loss: 0.0280
Epoch  28 Batch  620/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9375, Loss: 0.0239
Epoch  28 Batch  640/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9300, Loss: 0.0221
Epoch  28 Batch  660/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9347, Loss: 0.0229
Epoch  28 Batch  680/1077 - Train Accuracy: 0.9498, Validation Accuracy: 0.9279, Loss: 0.0293
Epoch  28 Batch  700/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9357, Loss: 0.0237
Epoch  28 Batch  720/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9322, Loss: 0.0283
Epoch  28 Batch  740/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9457, Loss: 0.0234
Epoch  28 Batch  760/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9403, Loss: 0.0270
Epoch  28 Batch  780/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9414, Loss: 0.0375
Epoch  28 Batch  800/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9478, Loss: 0.0242
Epoch  28 Batch  820/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9386, Loss: 0.0242
Epoch  28 Batch  840/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9414, Loss: 0.0297
Epoch  28 Batch  860/1077 - Train Accuracy: 0.9435, Validation Accuracy: 0.9325, Loss: 0.0337
Epoch  28 Batch  880/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9308, Loss: 0.0293
Epoch  28 Batch  900/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9428, Loss: 0.0284
Epoch  28 Batch  920/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9407, Loss: 0.0241
Epoch  28 Batch  940/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9279, Loss: 0.0247
Epoch  28 Batch  960/1077 - Train Accuracy: 0.9524, Validation Accuracy: 0.9396, Loss: 0.0236
Epoch  28 Batch  980/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.9506, Loss: 0.0289
Epoch  28 Batch 1000/1077 - Train Accuracy: 0.9416, Validation Accuracy: 0.9343, Loss: 0.0253
Epoch  28 Batch 1020/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9354, Loss: 0.0189
Epoch  28 Batch 1040/1077 - Train Accuracy: 0.9663, Validation Accuracy: 0.9318, Loss: 0.0246
Epoch  28 Batch 1060/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9538, Loss: 0.0232
Epoch  29 Batch   20/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9336, Loss: 0.0197
Epoch  29 Batch   40/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9464, Loss: 0.0212
Epoch  29 Batch   60/1077 - Train Accuracy: 0.9643, Validation Accuracy: 0.9403, Loss: 0.0188
Epoch  29 Batch   80/1077 - Train Accuracy: 0.9426, Validation Accuracy: 0.9418, Loss: 0.0242
Epoch  29 Batch  100/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9457, Loss: 0.0291
Epoch  29 Batch  120/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9407, Loss: 0.0296
Epoch  29 Batch  140/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9467, Loss: 0.0248
Epoch  29 Batch  160/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9389, Loss: 0.0230
Epoch  29 Batch  180/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9386, Loss: 0.0231
Epoch  29 Batch  200/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9471, Loss: 0.0239
Epoch  29 Batch  220/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9364, Loss: 0.0378
Epoch  29 Batch  240/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9400, Loss: 0.0200
Epoch  29 Batch  260/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.9357, Loss: 0.0251
Epoch  29 Batch  280/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.9389, Loss: 0.0336
Epoch  29 Batch  300/1077 - Train Accuracy: 0.9696, Validation Accuracy: 0.9158, Loss: 0.0209
Epoch  29 Batch  320/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.9300, Loss: 0.0296
Epoch  29 Batch  340/1077 - Train Accuracy: 0.9634, Validation Accuracy: 0.9375, Loss: 0.0254
Epoch  29 Batch  360/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9347, Loss: 0.0187
Epoch  29 Batch  380/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9379, Loss: 0.0212
Epoch  29 Batch  400/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9471, Loss: 0.0276
Epoch  29 Batch  420/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9244, Loss: 0.0173
Epoch  29 Batch  440/1077 - Train Accuracy: 0.9367, Validation Accuracy: 0.9293, Loss: 0.0293
Epoch  29 Batch  460/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9379, Loss: 0.0308
Epoch  29 Batch  480/1077 - Train Accuracy: 0.9494, Validation Accuracy: 0.9393, Loss: 0.0242
Epoch  29 Batch  500/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9474, Loss: 0.0207
Epoch  29 Batch  520/1077 - Train Accuracy: 0.9866, Validation Accuracy: 0.9400, Loss: 0.0206
Epoch  29 Batch  540/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9411, Loss: 0.0192
Epoch  29 Batch  560/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9442, Loss: 0.0254
Epoch  29 Batch  580/1077 - Train Accuracy: 0.9643, Validation Accuracy: 0.9283, Loss: 0.0316
Epoch  29 Batch  600/1077 - Train Accuracy: 0.9572, Validation Accuracy: 0.9425, Loss: 0.0289
Epoch  29 Batch  620/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9496, Loss: 0.0233
Epoch  29 Batch  640/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9400, Loss: 0.0215
Epoch  29 Batch  660/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9350, Loss: 0.0219
Epoch  29 Batch  680/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9364, Loss: 0.0282
Epoch  29 Batch  700/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9304, Loss: 0.0216
Epoch  29 Batch  720/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9467, Loss: 0.0282
Epoch  29 Batch  740/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9467, Loss: 0.0238
Epoch  29 Batch  760/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9492, Loss: 0.0257
Epoch  29 Batch  780/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.9464, Loss: 0.0354
Epoch  29 Batch  800/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9425, Loss: 0.0236
Epoch  29 Batch  820/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9393, Loss: 0.0229
Epoch  29 Batch  840/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9439, Loss: 0.0270
Epoch  29 Batch  860/1077 - Train Accuracy: 0.9468, Validation Accuracy: 0.9343, Loss: 0.0334
Epoch  29 Batch  880/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9375, Loss: 0.0273
Epoch  29 Batch  900/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9442, Loss: 0.0288
Epoch  29 Batch  920/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9453, Loss: 0.0268
Epoch  29 Batch  940/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.9375, Loss: 0.0250
Epoch  29 Batch  960/1077 - Train Accuracy: 0.9464, Validation Accuracy: 0.9382, Loss: 0.0214
Epoch  29 Batch  980/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.9489, Loss: 0.0275
Epoch  29 Batch 1000/1077 - Train Accuracy: 0.9334, Validation Accuracy: 0.9336, Loss: 0.0253
Epoch  29 Batch 1020/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9382, Loss: 0.0183
Epoch  29 Batch 1040/1077 - Train Accuracy: 0.9700, Validation Accuracy: 0.9297, Loss: 0.0243
Epoch  29 Batch 1060/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9563, Loss: 0.0211
Epoch  30 Batch   20/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9478, Loss: 0.0191
Epoch  30 Batch   40/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9535, Loss: 0.0216
Epoch  30 Batch   60/1077 - Train Accuracy: 0.9714, Validation Accuracy: 0.9279, Loss: 0.0177
Epoch  30 Batch   80/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9421, Loss: 0.0242
Epoch  30 Batch  100/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9442, Loss: 0.0280
Epoch  30 Batch  120/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9499, Loss: 0.0283
Epoch  30 Batch  140/1077 - Train Accuracy: 0.9618, Validation Accuracy: 0.9560, Loss: 0.0232
Epoch  30 Batch  160/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9748, Loss: 0.0222
Epoch  30 Batch  180/1077 - Train Accuracy: 0.9398, Validation Accuracy: 0.9435, Loss: 0.0217
Epoch  30 Batch  200/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.9499, Loss: 0.0241
Epoch  30 Batch  220/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9361, Loss: 0.0365
Epoch  30 Batch  240/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9482, Loss: 0.0194
Epoch  30 Batch  260/1077 - Train Accuracy: 0.9222, Validation Accuracy: 0.9325, Loss: 0.0223
Epoch  30 Batch  280/1077 - Train Accuracy: 0.9258, Validation Accuracy: 0.9471, Loss: 0.0316
Epoch  30 Batch  300/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9201, Loss: 0.0209
Epoch  30 Batch  320/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9457, Loss: 0.0278
Epoch  30 Batch  340/1077 - Train Accuracy: 0.9704, Validation Accuracy: 0.9368, Loss: 0.0243
Epoch  30 Batch  360/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9322, Loss: 0.0188
Epoch  30 Batch  380/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9375, Loss: 0.0212
Epoch  30 Batch  400/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9510, Loss: 0.0256
Epoch  30 Batch  420/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9396, Loss: 0.0170
Epoch  30 Batch  440/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9229, Loss: 0.0282
Epoch  30 Batch  460/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9414, Loss: 0.0290
Epoch  30 Batch  480/1077 - Train Accuracy: 0.9474, Validation Accuracy: 0.9389, Loss: 0.0226
Epoch  30 Batch  500/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9478, Loss: 0.0205
Epoch  30 Batch  520/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9403, Loss: 0.0200
Epoch  30 Batch  540/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9531, Loss: 0.0182
Epoch  30 Batch  560/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9553, Loss: 0.0246
Epoch  30 Batch  580/1077 - Train Accuracy: 0.9643, Validation Accuracy: 0.9350, Loss: 0.0187
Epoch  30 Batch  600/1077 - Train Accuracy: 0.9669, Validation Accuracy: 0.9418, Loss: 0.0256
Epoch  30 Batch  620/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9467, Loss: 0.0227
Epoch  30 Batch  640/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9467, Loss: 0.0201
Epoch  30 Batch  660/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9347, Loss: 0.0195
Epoch  30 Batch  680/1077 - Train Accuracy: 0.9427, Validation Accuracy: 0.9308, Loss: 0.0272
Epoch  30 Batch  700/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9339, Loss: 0.0203
Epoch  30 Batch  720/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9414, Loss: 0.0267
Epoch  30 Batch  740/1077 - Train Accuracy: 0.9500, Validation Accuracy: 0.9421, Loss: 0.0219
Epoch  30 Batch  760/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9446, Loss: 0.0241
Epoch  30 Batch  780/1077 - Train Accuracy: 0.9355, Validation Accuracy: 0.9425, Loss: 0.0348
Epoch  30 Batch  800/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9471, Loss: 0.0221
Epoch  30 Batch  820/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9460, Loss: 0.0231
Epoch  30 Batch  840/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9482, Loss: 0.0280
Epoch  30 Batch  860/1077 - Train Accuracy: 0.9557, Validation Accuracy: 0.9364, Loss: 0.0324
Epoch  30 Batch  880/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9499, Loss: 0.0274
Epoch  30 Batch  900/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9485, Loss: 0.0267
Epoch  30 Batch  920/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9403, Loss: 0.0251
Epoch  30 Batch  940/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.9329, Loss: 0.0258
Epoch  30 Batch  960/1077 - Train Accuracy: 0.9468, Validation Accuracy: 0.9457, Loss: 0.0209
Epoch  30 Batch  980/1077 - Train Accuracy: 0.9363, Validation Accuracy: 0.9510, Loss: 0.0269
Epoch  30 Batch 1000/1077 - Train Accuracy: 0.9494, Validation Accuracy: 0.9400, Loss: 0.0237
Epoch  30 Batch 1020/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9496, Loss: 0.0174
Epoch  30 Batch 1040/1077 - Train Accuracy: 0.9630, Validation Accuracy: 0.9347, Loss: 0.0233
Epoch  30 Batch 1060/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9545, Loss: 0.0195
Epoch  31 Batch   20/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9513, Loss: 0.0170
Epoch  31 Batch   40/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9535, Loss: 0.0201
Epoch  31 Batch   60/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9457, Loss: 0.0170
Epoch  31 Batch   80/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9499, Loss: 0.0212
Epoch  31 Batch  100/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9478, Loss: 0.0259
Epoch  31 Batch  120/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9531, Loss: 0.0250
Epoch  31 Batch  140/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9503, Loss: 0.0237
Epoch  31 Batch  160/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9663, Loss: 0.0223
Epoch  31 Batch  180/1077 - Train Accuracy: 0.9367, Validation Accuracy: 0.9471, Loss: 0.0214
Epoch  31 Batch  200/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9585, Loss: 0.0213
Epoch  31 Batch  220/1077 - Train Accuracy: 0.9552, Validation Accuracy: 0.9364, Loss: 0.0353
Epoch  31 Batch  240/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9627, Loss: 0.0180
Epoch  31 Batch  260/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.9386, Loss: 0.0214
Epoch  31 Batch  280/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.9496, Loss: 0.0296
Epoch  31 Batch  300/1077 - Train Accuracy: 0.9683, Validation Accuracy: 0.9205, Loss: 0.0196
Epoch  31 Batch  320/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9453, Loss: 0.0242
Epoch  31 Batch  340/1077 - Train Accuracy: 0.9642, Validation Accuracy: 0.9396, Loss: 0.0226
Epoch  31 Batch  360/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9386, Loss: 0.0174
Epoch  31 Batch  380/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9308, Loss: 0.0209
Epoch  31 Batch  400/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9439, Loss: 0.0248
Epoch  31 Batch  420/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9489, Loss: 0.0159
Epoch  31 Batch  440/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9400, Loss: 0.0277
Epoch  31 Batch  460/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9375, Loss: 0.0279
Epoch  31 Batch  480/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9339, Loss: 0.0223
Epoch  31 Batch  500/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9506, Loss: 0.0186
Epoch  31 Batch  520/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9400, Loss: 0.0176
Epoch  31 Batch  540/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9485, Loss: 0.0178
Epoch  31 Batch  560/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9549, Loss: 0.0211
Epoch  31 Batch  580/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9464, Loss: 0.0172
Epoch  31 Batch  600/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9467, Loss: 0.0260
Epoch  31 Batch  620/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9513, Loss: 0.0218
Epoch  31 Batch  640/1077 - Train Accuracy: 0.9665, Validation Accuracy: 0.9354, Loss: 0.0194
Epoch  31 Batch  660/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9432, Loss: 0.0202
Epoch  31 Batch  680/1077 - Train Accuracy: 0.9442, Validation Accuracy: 0.9411, Loss: 0.0271
Epoch  31 Batch  700/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9343, Loss: 0.0195
Epoch  31 Batch  720/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9471, Loss: 0.0253
Epoch  31 Batch  740/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9467, Loss: 0.0218
Epoch  31 Batch  760/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9492, Loss: 0.0222
Epoch  31 Batch  780/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.9432, Loss: 0.0340
Epoch  31 Batch  800/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9414, Loss: 0.0217
Epoch  31 Batch  820/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9421, Loss: 0.0215
Epoch  31 Batch  840/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9524, Loss: 0.0270
Epoch  31 Batch  860/1077 - Train Accuracy: 0.9390, Validation Accuracy: 0.9428, Loss: 0.0310
Epoch  31 Batch  880/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9538, Loss: 0.0261
Epoch  31 Batch  900/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9535, Loss: 0.0250
Epoch  31 Batch  920/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9435, Loss: 0.0246
Epoch  31 Batch  940/1077 - Train Accuracy: 0.9480, Validation Accuracy: 0.9435, Loss: 0.0240
Epoch  31 Batch  960/1077 - Train Accuracy: 0.9431, Validation Accuracy: 0.9453, Loss: 0.0409
Epoch  31 Batch  980/1077 - Train Accuracy: 0.9379, Validation Accuracy: 0.9489, Loss: 0.0283
Epoch  31 Batch 1000/1077 - Train Accuracy: 0.9353, Validation Accuracy: 0.9379, Loss: 0.0263
Epoch  31 Batch 1020/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9485, Loss: 0.0165
Epoch  31 Batch 1040/1077 - Train Accuracy: 0.9618, Validation Accuracy: 0.9432, Loss: 0.0241
Epoch  31 Batch 1060/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9688, Loss: 0.0195
Epoch  32 Batch   20/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9467, Loss: 0.0165
Epoch  32 Batch   40/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9581, Loss: 0.0190
Epoch  32 Batch   60/1077 - Train Accuracy: 0.9665, Validation Accuracy: 0.9471, Loss: 0.0160
Epoch  32 Batch   80/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9499, Loss: 0.0204
Epoch  32 Batch  100/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9531, Loss: 0.0253
Epoch  32 Batch  120/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9545, Loss: 0.0271
Epoch  32 Batch  140/1077 - Train Accuracy: 0.9811, Validation Accuracy: 0.9581, Loss: 0.0208
Epoch  32 Batch  160/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9677, Loss: 0.0207
Epoch  32 Batch  180/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9407, Loss: 0.0201
Epoch  32 Batch  200/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9613, Loss: 0.0202
Epoch  32 Batch  220/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9528, Loss: 0.0347
Epoch  32 Batch  240/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9510, Loss: 0.0175
Epoch  32 Batch  260/1077 - Train Accuracy: 0.9304, Validation Accuracy: 0.9407, Loss: 0.0199
Epoch  32 Batch  280/1077 - Train Accuracy: 0.9309, Validation Accuracy: 0.9513, Loss: 0.0283
Epoch  32 Batch  300/1077 - Train Accuracy: 0.9667, Validation Accuracy: 0.9339, Loss: 0.0198
Epoch  32 Batch  320/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9524, Loss: 0.0229
Epoch  32 Batch  340/1077 - Train Accuracy: 0.9692, Validation Accuracy: 0.9375, Loss: 0.0219
Epoch  32 Batch  360/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9414, Loss: 0.0153
Epoch  32 Batch  380/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9535, Loss: 0.0185
Epoch  32 Batch  400/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9386, Loss: 0.0241
Epoch  32 Batch  420/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9421, Loss: 0.0156
Epoch  32 Batch  440/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9386, Loss: 0.0263
Epoch  32 Batch  460/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9379, Loss: 0.0261
Epoch  32 Batch  480/1077 - Train Accuracy: 0.9564, Validation Accuracy: 0.9393, Loss: 0.0214
Epoch  32 Batch  500/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9531, Loss: 0.0182
Epoch  32 Batch  520/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9499, Loss: 0.0174
Epoch  32 Batch  540/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9432, Loss: 0.0183
Epoch  32 Batch  560/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9549, Loss: 0.0205
Epoch  32 Batch  580/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9414, Loss: 0.0169
Epoch  32 Batch  600/1077 - Train Accuracy: 0.9661, Validation Accuracy: 0.9563, Loss: 0.0246
Epoch  32 Batch  620/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9513, Loss: 0.0211
Epoch  32 Batch  640/1077 - Train Accuracy: 0.9743, Validation Accuracy: 0.9368, Loss: 0.0203
Epoch  32 Batch  660/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9453, Loss: 0.0194
Epoch  32 Batch  680/1077 - Train Accuracy: 0.9390, Validation Accuracy: 0.9379, Loss: 0.0276
Epoch  32 Batch  700/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9421, Loss: 0.0188
Epoch  32 Batch  720/1077 - Train Accuracy: 0.9601, Validation Accuracy: 0.9602, Loss: 0.0255
Epoch  32 Batch  740/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9450, Loss: 0.0203
Epoch  32 Batch  760/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9450, Loss: 0.0250
Epoch  32 Batch  780/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9528, Loss: 0.0303
Epoch  32 Batch  800/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9467, Loss: 0.0217
Epoch  32 Batch  820/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9460, Loss: 0.0225
Epoch  32 Batch  840/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9471, Loss: 0.0296
Epoch  32 Batch  860/1077 - Train Accuracy: 0.9423, Validation Accuracy: 0.9396, Loss: 0.0289
Epoch  32 Batch  880/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9588, Loss: 0.0252
Epoch  32 Batch  900/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9510, Loss: 0.0236
Epoch  32 Batch  920/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9478, Loss: 0.0209
Epoch  32 Batch  940/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9474, Loss: 0.0211
Epoch  32 Batch  960/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9425, Loss: 0.0188
Epoch  32 Batch  980/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9517, Loss: 0.0249
Epoch  32 Batch 1000/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.9396, Loss: 0.0235
Epoch  32 Batch 1020/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9620, Loss: 0.0158
Epoch  32 Batch 1040/1077 - Train Accuracy: 0.9712, Validation Accuracy: 0.9549, Loss: 0.0216
Epoch  32 Batch 1060/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9663, Loss: 0.0180
Epoch  33 Batch   20/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9492, Loss: 0.0154
Epoch  33 Batch   40/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9563, Loss: 0.0181
Epoch  33 Batch   60/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9496, Loss: 0.0153
Epoch  33 Batch   80/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9595, Loss: 0.0187
Epoch  33 Batch  100/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9616, Loss: 0.0245
Epoch  33 Batch  120/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9482, Loss: 0.0259
Epoch  33 Batch  140/1077 - Train Accuracy: 0.9749, Validation Accuracy: 0.9485, Loss: 0.0192
Epoch  33 Batch  160/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9794, Loss: 0.0207
Epoch  33 Batch  180/1077 - Train Accuracy: 0.9344, Validation Accuracy: 0.9457, Loss: 0.0215
Epoch  33 Batch  200/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9613, Loss: 0.0196
Epoch  33 Batch  220/1077 - Train Accuracy: 0.9515, Validation Accuracy: 0.9517, Loss: 0.0329
Epoch  33 Batch  240/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9574, Loss: 0.0172
Epoch  33 Batch  260/1077 - Train Accuracy: 0.9304, Validation Accuracy: 0.9485, Loss: 0.0203
Epoch  33 Batch  280/1077 - Train Accuracy: 0.9348, Validation Accuracy: 0.9513, Loss: 0.0268
Epoch  33 Batch  300/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9364, Loss: 0.0202
Epoch  33 Batch  320/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9613, Loss: 0.0233
Epoch  33 Batch  340/1077 - Train Accuracy: 0.9597, Validation Accuracy: 0.9439, Loss: 0.0215
Epoch  33 Batch  360/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9393, Loss: 0.0149
Epoch  33 Batch  380/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9545, Loss: 0.0206
Epoch  33 Batch  400/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9485, Loss: 0.0220
Epoch  33 Batch  420/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9428, Loss: 0.0147
Epoch  33 Batch  440/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9435, Loss: 0.0247
Epoch  33 Batch  460/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.9542, Loss: 0.0251
Epoch  33 Batch  480/1077 - Train Accuracy: 0.9642, Validation Accuracy: 0.9478, Loss: 0.0202
Epoch  33 Batch  500/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9616, Loss: 0.0173
Epoch  33 Batch  520/1077 - Train Accuracy: 0.9903, Validation Accuracy: 0.9450, Loss: 0.0167
Epoch  33 Batch  540/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9506, Loss: 0.0181
Epoch  33 Batch  560/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9467, Loss: 0.0187
Epoch  33 Batch  580/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9503, Loss: 0.0163
Epoch  33 Batch  600/1077 - Train Accuracy: 0.9714, Validation Accuracy: 0.9421, Loss: 0.0232
Epoch  33 Batch  620/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9510, Loss: 0.0199
Epoch  33 Batch  640/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9521, Loss: 0.0182
Epoch  33 Batch  660/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9528, Loss: 0.0178
Epoch  33 Batch  680/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9453, Loss: 0.0261
Epoch  33 Batch  700/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9524, Loss: 0.0179
Epoch  33 Batch  720/1077 - Train Accuracy: 0.9548, Validation Accuracy: 0.9549, Loss: 0.0248
Epoch  33 Batch  740/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9442, Loss: 0.0193
Epoch  33 Batch  760/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9524, Loss: 0.0204
Epoch  33 Batch  780/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9553, Loss: 0.0296
Epoch  33 Batch  800/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9467, Loss: 0.0212
Epoch  33 Batch  820/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9588, Loss: 0.0218
Epoch  33 Batch  840/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9535, Loss: 0.0257
Epoch  33 Batch  860/1077 - Train Accuracy: 0.9468, Validation Accuracy: 0.9563, Loss: 0.0285
Epoch  33 Batch  880/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9570, Loss: 0.0251
Epoch  33 Batch  900/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9517, Loss: 0.0248
Epoch  33 Batch  920/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9535, Loss: 0.0215
Epoch  33 Batch  940/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9673, Loss: 0.0247
Epoch  33 Batch  960/1077 - Train Accuracy: 0.9576, Validation Accuracy: 0.9457, Loss: 0.0192
Epoch  33 Batch  980/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9496, Loss: 0.0243
Epoch  33 Batch 1000/1077 - Train Accuracy: 0.9420, Validation Accuracy: 0.9371, Loss: 0.0225
Epoch  33 Batch 1020/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9517, Loss: 0.0149
Epoch  33 Batch 1040/1077 - Train Accuracy: 0.9716, Validation Accuracy: 0.9442, Loss: 0.0206
Epoch  33 Batch 1060/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9609, Loss: 0.0179
Epoch  34 Batch   20/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9361, Loss: 0.0138
Epoch  34 Batch   40/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9613, Loss: 0.0186
Epoch  34 Batch   60/1077 - Train Accuracy: 0.9673, Validation Accuracy: 0.9538, Loss: 0.0169
Epoch  34 Batch   80/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9613, Loss: 0.0189
Epoch  34 Batch  100/1077 - Train Accuracy: 0.9480, Validation Accuracy: 0.9627, Loss: 0.0235
Epoch  34 Batch  120/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9592, Loss: 0.0272
Epoch  34 Batch  140/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9563, Loss: 0.0182
Epoch  34 Batch  160/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9691, Loss: 0.0203
Epoch  34 Batch  180/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9506, Loss: 0.0196
Epoch  34 Batch  200/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9602, Loss: 0.0189
Epoch  34 Batch  220/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9482, Loss: 0.0315
Epoch  34 Batch  240/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9638, Loss: 0.0158
Epoch  34 Batch  260/1077 - Train Accuracy: 0.9416, Validation Accuracy: 0.9457, Loss: 0.0190
Epoch  34 Batch  280/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.9446, Loss: 0.0275
Epoch  34 Batch  300/1077 - Train Accuracy: 0.9618, Validation Accuracy: 0.9492, Loss: 0.0214
Epoch  34 Batch  320/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9595, Loss: 0.0218
Epoch  34 Batch  340/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9563, Loss: 0.0213
Epoch  34 Batch  360/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9478, Loss: 0.0144
Epoch  34 Batch  380/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9528, Loss: 0.0162
Epoch  34 Batch  400/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9538, Loss: 0.0215
Epoch  34 Batch  420/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9570, Loss: 0.0135
Epoch  34 Batch  440/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9496, Loss: 0.0342
Epoch  34 Batch  460/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.9425, Loss: 0.0237
Epoch  34 Batch  480/1077 - Train Accuracy: 0.9597, Validation Accuracy: 0.9535, Loss: 0.0203
Epoch  34 Batch  500/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9474, Loss: 0.0180
Epoch  34 Batch  520/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9492, Loss: 0.0163
Epoch  34 Batch  540/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9510, Loss: 0.0163
Epoch  34 Batch  560/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9489, Loss: 0.0192
Epoch  34 Batch  580/1077 - Train Accuracy: 0.9721, Validation Accuracy: 0.9521, Loss: 0.0150
Epoch  34 Batch  600/1077 - Train Accuracy: 0.9628, Validation Accuracy: 0.9521, Loss: 0.0229
Epoch  34 Batch  620/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9567, Loss: 0.0200
Epoch  34 Batch  640/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9457, Loss: 0.0179
Epoch  34 Batch  660/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9517, Loss: 0.0189
Epoch  34 Batch  680/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.9524, Loss: 0.0267
Epoch  34 Batch  700/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9474, Loss: 0.0180
Epoch  34 Batch  720/1077 - Train Accuracy: 0.9589, Validation Accuracy: 0.9567, Loss: 0.0241
Epoch  34 Batch  740/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9446, Loss: 0.0187
Epoch  34 Batch  760/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9574, Loss: 0.0206
Epoch  34 Batch  780/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9528, Loss: 0.0287
Epoch  34 Batch  800/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9311, Loss: 0.0199
Epoch  34 Batch  820/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9450, Loss: 0.0188
Epoch  34 Batch  840/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9418, Loss: 0.0261
Epoch  34 Batch  860/1077 - Train Accuracy: 0.9464, Validation Accuracy: 0.9563, Loss: 0.0265
Epoch  34 Batch  880/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9595, Loss: 0.0228
Epoch  34 Batch  900/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9613, Loss: 0.0222
Epoch  34 Batch  920/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9510, Loss: 0.0192
Epoch  34 Batch  940/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9666, Loss: 0.0197
Epoch  34 Batch  960/1077 - Train Accuracy: 0.9528, Validation Accuracy: 0.9503, Loss: 0.0176
Epoch  34 Batch  980/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9517, Loss: 0.0231
Epoch  34 Batch 1000/1077 - Train Accuracy: 0.9405, Validation Accuracy: 0.9375, Loss: 0.0220
Epoch  34 Batch 1020/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9645, Loss: 0.0142
Epoch  34 Batch 1040/1077 - Train Accuracy: 0.9720, Validation Accuracy: 0.9641, Loss: 0.0195
Epoch  34 Batch 1060/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9712, Loss: 0.0175
Epoch  35 Batch   20/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9517, Loss: 0.0134
Epoch  35 Batch   40/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9712, Loss: 0.0168
Epoch  35 Batch   60/1077 - Train Accuracy: 0.9658, Validation Accuracy: 0.9556, Loss: 0.0155
Epoch  35 Batch   80/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9688, Loss: 0.0174
Epoch  35 Batch  100/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9627, Loss: 0.0225
Epoch  35 Batch  120/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9599, Loss: 0.0220
Epoch  35 Batch  140/1077 - Train Accuracy: 0.9868, Validation Accuracy: 0.9645, Loss: 0.0180
Epoch  35 Batch  160/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9648, Loss: 0.0203
Epoch  35 Batch  180/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9371, Loss: 0.0190
Epoch  35 Batch  200/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9613, Loss: 0.0178
Epoch  35 Batch  220/1077 - Train Accuracy: 0.9597, Validation Accuracy: 0.9627, Loss: 0.0285
Epoch  35 Batch  240/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9624, Loss: 0.0152
Epoch  35 Batch  260/1077 - Train Accuracy: 0.9464, Validation Accuracy: 0.9464, Loss: 0.0176
Epoch  35 Batch  280/1077 - Train Accuracy: 0.9328, Validation Accuracy: 0.9467, Loss: 0.0262
Epoch  35 Batch  300/1077 - Train Accuracy: 0.9696, Validation Accuracy: 0.9432, Loss: 0.0199
Epoch  35 Batch  320/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9638, Loss: 0.0211
Epoch  35 Batch  340/1077 - Train Accuracy: 0.9745, Validation Accuracy: 0.9581, Loss: 0.0202
Epoch  35 Batch  360/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9577, Loss: 0.0138
Epoch  35 Batch  380/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9482, Loss: 0.0159
Epoch  35 Batch  400/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9581, Loss: 0.0218
Epoch  35 Batch  420/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9418, Loss: 0.0134
Epoch  35 Batch  440/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9545, Loss: 0.0226
Epoch  35 Batch  460/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9478, Loss: 0.0226
Epoch  35 Batch  480/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9531, Loss: 0.0188
Epoch  35 Batch  500/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9506, Loss: 0.0183
Epoch  35 Batch  520/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9467, Loss: 0.0152
Epoch  35 Batch  540/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9482, Loss: 0.0181
Epoch  35 Batch  560/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9524, Loss: 0.0184
Epoch  35 Batch  580/1077 - Train Accuracy: 0.9714, Validation Accuracy: 0.9574, Loss: 0.0148
Epoch  35 Batch  600/1077 - Train Accuracy: 0.9661, Validation Accuracy: 0.9521, Loss: 0.0248
Epoch  35 Batch  620/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9538, Loss: 0.0193
Epoch  35 Batch  640/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9560, Loss: 0.0166
Epoch  35 Batch  660/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9503, Loss: 0.0168
Epoch  35 Batch  680/1077 - Train Accuracy: 0.9487, Validation Accuracy: 0.9379, Loss: 0.0257
Epoch  35 Batch  700/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9499, Loss: 0.0168
Epoch  35 Batch  720/1077 - Train Accuracy: 0.9601, Validation Accuracy: 0.9517, Loss: 0.0318
Epoch  35 Batch  740/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9407, Loss: 0.0366
Epoch  35 Batch  760/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9492, Loss: 0.0276
Epoch  35 Batch  780/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9403, Loss: 0.0312
Epoch  35 Batch  800/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9613, Loss: 0.0201
Epoch  35 Batch  820/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9464, Loss: 0.0167
Epoch  35 Batch  840/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9521, Loss: 0.0237
Epoch  35 Batch  860/1077 - Train Accuracy: 0.9472, Validation Accuracy: 0.9542, Loss: 0.0258
Epoch  35 Batch  880/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9638, Loss: 0.0228
Epoch  35 Batch  900/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9670, Loss: 0.0216
Epoch  35 Batch  920/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9602, Loss: 0.0184
Epoch  35 Batch  940/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9613, Loss: 0.0203
Epoch  35 Batch  960/1077 - Train Accuracy: 0.9561, Validation Accuracy: 0.9592, Loss: 0.0221
Epoch  35 Batch  980/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9581, Loss: 0.0246
Epoch  35 Batch 1000/1077 - Train Accuracy: 0.9498, Validation Accuracy: 0.9446, Loss: 0.0209
Epoch  35 Batch 1020/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9666, Loss: 0.0139
Epoch  35 Batch 1040/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9599, Loss: 0.0187
Epoch  35 Batch 1060/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9727, Loss: 0.0164
Epoch  36 Batch   20/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9524, Loss: 0.0139
Epoch  36 Batch   40/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9684, Loss: 0.0180
Epoch  36 Batch   60/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9588, Loss: 0.0148
Epoch  36 Batch   80/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9599, Loss: 0.0167
Epoch  36 Batch  100/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9627, Loss: 0.0207
Epoch  36 Batch  120/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9645, Loss: 0.0223
Epoch  36 Batch  140/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9517, Loss: 0.0173
Epoch  36 Batch  160/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9709, Loss: 0.0179
Epoch  36 Batch  180/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9489, Loss: 0.0161
Epoch  36 Batch  200/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9645, Loss: 0.0180
Epoch  36 Batch  220/1077 - Train Accuracy: 0.9568, Validation Accuracy: 0.9553, Loss: 0.0274
Epoch  36 Batch  240/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9624, Loss: 0.0148
Epoch  36 Batch  260/1077 - Train Accuracy: 0.9315, Validation Accuracy: 0.9499, Loss: 0.0187
Epoch  36 Batch  280/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.9499, Loss: 0.0254
Epoch  36 Batch  300/1077 - Train Accuracy: 0.9696, Validation Accuracy: 0.9474, Loss: 0.0217
Epoch  36 Batch  320/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9624, Loss: 0.0226
Epoch  36 Batch  340/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9648, Loss: 0.0204
Epoch  36 Batch  360/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9531, Loss: 0.0141
Epoch  36 Batch  380/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9641, Loss: 0.0166
Epoch  36 Batch  400/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9581, Loss: 0.0192
Epoch  36 Batch  420/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9492, Loss: 0.0122
Epoch  36 Batch  440/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9446, Loss: 0.0237
Epoch  36 Batch  460/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9425, Loss: 0.0210
Epoch  36 Batch  480/1077 - Train Accuracy: 0.9593, Validation Accuracy: 0.9588, Loss: 0.0179
Epoch  36 Batch  500/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9577, Loss: 0.0150
Epoch  36 Batch  520/1077 - Train Accuracy: 0.9892, Validation Accuracy: 0.9450, Loss: 0.0143
Epoch  36 Batch  540/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9510, Loss: 0.0149
Epoch  36 Batch  560/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9524, Loss: 0.0160
Epoch  36 Batch  580/1077 - Train Accuracy: 0.9717, Validation Accuracy: 0.9570, Loss: 0.0146
Epoch  36 Batch  600/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9570, Loss: 0.0239
Epoch  36 Batch  620/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9592, Loss: 0.0177
Epoch  36 Batch  640/1077 - Train Accuracy: 0.9736, Validation Accuracy: 0.9567, Loss: 0.0159
Epoch  36 Batch  660/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9545, Loss: 0.0162
Epoch  36 Batch  680/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9474, Loss: 0.0257
Epoch  36 Batch  700/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9545, Loss: 0.0174
Epoch  36 Batch  720/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9606, Loss: 0.0242
Epoch  36 Batch  740/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9592, Loss: 0.0177
Epoch  36 Batch  760/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9624, Loss: 0.0182
Epoch  36 Batch  780/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9549, Loss: 0.0262
Epoch  36 Batch  800/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9542, Loss: 0.0185
Epoch  36 Batch  820/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9634, Loss: 0.0163
Epoch  36 Batch  840/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9467, Loss: 0.0228
Epoch  36 Batch  860/1077 - Train Accuracy: 0.9509, Validation Accuracy: 0.9592, Loss: 0.0243
Epoch  36 Batch  880/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9631, Loss: 0.0219
Epoch  36 Batch  900/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9616, Loss: 0.0213
Epoch  36 Batch  920/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9620, Loss: 0.0179
Epoch  36 Batch  940/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9645, Loss: 0.0182
Epoch  36 Batch  960/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9403, Loss: 0.0177
Epoch  36 Batch  980/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9595, Loss: 0.0218
Epoch  36 Batch 1000/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9464, Loss: 0.0213
Epoch  36 Batch 1020/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9542, Loss: 0.0141
Epoch  36 Batch 1040/1077 - Train Accuracy: 0.9712, Validation Accuracy: 0.9631, Loss: 0.0183
Epoch  36 Batch 1060/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9684, Loss: 0.0162
Epoch  37 Batch   20/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9634, Loss: 0.0124
Epoch  37 Batch   40/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9663, Loss: 0.0166
Epoch  37 Batch   60/1077 - Train Accuracy: 0.9658, Validation Accuracy: 0.9588, Loss: 0.0158
Epoch  37 Batch   80/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9656, Loss: 0.0163
Epoch  37 Batch  100/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9613, Loss: 0.0232
Epoch  37 Batch  120/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9648, Loss: 0.0222
Epoch  37 Batch  140/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9570, Loss: 0.0165
Epoch  37 Batch  160/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9712, Loss: 0.0176
Epoch  37 Batch  180/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9464, Loss: 0.0171
Epoch  37 Batch  200/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9698, Loss: 0.0171
Epoch  37 Batch  220/1077 - Train Accuracy: 0.9576, Validation Accuracy: 0.9574, Loss: 0.0286
Epoch  37 Batch  240/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9641, Loss: 0.0153
Epoch  37 Batch  260/1077 - Train Accuracy: 0.9420, Validation Accuracy: 0.9460, Loss: 0.0165
Epoch  37 Batch  280/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9563, Loss: 0.0246
Epoch  37 Batch  300/1077 - Train Accuracy: 0.9696, Validation Accuracy: 0.9435, Loss: 0.0195
Epoch  37 Batch  320/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9641, Loss: 0.0199
Epoch  37 Batch  340/1077 - Train Accuracy: 0.9745, Validation Accuracy: 0.9634, Loss: 0.0194
Epoch  37 Batch  360/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9467, Loss: 0.0126
Epoch  37 Batch  380/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9620, Loss: 0.0159
Epoch  37 Batch  400/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9563, Loss: 0.0191
Epoch  37 Batch  420/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9556, Loss: 0.0115
Epoch  37 Batch  440/1077 - Train Accuracy: 0.9402, Validation Accuracy: 0.9496, Loss: 0.0226
Epoch  37 Batch  460/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9482, Loss: 0.0205
Epoch  37 Batch  480/1077 - Train Accuracy: 0.9622, Validation Accuracy: 0.9577, Loss: 0.0171
Epoch  37 Batch  500/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9592, Loss: 0.0154
Epoch  37 Batch  520/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9496, Loss: 0.0131
Epoch  37 Batch  540/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9510, Loss: 0.0158
Epoch  37 Batch  560/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9517, Loss: 0.0161
Epoch  37 Batch  580/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9535, Loss: 0.0150
Epoch  37 Batch  600/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9567, Loss: 0.0216
Epoch  37 Batch  620/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9503, Loss: 0.0177
Epoch  37 Batch  640/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9616, Loss: 0.0169
Epoch  37 Batch  660/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9517, Loss: 0.0158
Epoch  37 Batch  680/1077 - Train Accuracy: 0.9542, Validation Accuracy: 0.9482, Loss: 0.0244
Epoch  37 Batch  700/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9545, Loss: 0.0162
Epoch  37 Batch  720/1077 - Train Accuracy: 0.9593, Validation Accuracy: 0.9663, Loss: 0.0234
Epoch  37 Batch  740/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9606, Loss: 0.0167
Epoch  37 Batch  760/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9723, Loss: 0.0176
Epoch  37 Batch  780/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9542, Loss: 0.0249
Epoch  37 Batch  800/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9496, Loss: 0.0177
Epoch  37 Batch  820/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9549, Loss: 0.0169
Epoch  37 Batch  840/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9567, Loss: 0.0229
Epoch  37 Batch  860/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9570, Loss: 0.0221
Epoch  37 Batch  880/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9606, Loss: 0.0203
Epoch  37 Batch  900/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9613, Loss: 0.0215
Epoch  37 Batch  920/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9560, Loss: 0.0191
Epoch  37 Batch  940/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9691, Loss: 0.0172
Epoch  37 Batch  960/1077 - Train Accuracy: 0.9628, Validation Accuracy: 0.9613, Loss: 0.0164
Epoch  37 Batch  980/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9517, Loss: 0.0214
Epoch  37 Batch 1000/1077 - Train Accuracy: 0.9464, Validation Accuracy: 0.9609, Loss: 0.0226
Epoch  37 Batch 1020/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9549, Loss: 0.0135
Epoch  37 Batch 1040/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9648, Loss: 0.0195
Epoch  37 Batch 1060/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9684, Loss: 0.0154
Epoch  38 Batch   20/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9585, Loss: 0.0139
Epoch  38 Batch   40/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9737, Loss: 0.0166
Epoch  38 Batch   60/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9510, Loss: 0.0156
Epoch  38 Batch   80/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9663, Loss: 0.0151
Epoch  38 Batch  100/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9638, Loss: 0.0207
Epoch  38 Batch  120/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9656, Loss: 0.0229
Epoch  38 Batch  140/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9609, Loss: 0.0159
Epoch  38 Batch  160/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9645, Loss: 0.0174
Epoch  38 Batch  180/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9585, Loss: 0.0160
Epoch  38 Batch  200/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9624, Loss: 0.0172
Epoch  38 Batch  220/1077 - Train Accuracy: 0.9560, Validation Accuracy: 0.9627, Loss: 0.0285
Epoch  38 Batch  240/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9684, Loss: 0.0135
Epoch  38 Batch  260/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9492, Loss: 0.0167
Epoch  38 Batch  280/1077 - Train Accuracy: 0.9469, Validation Accuracy: 0.9542, Loss: 0.0239
Epoch  38 Batch  300/1077 - Train Accuracy: 0.9683, Validation Accuracy: 0.9432, Loss: 0.0184
Epoch  38 Batch  320/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9627, Loss: 0.0203
Epoch  38 Batch  340/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9638, Loss: 0.0181
Epoch  38 Batch  360/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9517, Loss: 0.0145
Epoch  38 Batch  380/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9620, Loss: 0.0161
Epoch  38 Batch  400/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9549, Loss: 0.0198
Epoch  38 Batch  420/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9485, Loss: 0.0111
Epoch  38 Batch  440/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9542, Loss: 0.0216
Epoch  38 Batch  460/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9435, Loss: 0.0194
Epoch  38 Batch  480/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9609, Loss: 0.0194
Epoch  38 Batch  500/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9585, Loss: 0.0153
Epoch  38 Batch  520/1077 - Train Accuracy: 0.9900, Validation Accuracy: 0.9503, Loss: 0.0128
Epoch  38 Batch  540/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9553, Loss: 0.0158
Epoch  38 Batch  560/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9485, Loss: 0.0173
Epoch  38 Batch  580/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9641, Loss: 0.0140
Epoch  38 Batch  600/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9609, Loss: 0.0213
Epoch  38 Batch  620/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9567, Loss: 0.0187
Epoch  38 Batch  640/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9560, Loss: 0.0148
Epoch  38 Batch  660/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9556, Loss: 0.0159
Epoch  38 Batch  680/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9510, Loss: 0.0268
Epoch  38 Batch  700/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9553, Loss: 0.0170
Epoch  38 Batch  720/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9609, Loss: 0.0253
Epoch  38 Batch  740/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9616, Loss: 0.0157
Epoch  38 Batch  760/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9684, Loss: 0.0176
Epoch  38 Batch  780/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9585, Loss: 0.0254
Epoch  38 Batch  800/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9528, Loss: 0.0177
Epoch  38 Batch  820/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9616, Loss: 0.0150
Epoch  38 Batch  840/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9521, Loss: 0.0209
Epoch  38 Batch  860/1077 - Train Accuracy: 0.9550, Validation Accuracy: 0.9634, Loss: 0.0225
Epoch  38 Batch  880/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9663, Loss: 0.0204
Epoch  38 Batch  900/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9663, Loss: 0.0191
Epoch  38 Batch  920/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9581, Loss: 0.0165
Epoch  38 Batch  940/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9691, Loss: 0.0172
Epoch  38 Batch  960/1077 - Train Accuracy: 0.9628, Validation Accuracy: 0.9446, Loss: 0.0148
Epoch  38 Batch  980/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9517, Loss: 0.0203
Epoch  38 Batch 1000/1077 - Train Accuracy: 0.9412, Validation Accuracy: 0.9467, Loss: 0.0202
Epoch  38 Batch 1020/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9620, Loss: 0.0123
Epoch  38 Batch 1040/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9627, Loss: 0.0183
Epoch  38 Batch 1060/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9677, Loss: 0.0145
Epoch  39 Batch   20/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9609, Loss: 0.0140
Epoch  39 Batch   40/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9634, Loss: 0.0201
Epoch  39 Batch   60/1077 - Train Accuracy: 0.9740, Validation Accuracy: 0.9535, Loss: 0.0150
Epoch  39 Batch   80/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9684, Loss: 0.0161
Epoch  39 Batch  100/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9663, Loss: 0.0207
Epoch  39 Batch  120/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9677, Loss: 0.0205
Epoch  39 Batch  140/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9592, Loss: 0.0149
Epoch  39 Batch  160/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9663, Loss: 0.0173
Epoch  39 Batch  180/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9549, Loss: 0.0162
Epoch  39 Batch  200/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9702, Loss: 0.0154
Epoch  39 Batch  220/1077 - Train Accuracy: 0.9585, Validation Accuracy: 0.9627, Loss: 0.0260
Epoch  39 Batch  240/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9524, Loss: 0.0240
Epoch  39 Batch  260/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.9570, Loss: 0.0173
Epoch  39 Batch  280/1077 - Train Accuracy: 0.9359, Validation Accuracy: 0.9542, Loss: 0.0226
Epoch  39 Batch  300/1077 - Train Accuracy: 0.9630, Validation Accuracy: 0.9513, Loss: 0.0198
Epoch  39 Batch  320/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9627, Loss: 0.0195
Epoch  39 Batch  340/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9570, Loss: 0.0189
Epoch  39 Batch  360/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9531, Loss: 0.0131
Epoch  39 Batch  380/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9556, Loss: 0.0147
Epoch  39 Batch  400/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9585, Loss: 0.0186
Epoch  39 Batch  420/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9517, Loss: 0.0108
Epoch  39 Batch  440/1077 - Train Accuracy: 0.9445, Validation Accuracy: 0.9499, Loss: 0.0216
Epoch  39 Batch  460/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9471, Loss: 0.0206
Epoch  39 Batch  480/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9581, Loss: 0.0161
Epoch  39 Batch  500/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9542, Loss: 0.0144
Epoch  39 Batch  520/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9453, Loss: 0.0124
Epoch  39 Batch  540/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9553, Loss: 0.0144
Epoch  39 Batch  560/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9524, Loss: 0.0141
Epoch  39 Batch  580/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9677, Loss: 0.0152
Epoch  39 Batch  600/1077 - Train Accuracy: 0.9706, Validation Accuracy: 0.9570, Loss: 0.0224
Epoch  39 Batch  620/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9620, Loss: 0.0166
Epoch  39 Batch  640/1077 - Train Accuracy: 0.9732, Validation Accuracy: 0.9521, Loss: 0.0158
Epoch  39 Batch  660/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9599, Loss: 0.0137
Epoch  39 Batch  680/1077 - Train Accuracy: 0.9405, Validation Accuracy: 0.9474, Loss: 0.0246
Epoch  39 Batch  700/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9581, Loss: 0.0155
Epoch  39 Batch  720/1077 - Train Accuracy: 0.9585, Validation Accuracy: 0.9712, Loss: 0.0227
Epoch  39 Batch  740/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9616, Loss: 0.0146
Epoch  39 Batch  760/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9648, Loss: 0.0169
Epoch  39 Batch  780/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9528, Loss: 0.0250
Epoch  39 Batch  800/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9631, Loss: 0.0174
Epoch  39 Batch  820/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9631, Loss: 0.0149
Epoch  39 Batch  840/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9517, Loss: 0.0211
Epoch  39 Batch  860/1077 - Train Accuracy: 0.9509, Validation Accuracy: 0.9620, Loss: 0.0234
Epoch  39 Batch  880/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9652, Loss: 0.0179
Epoch  39 Batch  900/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9666, Loss: 0.0187
Epoch  39 Batch  920/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9588, Loss: 0.0160
Epoch  39 Batch  940/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9673, Loss: 0.0173
Epoch  39 Batch  960/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9506, Loss: 0.0150
Epoch  39 Batch  980/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9499, Loss: 0.0201
Epoch  39 Batch 1000/1077 - Train Accuracy: 0.9468, Validation Accuracy: 0.9560, Loss: 0.0187
Epoch  39 Batch 1020/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9602, Loss: 0.0116
Epoch  39 Batch 1040/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9648, Loss: 0.0164
Epoch  39 Batch 1060/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9723, Loss: 0.0140
Epoch  40 Batch   20/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9638, Loss: 0.0112
Epoch  40 Batch   40/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9688, Loss: 0.0155
Epoch  40 Batch   60/1077 - Train Accuracy: 0.9721, Validation Accuracy: 0.9595, Loss: 0.0137
Epoch  40 Batch   80/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9616, Loss: 0.0167
Epoch  40 Batch  100/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9613, Loss: 0.0196
Epoch  40 Batch  120/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9666, Loss: 0.0197
Epoch  40 Batch  140/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9563, Loss: 0.0149
Epoch  40 Batch  160/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9641, Loss: 0.0166
Epoch  40 Batch  180/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9570, Loss: 0.0169
Epoch  40 Batch  200/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9719, Loss: 0.0160
Epoch  40 Batch  220/1077 - Train Accuracy: 0.9593, Validation Accuracy: 0.9677, Loss: 0.0251
Epoch  40 Batch  240/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9691, Loss: 0.0133
Epoch  40 Batch  260/1077 - Train Accuracy: 0.9382, Validation Accuracy: 0.9517, Loss: 0.0151
Epoch  40 Batch  280/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9648, Loss: 0.0221
Epoch  40 Batch  300/1077 - Train Accuracy: 0.9692, Validation Accuracy: 0.9570, Loss: 0.0173
Epoch  40 Batch  320/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9634, Loss: 0.0188
Epoch  40 Batch  340/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9624, Loss: 0.0174
Epoch  40 Batch  360/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9513, Loss: 0.0118
Epoch  40 Batch  380/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9606, Loss: 0.0145
Epoch  40 Batch  400/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9581, Loss: 0.0169
Epoch  40 Batch  420/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9464, Loss: 0.0104
Epoch  40 Batch  440/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9549, Loss: 0.0200
Epoch  40 Batch  460/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9496, Loss: 0.0189
Epoch  40 Batch  480/1077 - Train Accuracy: 0.9671, Validation Accuracy: 0.9595, Loss: 0.0153
Epoch  40 Batch  500/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9535, Loss: 0.0128
Epoch  40 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9553, Loss: 0.0107
Epoch  40 Batch  540/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9556, Loss: 0.0150
Epoch  40 Batch  560/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9496, Loss: 0.0155
Epoch  40 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9666, Loss: 0.0136
Epoch  40 Batch  600/1077 - Train Accuracy: 0.9747, Validation Accuracy: 0.9602, Loss: 0.0199
Epoch  40 Batch  620/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9560, Loss: 0.0193
Epoch  40 Batch  640/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9574, Loss: 0.0153
Epoch  40 Batch  660/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9656, Loss: 0.0142
Epoch  40 Batch  680/1077 - Train Accuracy: 0.9501, Validation Accuracy: 0.9474, Loss: 0.0252
Epoch  40 Batch  700/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9556, Loss: 0.0148
Epoch  40 Batch  720/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9680, Loss: 0.0206
Epoch  40 Batch  740/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9513, Loss: 0.0165
Epoch  40 Batch  760/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9595, Loss: 0.0172
Epoch  40 Batch  780/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9535, Loss: 0.0292
Epoch  40 Batch  800/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9570, Loss: 0.0181
Epoch  40 Batch  820/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9556, Loss: 0.0152
Epoch  40 Batch  840/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9570, Loss: 0.0218
Epoch  40 Batch  860/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9595, Loss: 0.0184
Epoch  40 Batch  880/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9688, Loss: 0.0181
Epoch  40 Batch  900/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9624, Loss: 0.0194
Epoch  40 Batch  920/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9609, Loss: 0.0151
Epoch  40 Batch  940/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9560, Loss: 0.0154
Epoch  40 Batch  960/1077 - Train Accuracy: 0.9654, Validation Accuracy: 0.9556, Loss: 0.0147
Epoch  40 Batch  980/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9577, Loss: 0.0194
Epoch  40 Batch 1000/1077 - Train Accuracy: 0.9431, Validation Accuracy: 0.9521, Loss: 0.0175
Epoch  40 Batch 1020/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9652, Loss: 0.0114
Epoch  40 Batch 1040/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9645, Loss: 0.0162
Epoch  40 Batch 1060/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9688, Loss: 0.0134
Epoch  41 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9698, Loss: 0.0111
Epoch  41 Batch   40/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9691, Loss: 0.0144
Epoch  41 Batch   60/1077 - Train Accuracy: 0.9706, Validation Accuracy: 0.9627, Loss: 0.0139
Epoch  41 Batch   80/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9595, Loss: 0.0177
Epoch  41 Batch  100/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9638, Loss: 0.0200
Epoch  41 Batch  120/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9666, Loss: 0.0186
Epoch  41 Batch  140/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9762, Loss: 0.0149
Epoch  41 Batch  160/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9645, Loss: 0.0164
Epoch  41 Batch  180/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9542, Loss: 0.0144
Epoch  41 Batch  200/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9688, Loss: 0.0149
Epoch  41 Batch  220/1077 - Train Accuracy: 0.9712, Validation Accuracy: 0.9677, Loss: 0.0237
Epoch  41 Batch  240/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9645, Loss: 0.0123
Epoch  41 Batch  260/1077 - Train Accuracy: 0.9308, Validation Accuracy: 0.9535, Loss: 0.0155
Epoch  41 Batch  280/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9627, Loss: 0.0212
Epoch  41 Batch  300/1077 - Train Accuracy: 0.9671, Validation Accuracy: 0.9620, Loss: 0.0170
Epoch  41 Batch  320/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9677, Loss: 0.0193
Epoch  41 Batch  340/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9592, Loss: 0.0204
Epoch  41 Batch  360/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9524, Loss: 0.0118
Epoch  41 Batch  380/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9524, Loss: 0.0144
Epoch  41 Batch  400/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9585, Loss: 0.0174
Epoch  41 Batch  420/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9538, Loss: 0.0101
Epoch  41 Batch  440/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.9503, Loss: 0.0186
Epoch  41 Batch  460/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.9450, Loss: 0.0171
Epoch  41 Batch  480/1077 - Train Accuracy: 0.9671, Validation Accuracy: 0.9585, Loss: 0.0140
Epoch  41 Batch  500/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9499, Loss: 0.0122
Epoch  41 Batch  520/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9460, Loss: 0.0122
Epoch  41 Batch  540/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9609, Loss: 0.0144
Epoch  41 Batch  560/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9521, Loss: 0.0132
Epoch  41 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9719, Loss: 0.0150
Epoch  41 Batch  600/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9620, Loss: 0.0192
Epoch  41 Batch  620/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9620, Loss: 0.0168
Epoch  41 Batch  640/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9616, Loss: 0.0134
Epoch  41 Batch  660/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9545, Loss: 0.0147
Epoch  41 Batch  680/1077 - Train Accuracy: 0.9494, Validation Accuracy: 0.9560, Loss: 0.0247
Epoch  41 Batch  700/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9581, Loss: 0.0156
Epoch  41 Batch  720/1077 - Train Accuracy: 0.9576, Validation Accuracy: 0.9684, Loss: 0.0200
Epoch  41 Batch  740/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9666, Loss: 0.0147
Epoch  41 Batch  760/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9790, Loss: 0.0171
Epoch  41 Batch  780/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9560, Loss: 0.0219
Epoch  41 Batch  800/1077 - Train Accuracy: 0.9500, Validation Accuracy: 0.9577, Loss: 0.0159
Epoch  41 Batch  820/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9585, Loss: 0.0157
Epoch  41 Batch  840/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9524, Loss: 0.0206
Epoch  41 Batch  860/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9627, Loss: 0.0210
Epoch  41 Batch  880/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9645, Loss: 0.0179
Epoch  41 Batch  900/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9592, Loss: 0.0189
Epoch  41 Batch  920/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9602, Loss: 0.0172
Epoch  41 Batch  940/1077 - Train Accuracy: 0.9500, Validation Accuracy: 0.9624, Loss: 0.0147
Epoch  41 Batch  960/1077 - Train Accuracy: 0.9550, Validation Accuracy: 0.9513, Loss: 0.0152
Epoch  41 Batch  980/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9521, Loss: 0.0184
Epoch  41 Batch 1000/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9659, Loss: 0.0183
Epoch  41 Batch 1020/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9616, Loss: 0.0119
Epoch  41 Batch 1040/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9648, Loss: 0.0150
Epoch  41 Batch 1060/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9688, Loss: 0.0130
Epoch  42 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9680, Loss: 0.0111
Epoch  42 Batch   40/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9595, Loss: 0.0153
Epoch  42 Batch   60/1077 - Train Accuracy: 0.9710, Validation Accuracy: 0.9723, Loss: 0.0137
Epoch  42 Batch   80/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9613, Loss: 0.0136
Epoch  42 Batch  100/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9616, Loss: 0.0178
Epoch  42 Batch  120/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9638, Loss: 0.0174
Epoch  42 Batch  140/1077 - Train Accuracy: 0.9897, Validation Accuracy: 0.9659, Loss: 0.0142
Epoch  42 Batch  160/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9641, Loss: 0.0155
Epoch  42 Batch  180/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9570, Loss: 0.0141
Epoch  42 Batch  200/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9709, Loss: 0.0156
Epoch  42 Batch  220/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9680, Loss: 0.0215
Epoch  42 Batch  240/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9688, Loss: 0.0129
Epoch  42 Batch  260/1077 - Train Accuracy: 0.9382, Validation Accuracy: 0.9560, Loss: 0.0146
Epoch  42 Batch  280/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9560, Loss: 0.0206
Epoch  42 Batch  300/1077 - Train Accuracy: 0.9671, Validation Accuracy: 0.9620, Loss: 0.0178
Epoch  42 Batch  320/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9627, Loss: 0.0176
Epoch  42 Batch  340/1077 - Train Accuracy: 0.9786, Validation Accuracy: 0.9616, Loss: 0.0166
Epoch  42 Batch  360/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9517, Loss: 0.0108
Epoch  42 Batch  380/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9606, Loss: 0.0127
Epoch  42 Batch  400/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9602, Loss: 0.0215
Epoch  42 Batch  420/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9581, Loss: 0.0136
Epoch  42 Batch  440/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9506, Loss: 0.0193
Epoch  42 Batch  460/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9510, Loss: 0.0212
Epoch  42 Batch  480/1077 - Train Accuracy: 0.9630, Validation Accuracy: 0.9602, Loss: 0.0172
Epoch  42 Batch  500/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9574, Loss: 0.0135
Epoch  42 Batch  520/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9574, Loss: 0.0113
Epoch  42 Batch  540/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9645, Loss: 0.0155
Epoch  42 Batch  560/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9560, Loss: 0.0154
Epoch  42 Batch  580/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9634, Loss: 0.0115
Epoch  42 Batch  600/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9606, Loss: 0.0201
Epoch  42 Batch  620/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9666, Loss: 0.0154
Epoch  42 Batch  640/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9602, Loss: 0.0134
Epoch  42 Batch  660/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9521, Loss: 0.0132
Epoch  42 Batch  680/1077 - Train Accuracy: 0.9513, Validation Accuracy: 0.9411, Loss: 0.0236
Epoch  42 Batch  700/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9542, Loss: 0.0149
Epoch  42 Batch  720/1077 - Train Accuracy: 0.9675, Validation Accuracy: 0.9702, Loss: 0.0196
Epoch  42 Batch  740/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9666, Loss: 0.0130
Epoch  42 Batch  760/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9819, Loss: 0.0157
Epoch  42 Batch  780/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9577, Loss: 0.0232
Epoch  42 Batch  800/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9496, Loss: 0.0158
Epoch  42 Batch  820/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9666, Loss: 0.0127
Epoch  42 Batch  840/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9510, Loss: 0.0197
Epoch  42 Batch  860/1077 - Train Accuracy: 0.9632, Validation Accuracy: 0.9638, Loss: 0.0178
Epoch  42 Batch  880/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9648, Loss: 0.0169
Epoch  42 Batch  900/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9620, Loss: 0.0178
Epoch  42 Batch  920/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9627, Loss: 0.0144
Epoch  42 Batch  940/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9716, Loss: 0.0147
Epoch  42 Batch  960/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9528, Loss: 0.0137
Epoch  42 Batch  980/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9567, Loss: 0.0181
Epoch  42 Batch 1000/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9634, Loss: 0.0168
Epoch  42 Batch 1020/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9659, Loss: 0.0108
Epoch  42 Batch 1040/1077 - Train Accuracy: 0.9757, Validation Accuracy: 0.9641, Loss: 0.0146
Epoch  42 Batch 1060/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9656, Loss: 0.0121
Epoch  43 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9723, Loss: 0.0113
Epoch  43 Batch   40/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9634, Loss: 0.0137
Epoch  43 Batch   60/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9673, Loss: 0.0128
Epoch  43 Batch   80/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9616, Loss: 0.0137
Epoch  43 Batch  100/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9638, Loss: 0.0191
Epoch  43 Batch  120/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9670, Loss: 0.0185
Epoch  43 Batch  140/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9663, Loss: 0.0139
Epoch  43 Batch  160/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9670, Loss: 0.0154
Epoch  43 Batch  180/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9524, Loss: 0.0132
Epoch  43 Batch  200/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9737, Loss: 0.0142
Epoch  43 Batch  220/1077 - Train Accuracy: 0.9659, Validation Accuracy: 0.9680, Loss: 0.0224
Epoch  43 Batch  240/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9652, Loss: 0.0111
Epoch  43 Batch  260/1077 - Train Accuracy: 0.9308, Validation Accuracy: 0.9620, Loss: 0.0150
Epoch  43 Batch  280/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9489, Loss: 0.0204
Epoch  43 Batch  300/1077 - Train Accuracy: 0.9696, Validation Accuracy: 0.9624, Loss: 0.0170
Epoch  43 Batch  320/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9581, Loss: 0.0178
Epoch  43 Batch  340/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9620, Loss: 0.0170
Epoch  43 Batch  360/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9503, Loss: 0.0109
Epoch  43 Batch  380/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9585, Loss: 0.0124
Epoch  43 Batch  400/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9606, Loss: 0.0157
Epoch  43 Batch  420/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9467, Loss: 0.0096
Epoch  43 Batch  440/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9553, Loss: 0.0179
Epoch  43 Batch  460/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9499, Loss: 0.0158
Epoch  43 Batch  480/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9599, Loss: 0.0140
Epoch  43 Batch  500/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9577, Loss: 0.0125
Epoch  43 Batch  520/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9574, Loss: 0.0092
Epoch  43 Batch  540/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9606, Loss: 0.0156
Epoch  43 Batch  560/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9599, Loss: 0.0156
Epoch  43 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9595, Loss: 0.0129
Epoch  43 Batch  600/1077 - Train Accuracy: 0.9728, Validation Accuracy: 0.9574, Loss: 0.0195
Epoch  43 Batch  620/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9705, Loss: 0.0157
Epoch  43 Batch  640/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9595, Loss: 0.0128
Epoch  43 Batch  660/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9616, Loss: 0.0123
Epoch  43 Batch  680/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9485, Loss: 0.0245
Epoch  43 Batch  700/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9577, Loss: 0.0146
Epoch  43 Batch  720/1077 - Train Accuracy: 0.9568, Validation Accuracy: 0.9659, Loss: 0.0194
Epoch  43 Batch  740/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9549, Loss: 0.0141
Epoch  43 Batch  760/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9638, Loss: 0.0165
Epoch  43 Batch  780/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9656, Loss: 0.0244
Epoch  43 Batch  800/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9460, Loss: 0.0169
Epoch  43 Batch  820/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9727, Loss: 0.0143
Epoch  43 Batch  840/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9538, Loss: 0.0211
Epoch  43 Batch  860/1077 - Train Accuracy: 0.9606, Validation Accuracy: 0.9673, Loss: 0.0223
Epoch  43 Batch  880/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9616, Loss: 0.0171
Epoch  43 Batch  900/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9638, Loss: 0.0175
Epoch  43 Batch  920/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9673, Loss: 0.0150
Epoch  43 Batch  940/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9670, Loss: 0.0148
Epoch  43 Batch  960/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9592, Loss: 0.0136
Epoch  43 Batch  980/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9613, Loss: 0.0178
Epoch  43 Batch 1000/1077 - Train Accuracy: 0.9628, Validation Accuracy: 0.9645, Loss: 0.0174
Epoch  43 Batch 1020/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9620, Loss: 0.0113
Epoch  43 Batch 1040/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9595, Loss: 0.0146
Epoch  43 Batch 1060/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9560, Loss: 0.0126
Epoch  44 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9727, Loss: 0.0093
Epoch  44 Batch   40/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9656, Loss: 0.0142
Epoch  44 Batch   60/1077 - Train Accuracy: 0.9732, Validation Accuracy: 0.9695, Loss: 0.0143
Epoch  44 Batch   80/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9616, Loss: 0.0142
Epoch  44 Batch  100/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9613, Loss: 0.0172
Epoch  44 Batch  120/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9716, Loss: 0.0175
Epoch  44 Batch  140/1077 - Train Accuracy: 0.9873, Validation Accuracy: 0.9613, Loss: 0.0126
Epoch  44 Batch  160/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9620, Loss: 0.0156
Epoch  44 Batch  180/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9620, Loss: 0.0124
Epoch  44 Batch  200/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9691, Loss: 0.0134
Epoch  44 Batch  220/1077 - Train Accuracy: 0.9720, Validation Accuracy: 0.9680, Loss: 0.0204
Epoch  44 Batch  240/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9691, Loss: 0.0115
Epoch  44 Batch  260/1077 - Train Accuracy: 0.9408, Validation Accuracy: 0.9638, Loss: 0.0149
Epoch  44 Batch  280/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9563, Loss: 0.0202
Epoch  44 Batch  300/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9627, Loss: 0.0157
Epoch  44 Batch  320/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9624, Loss: 0.0166
Epoch  44 Batch  340/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9620, Loss: 0.0164
Epoch  44 Batch  360/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9517, Loss: 0.0104
Epoch  44 Batch  380/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9680, Loss: 0.0126
Epoch  44 Batch  400/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9609, Loss: 0.0163
Epoch  44 Batch  420/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9570, Loss: 0.0134
Epoch  44 Batch  440/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9549, Loss: 0.0181
Epoch  44 Batch  460/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9421, Loss: 0.0154
Epoch  44 Batch  480/1077 - Train Accuracy: 0.9733, Validation Accuracy: 0.9638, Loss: 0.0137
Epoch  44 Batch  500/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9570, Loss: 0.0127
Epoch  44 Batch  520/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9524, Loss: 0.0100
Epoch  44 Batch  540/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9574, Loss: 0.0141
Epoch  44 Batch  560/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9524, Loss: 0.0125
Epoch  44 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9659, Loss: 0.0137
Epoch  44 Batch  600/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9588, Loss: 0.0190
Epoch  44 Batch  620/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9719, Loss: 0.0162
Epoch  44 Batch  640/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9638, Loss: 0.0120
Epoch  44 Batch  660/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9606, Loss: 0.0123
Epoch  44 Batch  680/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9521, Loss: 0.0232
Epoch  44 Batch  700/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9531, Loss: 0.0141
Epoch  44 Batch  720/1077 - Train Accuracy: 0.9568, Validation Accuracy: 0.9680, Loss: 0.0242
Epoch  44 Batch  740/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9595, Loss: 0.0150
Epoch  44 Batch  760/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9592, Loss: 0.0175
Epoch  44 Batch  780/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9553, Loss: 0.0255
Epoch  44 Batch  800/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9489, Loss: 0.0150
Epoch  44 Batch  820/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9688, Loss: 0.0147
Epoch  44 Batch  840/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9631, Loss: 0.0211
Epoch  44 Batch  860/1077 - Train Accuracy: 0.9673, Validation Accuracy: 0.9663, Loss: 0.0186
Epoch  44 Batch  880/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9656, Loss: 0.0162
Epoch  44 Batch  900/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9666, Loss: 0.0176
Epoch  44 Batch  920/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9613, Loss: 0.0141
Epoch  44 Batch  940/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9574, Loss: 0.0139
Epoch  44 Batch  960/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9599, Loss: 0.0125
Epoch  44 Batch  980/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9599, Loss: 0.0161
Epoch  44 Batch 1000/1077 - Train Accuracy: 0.9509, Validation Accuracy: 0.9616, Loss: 0.0153
Epoch  44 Batch 1020/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9716, Loss: 0.0105
Epoch  44 Batch 1040/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9648, Loss: 0.0152
Epoch  44 Batch 1060/1077 - Train Accuracy: 0.9980, Validation Accuracy: 0.9545, Loss: 0.0114
Epoch  45 Batch   20/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9645, Loss: 0.0111
Epoch  45 Batch   40/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9663, Loss: 0.0153
Epoch  45 Batch   60/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9691, Loss: 0.0158
Epoch  45 Batch   80/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9620, Loss: 0.0145
Epoch  45 Batch  100/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9631, Loss: 0.0162
Epoch  45 Batch  120/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9666, Loss: 0.0163
Epoch  45 Batch  140/1077 - Train Accuracy: 0.9893, Validation Accuracy: 0.9684, Loss: 0.0124
Epoch  45 Batch  160/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9670, Loss: 0.0150
Epoch  45 Batch  180/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9595, Loss: 0.0125
Epoch  45 Batch  200/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9705, Loss: 0.0131
Epoch  45 Batch  220/1077 - Train Accuracy: 0.9741, Validation Accuracy: 0.9641, Loss: 0.0192
Epoch  45 Batch  240/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9684, Loss: 0.0106
Epoch  45 Batch  260/1077 - Train Accuracy: 0.9565, Validation Accuracy: 0.9542, Loss: 0.0141
Epoch  45 Batch  280/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9542, Loss: 0.0193
Epoch  45 Batch  300/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9616, Loss: 0.0150
Epoch  45 Batch  320/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9634, Loss: 0.0160
Epoch  45 Batch  340/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9624, Loss: 0.0153
Epoch  45 Batch  360/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9563, Loss: 0.0107
Epoch  45 Batch  380/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9588, Loss: 0.0106
Epoch  45 Batch  400/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9627, Loss: 0.0145
Epoch  45 Batch  420/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9474, Loss: 0.0094
Epoch  45 Batch  440/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9549, Loss: 0.0172
Epoch  45 Batch  460/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9432, Loss: 0.0150
Epoch  45 Batch  480/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9602, Loss: 0.0131
Epoch  45 Batch  500/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9577, Loss: 0.0111
Epoch  45 Batch  520/1077 - Train Accuracy: 0.9933, Validation Accuracy: 0.9549, Loss: 0.0095
Epoch  45 Batch  540/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9609, Loss: 0.0141
Epoch  45 Batch  560/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9570, Loss: 0.0131
Epoch  45 Batch  580/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9670, Loss: 0.0127
Epoch  45 Batch  600/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9595, Loss: 0.0184
Epoch  45 Batch  620/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9549, Loss: 0.0148
Epoch  45 Batch  640/1077 - Train Accuracy: 0.9818, Validation Accuracy: 0.9691, Loss: 0.0132
Epoch  45 Batch  660/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9641, Loss: 0.0114
Epoch  45 Batch  680/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9457, Loss: 0.0234
Epoch  45 Batch  700/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9574, Loss: 0.0132
Epoch  45 Batch  720/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9702, Loss: 0.0189
Epoch  45 Batch  740/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9620, Loss: 0.0147
Epoch  45 Batch  760/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9737, Loss: 0.0152
Epoch  45 Batch  780/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9705, Loss: 0.0223
Epoch  45 Batch  800/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9492, Loss: 0.0156
Epoch  45 Batch  820/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9641, Loss: 0.0127
Epoch  45 Batch  840/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9567, Loss: 0.0195
Epoch  45 Batch  860/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9670, Loss: 0.0183
Epoch  45 Batch  880/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9691, Loss: 0.0146
Epoch  45 Batch  900/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9709, Loss: 0.0184
Epoch  45 Batch  920/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9680, Loss: 0.0149
Epoch  45 Batch  940/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9641, Loss: 0.0144
Epoch  45 Batch  960/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9595, Loss: 0.0131
Epoch  45 Batch  980/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9599, Loss: 0.0153
Epoch  45 Batch 1000/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9638, Loss: 0.0166
Epoch  45 Batch 1020/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9709, Loss: 0.0105
Epoch  45 Batch 1040/1077 - Train Accuracy: 0.9757, Validation Accuracy: 0.9595, Loss: 0.0136
Epoch  45 Batch 1060/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9656, Loss: 0.0119
Epoch  46 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9656, Loss: 0.0124
Epoch  46 Batch   40/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9638, Loss: 0.0122
Epoch  46 Batch   60/1077 - Train Accuracy: 0.9736, Validation Accuracy: 0.9652, Loss: 0.0132
Epoch  46 Batch   80/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9666, Loss: 0.0130
Epoch  46 Batch  100/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9613, Loss: 0.0156
Epoch  46 Batch  120/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9719, Loss: 0.0158
Epoch  46 Batch  140/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9652, Loss: 0.0123
Epoch  46 Batch  160/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9659, Loss: 0.0146
Epoch  46 Batch  180/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9510, Loss: 0.0134
Epoch  46 Batch  200/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9702, Loss: 0.0142
Epoch  46 Batch  220/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9648, Loss: 0.0178
Epoch  46 Batch  240/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9688, Loss: 0.0096
Epoch  46 Batch  260/1077 - Train Accuracy: 0.9572, Validation Accuracy: 0.9602, Loss: 0.0136
Epoch  46 Batch  280/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9641, Loss: 0.0190
Epoch  46 Batch  300/1077 - Train Accuracy: 0.9749, Validation Accuracy: 0.9705, Loss: 0.0158
Epoch  46 Batch  320/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9627, Loss: 0.0167
Epoch  46 Batch  340/1077 - Train Accuracy: 0.9729, Validation Accuracy: 0.9595, Loss: 0.0168
Epoch  46 Batch  360/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9585, Loss: 0.0120
Epoch  46 Batch  380/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9538, Loss: 0.0110
Epoch  46 Batch  400/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9663, Loss: 0.0151
Epoch  46 Batch  420/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9474, Loss: 0.0096
Epoch  46 Batch  440/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9560, Loss: 0.0171
Epoch  46 Batch  460/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9531, Loss: 0.0143
Epoch  46 Batch  480/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9606, Loss: 0.0133
Epoch  46 Batch  500/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9577, Loss: 0.0111
Epoch  46 Batch  520/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9513, Loss: 0.0086
Epoch  46 Batch  540/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9602, Loss: 0.0132
Epoch  46 Batch  560/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9560, Loss: 0.0125
Epoch  46 Batch  580/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9620, Loss: 0.0126
Epoch  46 Batch  600/1077 - Train Accuracy: 0.9751, Validation Accuracy: 0.9585, Loss: 0.0176
Epoch  46 Batch  620/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9670, Loss: 0.0142
Epoch  46 Batch  640/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9659, Loss: 0.0135
Epoch  46 Batch  660/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9585, Loss: 0.0112
Epoch  46 Batch  680/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9577, Loss: 0.0221
Epoch  46 Batch  700/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9496, Loss: 0.0134
Epoch  46 Batch  720/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9656, Loss: 0.0189
Epoch  46 Batch  740/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9620, Loss: 0.0114
Epoch  46 Batch  760/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9656, Loss: 0.0134
Epoch  46 Batch  780/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9602, Loss: 0.0212
Epoch  46 Batch  800/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9648, Loss: 0.0135
Epoch  46 Batch  820/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9723, Loss: 0.0122
Epoch  46 Batch  840/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9613, Loss: 0.0184
Epoch  46 Batch  860/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9613, Loss: 0.0171
Epoch  46 Batch  880/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9652, Loss: 0.0149
Epoch  46 Batch  900/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9670, Loss: 0.0169
Epoch  46 Batch  920/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9620, Loss: 0.0152
Epoch  46 Batch  940/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9734, Loss: 0.0118
Epoch  46 Batch  960/1077 - Train Accuracy: 0.9654, Validation Accuracy: 0.9634, Loss: 0.0128
Epoch  46 Batch  980/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9666, Loss: 0.0161
Epoch  46 Batch 1000/1077 - Train Accuracy: 0.9524, Validation Accuracy: 0.9503, Loss: 0.0160
Epoch  46 Batch 1020/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9709, Loss: 0.0102
Epoch  46 Batch 1040/1077 - Train Accuracy: 0.9774, Validation Accuracy: 0.9652, Loss: 0.0142
Epoch  46 Batch 1060/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9599, Loss: 0.0121
Epoch  47 Batch   20/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9737, Loss: 0.0106
Epoch  47 Batch   40/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9691, Loss: 0.0128
Epoch  47 Batch   60/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9688, Loss: 0.0154
Epoch  47 Batch   80/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9613, Loss: 0.0136
Epoch  47 Batch  100/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9638, Loss: 0.0156
Epoch  47 Batch  120/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9719, Loss: 0.0149
Epoch  47 Batch  140/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9712, Loss: 0.0126
Epoch  47 Batch  160/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9620, Loss: 0.0138
Epoch  47 Batch  180/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9567, Loss: 0.0110
Epoch  47 Batch  200/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9759, Loss: 0.0129
Epoch  47 Batch  220/1077 - Train Accuracy: 0.9741, Validation Accuracy: 0.9577, Loss: 0.0187
Epoch  47 Batch  240/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9659, Loss: 0.0093
Epoch  47 Batch  260/1077 - Train Accuracy: 0.9565, Validation Accuracy: 0.9616, Loss: 0.0142
Epoch  47 Batch  280/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9641, Loss: 0.0194
Epoch  47 Batch  300/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9670, Loss: 0.0135
Epoch  47 Batch  320/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9560, Loss: 0.0164
Epoch  47 Batch  340/1077 - Train Accuracy: 0.9749, Validation Accuracy: 0.9624, Loss: 0.0159
Epoch  47 Batch  360/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9588, Loss: 0.0096
Epoch  47 Batch  380/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9588, Loss: 0.0114
Epoch  47 Batch  400/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9634, Loss: 0.0148
Epoch  47 Batch  420/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9478, Loss: 0.0095
Epoch  47 Batch  440/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9609, Loss: 0.0160
Epoch  47 Batch  460/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9450, Loss: 0.0153
Epoch  47 Batch  480/1077 - Train Accuracy: 0.9741, Validation Accuracy: 0.9595, Loss: 0.0142
Epoch  47 Batch  500/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9499, Loss: 0.0114
Epoch  47 Batch  520/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9549, Loss: 0.0081
Epoch  47 Batch  540/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9517, Loss: 0.0130
Epoch  47 Batch  560/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9620, Loss: 0.0128
Epoch  47 Batch  580/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9716, Loss: 0.0126
Epoch  47 Batch  600/1077 - Train Accuracy: 0.9717, Validation Accuracy: 0.9609, Loss: 0.0190
Epoch  47 Batch  620/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9769, Loss: 0.0147
Epoch  47 Batch  640/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9606, Loss: 0.0121
Epoch  47 Batch  660/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9656, Loss: 0.0110
Epoch  47 Batch  680/1077 - Train Accuracy: 0.9632, Validation Accuracy: 0.9513, Loss: 0.0217
Epoch  47 Batch  700/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9506, Loss: 0.0133
Epoch  47 Batch  720/1077 - Train Accuracy: 0.9593, Validation Accuracy: 0.9648, Loss: 0.0206
Epoch  47 Batch  740/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9719, Loss: 0.0140
Epoch  47 Batch  760/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9606, Loss: 0.0153
Epoch  47 Batch  780/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9634, Loss: 0.0203
Epoch  47 Batch  800/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9670, Loss: 0.0136
Epoch  47 Batch  820/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9631, Loss: 0.0122
Epoch  47 Batch  840/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9563, Loss: 0.0179
Epoch  47 Batch  860/1077 - Train Accuracy: 0.9747, Validation Accuracy: 0.9659, Loss: 0.0153
Epoch  47 Batch  880/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9663, Loss: 0.0135
Epoch  47 Batch  900/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9688, Loss: 0.0158
Epoch  47 Batch  920/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9684, Loss: 0.0136
Epoch  47 Batch  940/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9691, Loss: 0.0119
Epoch  47 Batch  960/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9570, Loss: 0.0133
Epoch  47 Batch  980/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9592, Loss: 0.0144
Epoch  47 Batch 1000/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9648, Loss: 0.0160
Epoch  47 Batch 1020/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9670, Loss: 0.0095
Epoch  47 Batch 1040/1077 - Train Accuracy: 0.9757, Validation Accuracy: 0.9648, Loss: 0.0139
Epoch  47 Batch 1060/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9684, Loss: 0.0120
Epoch  48 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9737, Loss: 0.0088
Epoch  48 Batch   40/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9613, Loss: 0.0120
Epoch  48 Batch   60/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9741, Loss: 0.0138
Epoch  48 Batch   80/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9741, Loss: 0.0131
Epoch  48 Batch  100/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9560, Loss: 0.0168
Epoch  48 Batch  120/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9719, Loss: 0.0157
Epoch  48 Batch  140/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9712, Loss: 0.0118
Epoch  48 Batch  160/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9698, Loss: 0.0137
Epoch  48 Batch  180/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9513, Loss: 0.0109
Epoch  48 Batch  200/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9727, Loss: 0.0123
Epoch  48 Batch  220/1077 - Train Accuracy: 0.9741, Validation Accuracy: 0.9691, Loss: 0.0180
Epoch  48 Batch  240/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9656, Loss: 0.0093
Epoch  48 Batch  260/1077 - Train Accuracy: 0.9628, Validation Accuracy: 0.9592, Loss: 0.0134
Epoch  48 Batch  280/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9638, Loss: 0.0181
Epoch  48 Batch  300/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9673, Loss: 0.0128
Epoch  48 Batch  320/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9641, Loss: 0.0160
Epoch  48 Batch  340/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9709, Loss: 0.0153
Epoch  48 Batch  360/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9549, Loss: 0.0089
Epoch  48 Batch  380/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9563, Loss: 0.0099
Epoch  48 Batch  400/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9556, Loss: 0.0130
Epoch  48 Batch  420/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9524, Loss: 0.0090
Epoch  48 Batch  440/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9652, Loss: 0.0174
Epoch  48 Batch  460/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9485, Loss: 0.0146
Epoch  48 Batch  480/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9542, Loss: 0.0142
Epoch  48 Batch  500/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9524, Loss: 0.0138
Epoch  48 Batch  520/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9606, Loss: 0.0146
Epoch  48 Batch  540/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9521, Loss: 0.0147
Epoch  48 Batch  560/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9606, Loss: 0.0111
Epoch  48 Batch  580/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9652, Loss: 0.0113
Epoch  48 Batch  600/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9638, Loss: 0.0168
Epoch  48 Batch  620/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9585, Loss: 0.0152
Epoch  48 Batch  640/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9616, Loss: 0.0118
Epoch  48 Batch  660/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9688, Loss: 0.0115
Epoch  48 Batch  680/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9517, Loss: 0.0216
Epoch  48 Batch  700/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9503, Loss: 0.0119
Epoch  48 Batch  720/1077 - Train Accuracy: 0.9585, Validation Accuracy: 0.9588, Loss: 0.0175
Epoch  48 Batch  740/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9535, Loss: 0.0121
Epoch  48 Batch  760/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9634, Loss: 0.0133
Epoch  48 Batch  780/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9624, Loss: 0.0183
Epoch  48 Batch  800/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9631, Loss: 0.0130
Epoch  48 Batch  820/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9673, Loss: 0.0101
Epoch  48 Batch  840/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9627, Loss: 0.0178
Epoch  48 Batch  860/1077 - Train Accuracy: 0.9743, Validation Accuracy: 0.9606, Loss: 0.0151
Epoch  48 Batch  880/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9716, Loss: 0.0133
Epoch  48 Batch  900/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9606, Loss: 0.0169
Epoch  48 Batch  920/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9684, Loss: 0.0134
Epoch  48 Batch  940/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9698, Loss: 0.0107
Epoch  48 Batch  960/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9645, Loss: 0.0129
Epoch  48 Batch  980/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9549, Loss: 0.0138
Epoch  48 Batch 1000/1077 - Train Accuracy: 0.9658, Validation Accuracy: 0.9595, Loss: 0.0144
Epoch  48 Batch 1020/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9538, Loss: 0.0091
Epoch  48 Batch 1040/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9616, Loss: 0.0129
Epoch  48 Batch 1060/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9595, Loss: 0.0107
Epoch  49 Batch   20/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9695, Loss: 0.0097
Epoch  49 Batch   40/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9670, Loss: 0.0118
Epoch  49 Batch   60/1077 - Train Accuracy: 0.9751, Validation Accuracy: 0.9741, Loss: 0.0130
Epoch  49 Batch   80/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9616, Loss: 0.0134
Epoch  49 Batch  100/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9627, Loss: 0.0160
Epoch  49 Batch  120/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9670, Loss: 0.0150
Epoch  49 Batch  140/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9648, Loss: 0.0117
Epoch  49 Batch  160/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9744, Loss: 0.0134
Epoch  49 Batch  180/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9595, Loss: 0.0103
Epoch  49 Batch  200/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9712, Loss: 0.0124
Epoch  49 Batch  220/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9751, Loss: 0.0177
Epoch  49 Batch  240/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9648, Loss: 0.0087
Epoch  49 Batch  260/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9535, Loss: 0.0136
Epoch  49 Batch  280/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9695, Loss: 0.0192
Epoch  49 Batch  300/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9719, Loss: 0.0137
Epoch  49 Batch  320/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9592, Loss: 0.0159
Epoch  49 Batch  340/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9620, Loss: 0.0165
Epoch  49 Batch  360/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9538, Loss: 0.0093
Epoch  49 Batch  380/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9634, Loss: 0.0083
Epoch  49 Batch  400/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9620, Loss: 0.0130
Epoch  49 Batch  420/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9528, Loss: 0.0088
Epoch  49 Batch  440/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9503, Loss: 0.0146
Epoch  49 Batch  460/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9513, Loss: 0.0133
Epoch  49 Batch  480/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9567, Loss: 0.0134
Epoch  49 Batch  500/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9585, Loss: 0.0095
Epoch  49 Batch  520/1077 - Train Accuracy: 0.9903, Validation Accuracy: 0.9595, Loss: 0.0074
Epoch  49 Batch  540/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9563, Loss: 0.0129
Epoch  49 Batch  560/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9585, Loss: 0.0116
Epoch  49 Batch  580/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9698, Loss: 0.0122
Epoch  49 Batch  600/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9638, Loss: 0.0185
Epoch  49 Batch  620/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9762, Loss: 0.0146
Epoch  49 Batch  640/1077 - Train Accuracy: 0.9740, Validation Accuracy: 0.9620, Loss: 0.0126
Epoch  49 Batch  660/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9577, Loss: 0.0111
Epoch  49 Batch  680/1077 - Train Accuracy: 0.9568, Validation Accuracy: 0.9432, Loss: 0.0227
Epoch  49 Batch  700/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9570, Loss: 0.0118
Epoch  49 Batch  720/1077 - Train Accuracy: 0.9618, Validation Accuracy: 0.9702, Loss: 0.0167
Epoch  49 Batch  740/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9638, Loss: 0.0131
Epoch  49 Batch  760/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9656, Loss: 0.0141
Epoch  49 Batch  780/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9595, Loss: 0.0192
Epoch  49 Batch  800/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9741, Loss: 0.0131
Epoch  49 Batch  820/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9656, Loss: 0.0114
Epoch  49 Batch  840/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9641, Loss: 0.0187
Epoch  49 Batch  860/1077 - Train Accuracy: 0.9740, Validation Accuracy: 0.9684, Loss: 0.0175
Epoch  49 Batch  880/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9659, Loss: 0.0148
Epoch  49 Batch  900/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9730, Loss: 0.0171
Epoch  49 Batch  920/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9585, Loss: 0.0128
Epoch  49 Batch  940/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9787, Loss: 0.0117
Epoch  49 Batch  960/1077 - Train Accuracy: 0.9669, Validation Accuracy: 0.9592, Loss: 0.0130
Epoch  49 Batch  980/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9613, Loss: 0.0129
Epoch  49 Batch 1000/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9702, Loss: 0.0146
Epoch  49 Batch 1020/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9581, Loss: 0.0094
Epoch  49 Batch 1040/1077 - Train Accuracy: 0.9786, Validation Accuracy: 0.9616, Loss: 0.0142
Epoch  49 Batch 1060/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9691, Loss: 0.0117
Epoch  50 Batch   20/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9808, Loss: 0.0103
Epoch  50 Batch   40/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9780, Loss: 0.0107
Epoch  50 Batch   60/1077 - Train Accuracy: 0.9818, Validation Accuracy: 0.9691, Loss: 0.0124
Epoch  50 Batch   80/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9670, Loss: 0.0126
Epoch  50 Batch  100/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9599, Loss: 0.0152
Epoch  50 Batch  120/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9744, Loss: 0.0129
Epoch  50 Batch  140/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9688, Loss: 0.0121
Epoch  50 Batch  160/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9695, Loss: 0.0140
Epoch  50 Batch  180/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9567, Loss: 0.0106
Epoch  50 Batch  200/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9744, Loss: 0.0108
Epoch  50 Batch  220/1077 - Train Accuracy: 0.9741, Validation Accuracy: 0.9670, Loss: 0.0163
Epoch  50 Batch  240/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9570, Loss: 0.0092
Epoch  50 Batch  260/1077 - Train Accuracy: 0.9632, Validation Accuracy: 0.9638, Loss: 0.0117
Epoch  50 Batch  280/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9695, Loss: 0.0179
Epoch  50 Batch  300/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9670, Loss: 0.0128
Epoch  50 Batch  320/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9581, Loss: 0.0163
Epoch  50 Batch  340/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9620, Loss: 0.0147
Epoch  50 Batch  360/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9553, Loss: 0.0088
Epoch  50 Batch  380/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9613, Loss: 0.0082
Epoch  50 Batch  400/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9652, Loss: 0.0123
Epoch  50 Batch  420/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9485, Loss: 0.0085
Epoch  50 Batch  440/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9613, Loss: 0.0143
Epoch  50 Batch  460/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9545, Loss: 0.0123
Epoch  50 Batch  480/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9528, Loss: 0.0122
Epoch  50 Batch  500/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9560, Loss: 0.0100
Epoch  50 Batch  520/1077 - Train Accuracy: 0.9911, Validation Accuracy: 0.9574, Loss: 0.0085
Epoch  50 Batch  540/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9652, Loss: 0.0132
Epoch  50 Batch  560/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9542, Loss: 0.0211
Epoch  50 Batch  580/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9645, Loss: 0.0137
Epoch  50 Batch  600/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9641, Loss: 0.0195
Epoch  50 Batch  620/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9741, Loss: 0.0139
Epoch  50 Batch  640/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9613, Loss: 0.0117
Epoch  50 Batch  660/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9560, Loss: 0.0126
Epoch  50 Batch  680/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9453, Loss: 0.0196
Epoch  50 Batch  700/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9485, Loss: 0.0118
Epoch  50 Batch  720/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9645, Loss: 0.0162
Epoch  50 Batch  740/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9592, Loss: 0.0115
Epoch  50 Batch  760/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9670, Loss: 0.0142
Epoch  50 Batch  780/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9702, Loss: 0.0176
Epoch  50 Batch  800/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9609, Loss: 0.0135
Epoch  50 Batch  820/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9631, Loss: 0.0105
Epoch  50 Batch  840/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9627, Loss: 0.0164
Epoch  50 Batch  860/1077 - Train Accuracy: 0.9747, Validation Accuracy: 0.9620, Loss: 0.0143
Epoch  50 Batch  880/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9702, Loss: 0.0128
Epoch  50 Batch  900/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9666, Loss: 0.0186
Epoch  50 Batch  920/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9691, Loss: 0.0125
Epoch  50 Batch  940/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9759, Loss: 0.0124
Epoch  50 Batch  960/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9620, Loss: 0.0119
Epoch  50 Batch  980/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9624, Loss: 0.0139
Epoch  50 Batch 1000/1077 - Train Accuracy: 0.9717, Validation Accuracy: 0.9616, Loss: 0.0132
Epoch  50 Batch 1020/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9688, Loss: 0.0078
Epoch  50 Batch 1040/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9606, Loss: 0.0130
Epoch  50 Batch 1060/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9670, Loss: 0.0097
Epoch  51 Batch   20/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9762, Loss: 0.0084
Epoch  51 Batch   40/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9737, Loss: 0.0103
Epoch  51 Batch   60/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9666, Loss: 0.0123
Epoch  51 Batch   80/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9652, Loss: 0.0126
Epoch  51 Batch  100/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9613, Loss: 0.0133
Epoch  51 Batch  120/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9769, Loss: 0.0133
Epoch  51 Batch  140/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9737, Loss: 0.0106
Epoch  51 Batch  160/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9670, Loss: 0.0131
Epoch  51 Batch  180/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9545, Loss: 0.0108
Epoch  51 Batch  200/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9790, Loss: 0.0120
Epoch  51 Batch  220/1077 - Train Accuracy: 0.9741, Validation Accuracy: 0.9744, Loss: 0.0156
Epoch  51 Batch  240/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9688, Loss: 0.0079
Epoch  51 Batch  260/1077 - Train Accuracy: 0.9572, Validation Accuracy: 0.9645, Loss: 0.0130
Epoch  51 Batch  280/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9659, Loss: 0.0173
Epoch  51 Batch  300/1077 - Train Accuracy: 0.9786, Validation Accuracy: 0.9719, Loss: 0.0122
Epoch  51 Batch  320/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9638, Loss: 0.0158
Epoch  51 Batch  340/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9624, Loss: 0.0146
Epoch  51 Batch  360/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9513, Loss: 0.0084
Epoch  51 Batch  380/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9688, Loss: 0.0094
Epoch  51 Batch  400/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9616, Loss: 0.0135
Epoch  51 Batch  420/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9499, Loss: 0.0083
Epoch  51 Batch  440/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9606, Loss: 0.0143
Epoch  51 Batch  460/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9535, Loss: 0.0120
Epoch  51 Batch  480/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9595, Loss: 0.0116
Epoch  51 Batch  500/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9581, Loss: 0.0096
Epoch  51 Batch  520/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9570, Loss: 0.0072
Epoch  51 Batch  540/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9616, Loss: 0.0116
Epoch  51 Batch  560/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9624, Loss: 0.0119
Epoch  51 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9641, Loss: 0.0095
Epoch  51 Batch  600/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9482, Loss: 0.0182
Epoch  51 Batch  620/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9727, Loss: 0.0141
Epoch  51 Batch  640/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9620, Loss: 0.0110
Epoch  51 Batch  660/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9592, Loss: 0.0100
Epoch  51 Batch  680/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9478, Loss: 0.0205
Epoch  51 Batch  700/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9503, Loss: 0.0114
Epoch  51 Batch  720/1077 - Train Accuracy: 0.9593, Validation Accuracy: 0.9542, Loss: 0.0164
Epoch  51 Batch  740/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9631, Loss: 0.0109
Epoch  51 Batch  760/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9645, Loss: 0.0131
Epoch  51 Batch  780/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9627, Loss: 0.0182
Epoch  51 Batch  800/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9631, Loss: 0.0126
Epoch  51 Batch  820/1077 - Train Accuracy: 0.9988, Validation Accuracy: 0.9723, Loss: 0.0091
Epoch  51 Batch  840/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9577, Loss: 0.0197
Epoch  51 Batch  860/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9620, Loss: 0.0129
Epoch  51 Batch  880/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9716, Loss: 0.0140
Epoch  51 Batch  900/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9659, Loss: 0.0173
Epoch  51 Batch  920/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9645, Loss: 0.0137
Epoch  51 Batch  940/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9663, Loss: 0.0117
Epoch  51 Batch  960/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9634, Loss: 0.0117
Epoch  51 Batch  980/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9577, Loss: 0.0135
Epoch  51 Batch 1000/1077 - Train Accuracy: 0.9714, Validation Accuracy: 0.9599, Loss: 0.0166
Epoch  51 Batch 1020/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9616, Loss: 0.0080
Epoch  51 Batch 1040/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9556, Loss: 0.0116
Epoch  51 Batch 1060/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9549, Loss: 0.0121
Epoch  52 Batch   20/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9709, Loss: 0.0097
Epoch  52 Batch   40/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9737, Loss: 0.0110
Epoch  52 Batch   60/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9570, Loss: 0.0118
Epoch  52 Batch   80/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9602, Loss: 0.0132
Epoch  52 Batch  100/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9613, Loss: 0.0136
Epoch  52 Batch  120/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9719, Loss: 0.0135
Epoch  52 Batch  140/1077 - Train Accuracy: 0.9757, Validation Accuracy: 0.9762, Loss: 0.0106
Epoch  52 Batch  160/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9744, Loss: 0.0121
Epoch  52 Batch  180/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9531, Loss: 0.0099
Epoch  52 Batch  200/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9787, Loss: 0.0108
Epoch  52 Batch  220/1077 - Train Accuracy: 0.9794, Validation Accuracy: 0.9769, Loss: 0.0162
Epoch  52 Batch  240/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9627, Loss: 0.0084
Epoch  52 Batch  260/1077 - Train Accuracy: 0.9632, Validation Accuracy: 0.9634, Loss: 0.0107
Epoch  52 Batch  280/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9695, Loss: 0.0177
Epoch  52 Batch  300/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9719, Loss: 0.0126
Epoch  52 Batch  320/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9570, Loss: 0.0158
Epoch  52 Batch  340/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9631, Loss: 0.0133
Epoch  52 Batch  360/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9521, Loss: 0.0081
Epoch  52 Batch  380/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9641, Loss: 0.0080
Epoch  52 Batch  400/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9613, Loss: 0.0126
Epoch  52 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9425, Loss: 0.0081
Epoch  52 Batch  440/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9666, Loss: 0.0141
Epoch  52 Batch  460/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9489, Loss: 0.0122
Epoch  52 Batch  480/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9531, Loss: 0.0110
Epoch  52 Batch  500/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9588, Loss: 0.0088
Epoch  52 Batch  520/1077 - Train Accuracy: 0.9963, Validation Accuracy: 0.9620, Loss: 0.0069
Epoch  52 Batch  540/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9627, Loss: 0.0107
Epoch  52 Batch  560/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9606, Loss: 0.0113
Epoch  52 Batch  580/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9634, Loss: 0.0096
Epoch  52 Batch  600/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9652, Loss: 0.0170
Epoch  52 Batch  620/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9627, Loss: 0.0136
Epoch  52 Batch  640/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9616, Loss: 0.0105
Epoch  52 Batch  660/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9577, Loss: 0.0104
Epoch  52 Batch  680/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9574, Loss: 0.0193
Epoch  52 Batch  700/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9599, Loss: 0.0114
Epoch  52 Batch  720/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9624, Loss: 0.0175
Epoch  52 Batch  740/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9737, Loss: 0.0111
Epoch  52 Batch  760/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9663, Loss: 0.0136
Epoch  52 Batch  780/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9691, Loss: 0.0172
Epoch  52 Batch  800/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9606, Loss: 0.0115
Epoch  52 Batch  820/1077 - Train Accuracy: 0.9969, Validation Accuracy: 0.9631, Loss: 0.0094
Epoch  52 Batch  840/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9581, Loss: 0.0157
Epoch  52 Batch  860/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9585, Loss: 0.0130
Epoch  52 Batch  880/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9723, Loss: 0.0129
Epoch  52 Batch  900/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9638, Loss: 0.0141
Epoch  52 Batch  920/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9677, Loss: 0.0132
Epoch  52 Batch  940/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9734, Loss: 0.0107
Epoch  52 Batch  960/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9656, Loss: 0.0112
Epoch  52 Batch  980/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9641, Loss: 0.0127
Epoch  52 Batch 1000/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9648, Loss: 0.0147
Epoch  52 Batch 1020/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9673, Loss: 0.0076
Epoch  52 Batch 1040/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9574, Loss: 0.0138
Epoch  52 Batch 1060/1077 - Train Accuracy: 0.9984, Validation Accuracy: 0.9599, Loss: 0.0092
Epoch  53 Batch   20/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9695, Loss: 0.0077
Epoch  53 Batch   40/1077 - Train Accuracy: 0.9965, Validation Accuracy: 0.9688, Loss: 0.0098
Epoch  53 Batch   60/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9663, Loss: 0.0118
Epoch  53 Batch   80/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9648, Loss: 0.0125
Epoch  53 Batch  100/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9620, Loss: 0.0128
Epoch  53 Batch  120/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9798, Loss: 0.0158
Epoch  53 Batch  140/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9659, Loss: 0.0100
Epoch  53 Batch  160/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9688, Loss: 0.0134
Epoch  53 Batch  180/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9517, Loss: 0.0105
Epoch  53 Batch  200/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9766, Loss: 0.0104
Epoch  53 Batch  220/1077 - Train Accuracy: 0.9741, Validation Accuracy: 0.9680, Loss: 0.0151
Epoch  53 Batch  240/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9616, Loss: 0.0075
Epoch  53 Batch  260/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9624, Loss: 0.0111
Epoch  53 Batch  280/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9663, Loss: 0.0167
Epoch  53 Batch  300/1077 - Train Accuracy: 0.9745, Validation Accuracy: 0.9719, Loss: 0.0107
Epoch  53 Batch  320/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9631, Loss: 0.0153
Epoch  53 Batch  340/1077 - Train Accuracy: 0.9893, Validation Accuracy: 0.9670, Loss: 0.0139
Epoch  53 Batch  360/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9574, Loss: 0.0079
Epoch  53 Batch  380/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9634, Loss: 0.0082
Epoch  53 Batch  400/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9666, Loss: 0.0123
Epoch  53 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9474, Loss: 0.0081
Epoch  53 Batch  440/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9698, Loss: 0.0146
Epoch  53 Batch  460/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9549, Loss: 0.0118
Epoch  53 Batch  480/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9553, Loss: 0.0131
Epoch  53 Batch  500/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9599, Loss: 0.0094
Epoch  53 Batch  520/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9599, Loss: 0.0071
Epoch  53 Batch  540/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9673, Loss: 0.0111
Epoch  53 Batch  560/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9670, Loss: 0.0115
Epoch  53 Batch  580/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9698, Loss: 0.0094
Epoch  53 Batch  600/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9677, Loss: 0.0187
Epoch  53 Batch  620/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9723, Loss: 0.0133
Epoch  53 Batch  640/1077 - Train Accuracy: 0.9702, Validation Accuracy: 0.9620, Loss: 0.0134
Epoch  53 Batch  660/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9592, Loss: 0.0111
Epoch  53 Batch  680/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9521, Loss: 0.0180
Epoch  53 Batch  700/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9560, Loss: 0.0108
Epoch  53 Batch  720/1077 - Train Accuracy: 0.9601, Validation Accuracy: 0.9670, Loss: 0.0166
Epoch  53 Batch  740/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9776, Loss: 0.0117
Epoch  53 Batch  760/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9677, Loss: 0.0116
Epoch  53 Batch  780/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9727, Loss: 0.0186
Epoch  53 Batch  800/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9645, Loss: 0.0118
Epoch  53 Batch  820/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9574, Loss: 0.0087
Epoch  53 Batch  840/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9567, Loss: 0.0165
Epoch  53 Batch  860/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9673, Loss: 0.0138
Epoch  53 Batch  880/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9751, Loss: 0.0119
Epoch  53 Batch  900/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9688, Loss: 0.0152
Epoch  53 Batch  920/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9734, Loss: 0.0116
Epoch  53 Batch  940/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9766, Loss: 0.0109
Epoch  53 Batch  960/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9698, Loss: 0.0119
Epoch  53 Batch  980/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9645, Loss: 0.0127
Epoch  53 Batch 1000/1077 - Train Accuracy: 0.9669, Validation Accuracy: 0.9705, Loss: 0.0123
Epoch  53 Batch 1020/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9666, Loss: 0.0078
Epoch  53 Batch 1040/1077 - Train Accuracy: 0.9741, Validation Accuracy: 0.9627, Loss: 0.0117
Epoch  53 Batch 1060/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9581, Loss: 0.0108
Epoch  54 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9744, Loss: 0.0082
Epoch  54 Batch   40/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9741, Loss: 0.0106
Epoch  54 Batch   60/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9595, Loss: 0.0113
Epoch  54 Batch   80/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9581, Loss: 0.0118
Epoch  54 Batch  100/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9663, Loss: 0.0148
Epoch  54 Batch  120/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9769, Loss: 0.0118
Epoch  54 Batch  140/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9634, Loss: 0.0098
Epoch  54 Batch  160/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9691, Loss: 0.0121
Epoch  54 Batch  180/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9478, Loss: 0.0105
Epoch  54 Batch  200/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9826, Loss: 0.0100
Epoch  54 Batch  220/1077 - Train Accuracy: 0.9749, Validation Accuracy: 0.9695, Loss: 0.0149
Epoch  54 Batch  240/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9656, Loss: 0.0083
Epoch  54 Batch  260/1077 - Train Accuracy: 0.9628, Validation Accuracy: 0.9652, Loss: 0.0119
Epoch  54 Batch  280/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9702, Loss: 0.0174
Epoch  54 Batch  300/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9670, Loss: 0.0112
Epoch  54 Batch  320/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9631, Loss: 0.0149
Epoch  54 Batch  340/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9620, Loss: 0.0129
Epoch  54 Batch  360/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9553, Loss: 0.0077
Epoch  54 Batch  380/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9737, Loss: 0.0076
Epoch  54 Batch  400/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9677, Loss: 0.0133
Epoch  54 Batch  420/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9595, Loss: 0.0081
Epoch  54 Batch  440/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9627, Loss: 0.0139
Epoch  54 Batch  460/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9474, Loss: 0.0119
Epoch  54 Batch  480/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9581, Loss: 0.0098
Epoch  54 Batch  500/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9634, Loss: 0.0092
Epoch  54 Batch  520/1077 - Train Accuracy: 0.9937, Validation Accuracy: 0.9563, Loss: 0.0074
Epoch  54 Batch  540/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9666, Loss: 0.0106
Epoch  54 Batch  560/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9648, Loss: 0.0110
Epoch  54 Batch  580/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9702, Loss: 0.0086
Epoch  54 Batch  600/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9663, Loss: 0.0156
Epoch  54 Batch  620/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9748, Loss: 0.0123
Epoch  54 Batch  640/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9616, Loss: 0.0100
Epoch  54 Batch  660/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9581, Loss: 0.0120
Epoch  54 Batch  680/1077 - Train Accuracy: 0.9632, Validation Accuracy: 0.9467, Loss: 0.0194
Epoch  54 Batch  700/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9553, Loss: 0.0118
Epoch  54 Batch  720/1077 - Train Accuracy: 0.9589, Validation Accuracy: 0.9542, Loss: 0.0152
Epoch  54 Batch  740/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9599, Loss: 0.0121
Epoch  54 Batch  760/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9702, Loss: 0.0164
Epoch  54 Batch  780/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9570, Loss: 0.0232
Epoch  54 Batch  800/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9705, Loss: 0.0130
Epoch  54 Batch  820/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9616, Loss: 0.0108
Epoch  54 Batch  840/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9613, Loss: 0.0175
Epoch  54 Batch  860/1077 - Train Accuracy: 0.9743, Validation Accuracy: 0.9702, Loss: 0.0163
Epoch  54 Batch  880/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9712, Loss: 0.0129
Epoch  54 Batch  900/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9592, Loss: 0.0161
Epoch  54 Batch  920/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9627, Loss: 0.0119
Epoch  54 Batch  940/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9716, Loss: 0.0130
Epoch  54 Batch  960/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9670, Loss: 0.0111
Epoch  54 Batch  980/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9673, Loss: 0.0126
Epoch  54 Batch 1000/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9663, Loss: 0.0123
Epoch  54 Batch 1020/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9677, Loss: 0.0082
Epoch  54 Batch 1040/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9620, Loss: 0.0121
Epoch  54 Batch 1060/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9634, Loss: 0.0107
Epoch  55 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9716, Loss: 0.0094
Epoch  55 Batch   40/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9695, Loss: 0.0091
Epoch  55 Batch   60/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9570, Loss: 0.0115
Epoch  55 Batch   80/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9602, Loss: 0.0111
Epoch  55 Batch  100/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9684, Loss: 0.0145
Epoch  55 Batch  120/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9723, Loss: 0.0138
Epoch  55 Batch  140/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9705, Loss: 0.0103
Epoch  55 Batch  160/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9776, Loss: 0.0118
Epoch  55 Batch  180/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9577, Loss: 0.0102
Epoch  55 Batch  200/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9773, Loss: 0.0087
Epoch  55 Batch  220/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9666, Loss: 0.0135
Epoch  55 Batch  240/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9592, Loss: 0.0079
Epoch  55 Batch  260/1077 - Train Accuracy: 0.9628, Validation Accuracy: 0.9592, Loss: 0.0102
Epoch  55 Batch  280/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9631, Loss: 0.0162
Epoch  55 Batch  300/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9719, Loss: 0.0114
Epoch  55 Batch  320/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9602, Loss: 0.0157
Epoch  55 Batch  340/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9631, Loss: 0.0132
Epoch  55 Batch  360/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9549, Loss: 0.0072
Epoch  55 Batch  380/1077 - Train Accuracy: 0.9949, Validation Accuracy: 0.9638, Loss: 0.0085
Epoch  55 Batch  400/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9670, Loss: 0.0122
Epoch  55 Batch  420/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9595, Loss: 0.0078
Epoch  55 Batch  440/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9577, Loss: 0.0137
Epoch  55 Batch  460/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9577, Loss: 0.0106
Epoch  55 Batch  480/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9585, Loss: 0.0107
Epoch  55 Batch  500/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9503, Loss: 0.0093
Epoch  55 Batch  520/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9634, Loss: 0.0064
Epoch  55 Batch  540/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9634, Loss: 0.0098
Epoch  55 Batch  560/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9691, Loss: 0.0126
Epoch  55 Batch  580/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9673, Loss: 0.0102
Epoch  55 Batch  600/1077 - Train Accuracy: 0.9870, Validation Accuracy: 0.9688, Loss: 0.0171
Epoch  55 Batch  620/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9727, Loss: 0.0145
Epoch  55 Batch  640/1077 - Train Accuracy: 0.9747, Validation Accuracy: 0.9744, Loss: 0.0109
Epoch  55 Batch  660/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9638, Loss: 0.0089
Epoch  55 Batch  680/1077 - Train Accuracy: 0.9628, Validation Accuracy: 0.9567, Loss: 0.0182
Epoch  55 Batch  700/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9602, Loss: 0.0124
Epoch  55 Batch  720/1077 - Train Accuracy: 0.9638, Validation Accuracy: 0.9549, Loss: 0.0140
Epoch  55 Batch  740/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9730, Loss: 0.0098
Epoch  55 Batch  760/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9670, Loss: 0.0120
Epoch  55 Batch  780/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9652, Loss: 0.0160
Epoch  55 Batch  800/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9716, Loss: 0.0110
Epoch  55 Batch  820/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9581, Loss: 0.0096
Epoch  55 Batch  840/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9656, Loss: 0.0168
Epoch  55 Batch  860/1077 - Train Accuracy: 0.9747, Validation Accuracy: 0.9627, Loss: 0.0159
Epoch  55 Batch  880/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9656, Loss: 0.0123
Epoch  55 Batch  900/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9560, Loss: 0.0137
Epoch  55 Batch  920/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9595, Loss: 0.0126
Epoch  55 Batch  940/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9712, Loss: 0.0119
Epoch  55 Batch  960/1077 - Train Accuracy: 0.9728, Validation Accuracy: 0.9652, Loss: 0.0105
Epoch  55 Batch  980/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9652, Loss: 0.0122
Epoch  55 Batch 1000/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9670, Loss: 0.0149
Epoch  55 Batch 1020/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9741, Loss: 0.0093
Epoch  55 Batch 1040/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9609, Loss: 0.0120
Epoch  55 Batch 1060/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9482, Loss: 0.0109
Epoch  56 Batch   20/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9698, Loss: 0.0078
Epoch  56 Batch   40/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9741, Loss: 0.0094
Epoch  56 Batch   60/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9691, Loss: 0.0110
Epoch  56 Batch   80/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9698, Loss: 0.0109
Epoch  56 Batch  100/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9677, Loss: 0.0122
Epoch  56 Batch  120/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9798, Loss: 0.0115
Epoch  56 Batch  140/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9627, Loss: 0.0105
Epoch  56 Batch  160/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9719, Loss: 0.0111
Epoch  56 Batch  180/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9482, Loss: 0.0096
Epoch  56 Batch  200/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9748, Loss: 0.0087
Epoch  56 Batch  220/1077 - Train Accuracy: 0.9794, Validation Accuracy: 0.9698, Loss: 0.0165
Epoch  56 Batch  240/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9528, Loss: 0.0073
Epoch  56 Batch  260/1077 - Train Accuracy: 0.9568, Validation Accuracy: 0.9510, Loss: 0.0108
Epoch  56 Batch  280/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9656, Loss: 0.0172
Epoch  56 Batch  300/1077 - Train Accuracy: 0.9774, Validation Accuracy: 0.9670, Loss: 0.0115
Epoch  56 Batch  320/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9528, Loss: 0.0148
Epoch  56 Batch  340/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9627, Loss: 0.0116
Epoch  56 Batch  360/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9563, Loss: 0.0073
Epoch  56 Batch  380/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9737, Loss: 0.0071
Epoch  56 Batch  400/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9638, Loss: 0.0107
Epoch  56 Batch  420/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9531, Loss: 0.0077
Epoch  56 Batch  440/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9670, Loss: 0.0138
Epoch  56 Batch  460/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9606, Loss: 0.0109
Epoch  56 Batch  480/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9531, Loss: 0.0103
Epoch  56 Batch  500/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9542, Loss: 0.0088
Epoch  56 Batch  520/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9606, Loss: 0.0066
Epoch  56 Batch  540/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9613, Loss: 0.0095
Epoch  56 Batch  560/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9684, Loss: 0.0097
Epoch  56 Batch  580/1077 - Train Accuracy: 0.9795, Validation Accuracy: 0.9695, Loss: 0.0106
Epoch  56 Batch  600/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9638, Loss: 0.0155
Epoch  56 Batch  620/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9719, Loss: 0.0125
Epoch  56 Batch  640/1077 - Train Accuracy: 0.9725, Validation Accuracy: 0.9673, Loss: 0.0110
Epoch  56 Batch  660/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9457, Loss: 0.0099
Epoch  56 Batch  680/1077 - Train Accuracy: 0.9628, Validation Accuracy: 0.9524, Loss: 0.0170
Epoch  56 Batch  700/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9535, Loss: 0.0105
Epoch  56 Batch  720/1077 - Train Accuracy: 0.9597, Validation Accuracy: 0.9599, Loss: 0.0132
Epoch  56 Batch  740/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9648, Loss: 0.0113
Epoch  56 Batch  760/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9712, Loss: 0.0118
Epoch  56 Batch  780/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9663, Loss: 0.0174
Epoch  56 Batch  800/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9712, Loss: 0.0108
Epoch  56 Batch  820/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9645, Loss: 0.0086
Epoch  56 Batch  840/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9588, Loss: 0.0148
Epoch  56 Batch  860/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9602, Loss: 0.0126
Epoch  56 Batch  880/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9705, Loss: 0.0113
Epoch  56 Batch  900/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9663, Loss: 0.0152
Epoch  56 Batch  920/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9684, Loss: 0.0121
Epoch  56 Batch  940/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9641, Loss: 0.0096
Epoch  56 Batch  960/1077 - Train Accuracy: 0.9747, Validation Accuracy: 0.9698, Loss: 0.0104
Epoch  56 Batch  980/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9645, Loss: 0.0117
Epoch  56 Batch 1000/1077 - Train Accuracy: 0.9714, Validation Accuracy: 0.9616, Loss: 0.0121
Epoch  56 Batch 1020/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9712, Loss: 0.0071
Epoch  56 Batch 1040/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9592, Loss: 0.0118
Epoch  56 Batch 1060/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9680, Loss: 0.0120
Epoch  57 Batch   20/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9712, Loss: 0.0075
Epoch  57 Batch   40/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9688, Loss: 0.0093
Epoch  57 Batch   60/1077 - Train Accuracy: 0.9821, Validation Accuracy: 0.9641, Loss: 0.0105
Epoch  57 Batch   80/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9592, Loss: 0.0104
Epoch  57 Batch  100/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9734, Loss: 0.0125
Epoch  57 Batch  120/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9794, Loss: 0.0097
Epoch  57 Batch  140/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9609, Loss: 0.0126
Epoch  57 Batch  160/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9719, Loss: 0.0115
Epoch  57 Batch  180/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9521, Loss: 0.0094
Epoch  57 Batch  200/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9666, Loss: 0.0095
Epoch  57 Batch  220/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9688, Loss: 0.0146
Epoch  57 Batch  240/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9531, Loss: 0.0080
Epoch  57 Batch  260/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9599, Loss: 0.0092
Epoch  57 Batch  280/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9673, Loss: 0.0180
Epoch  57 Batch  300/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9766, Loss: 0.0123
Epoch  57 Batch  320/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9577, Loss: 0.0148
Epoch  57 Batch  340/1077 - Train Accuracy: 0.9864, Validation Accuracy: 0.9677, Loss: 0.0118
Epoch  57 Batch  360/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9624, Loss: 0.0065
Epoch  57 Batch  380/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9673, Loss: 0.0072
Epoch  57 Batch  400/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9670, Loss: 0.0112
Epoch  57 Batch  420/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9652, Loss: 0.0083
Epoch  57 Batch  440/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9719, Loss: 0.0132
Epoch  57 Batch  460/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9513, Loss: 0.0117
Epoch  57 Batch  480/1077 - Train Accuracy: 0.9905, Validation Accuracy: 0.9524, Loss: 0.0094
Epoch  57 Batch  500/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9595, Loss: 0.0094
Epoch  57 Batch  520/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9620, Loss: 0.0060
Epoch  57 Batch  540/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9616, Loss: 0.0095
Epoch  57 Batch  560/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9652, Loss: 0.0096
Epoch  57 Batch  580/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9670, Loss: 0.0096
Epoch  57 Batch  600/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9702, Loss: 0.0147
Epoch  57 Batch  620/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9723, Loss: 0.0131
Epoch  57 Batch  640/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9645, Loss: 0.0101
Epoch  57 Batch  660/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9719, Loss: 0.0076
Epoch  57 Batch  680/1077 - Train Accuracy: 0.9628, Validation Accuracy: 0.9567, Loss: 0.0168
Epoch  57 Batch  700/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9531, Loss: 0.0121
Epoch  57 Batch  720/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9624, Loss: 0.0140
Epoch  57 Batch  740/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9705, Loss: 0.0098
Epoch  57 Batch  760/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9691, Loss: 0.0112
Epoch  57 Batch  780/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9684, Loss: 0.0158
Epoch  57 Batch  800/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9691, Loss: 0.0105
Epoch  57 Batch  820/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9574, Loss: 0.0116
Epoch  57 Batch  840/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9659, Loss: 0.0165
Epoch  57 Batch  860/1077 - Train Accuracy: 0.9829, Validation Accuracy: 0.9581, Loss: 0.0230
Epoch  57 Batch  880/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9631, Loss: 0.0118
Epoch  57 Batch  900/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9712, Loss: 0.0176
Epoch  57 Batch  920/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9641, Loss: 0.0113
Epoch  57 Batch  940/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9748, Loss: 0.0110
Epoch  57 Batch  960/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9648, Loss: 0.0100
Epoch  57 Batch  980/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9670, Loss: 0.0134
Epoch  57 Batch 1000/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9602, Loss: 0.0105
Epoch  57 Batch 1020/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9762, Loss: 0.0073
Epoch  57 Batch 1040/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9624, Loss: 0.0116
Epoch  57 Batch 1060/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9482, Loss: 0.0092
Epoch  58 Batch   20/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9719, Loss: 0.0064
Epoch  58 Batch   40/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9645, Loss: 0.0085
Epoch  58 Batch   60/1077 - Train Accuracy: 0.9710, Validation Accuracy: 0.9659, Loss: 0.0097
Epoch  58 Batch   80/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9599, Loss: 0.0116
Epoch  58 Batch  100/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9680, Loss: 0.0105
Epoch  58 Batch  120/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9773, Loss: 0.0098
Epoch  58 Batch  140/1077 - Train Accuracy: 0.9827, Validation Accuracy: 0.9553, Loss: 0.0095
Epoch  58 Batch  160/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9702, Loss: 0.0110
Epoch  58 Batch  180/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9545, Loss: 0.0101
Epoch  58 Batch  200/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9748, Loss: 0.0094
Epoch  58 Batch  220/1077 - Train Accuracy: 0.9794, Validation Accuracy: 0.9680, Loss: 0.0142
Epoch  58 Batch  240/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9624, Loss: 0.0072
Epoch  58 Batch  260/1077 - Train Accuracy: 0.9658, Validation Accuracy: 0.9556, Loss: 0.0088
Epoch  58 Batch  280/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9673, Loss: 0.0156
Epoch  58 Batch  300/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9719, Loss: 0.0105
Epoch  58 Batch  320/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9531, Loss: 0.0133
Epoch  58 Batch  340/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9645, Loss: 0.0117
Epoch  58 Batch  360/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9602, Loss: 0.0069
Epoch  58 Batch  380/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9652, Loss: 0.0070
Epoch  58 Batch  400/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9652, Loss: 0.0122
Epoch  58 Batch  420/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9585, Loss: 0.0075
Epoch  58 Batch  440/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9677, Loss: 0.0141
Epoch  58 Batch  460/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9588, Loss: 0.0099
Epoch  58 Batch  480/1077 - Train Accuracy: 0.9774, Validation Accuracy: 0.9574, Loss: 0.0103
Epoch  58 Batch  500/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9549, Loss: 0.0099
Epoch  58 Batch  520/1077 - Train Accuracy: 0.9948, Validation Accuracy: 0.9634, Loss: 0.0062
Epoch  58 Batch  540/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9620, Loss: 0.0085
Epoch  58 Batch  560/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9652, Loss: 0.0101
Epoch  58 Batch  580/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9627, Loss: 0.0090
Epoch  58 Batch  600/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9705, Loss: 0.0135
Epoch  58 Batch  620/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9776, Loss: 0.0117
Epoch  58 Batch  640/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9645, Loss: 0.0112
Epoch  58 Batch  660/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9670, Loss: 0.0102
Epoch  58 Batch  680/1077 - Train Accuracy: 0.9714, Validation Accuracy: 0.9435, Loss: 0.0155
Epoch  58 Batch  700/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9691, Loss: 0.0099
Epoch  58 Batch  720/1077 - Train Accuracy: 0.9597, Validation Accuracy: 0.9666, Loss: 0.0172
Epoch  58 Batch  740/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9688, Loss: 0.0107
Epoch  58 Batch  760/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9673, Loss: 0.0118
Epoch  58 Batch  780/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9609, Loss: 0.0141
Epoch  58 Batch  800/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9673, Loss: 0.0098
Epoch  58 Batch  820/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9581, Loss: 0.0073
Epoch  58 Batch  840/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9599, Loss: 0.0137
Epoch  58 Batch  860/1077 - Train Accuracy: 0.9747, Validation Accuracy: 0.9652, Loss: 0.0127
Epoch  58 Batch  880/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9602, Loss: 0.0106
Epoch  58 Batch  900/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9702, Loss: 0.0114
Epoch  58 Batch  920/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9727, Loss: 0.0127
Epoch  58 Batch  940/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9684, Loss: 0.0089
Epoch  58 Batch  960/1077 - Train Accuracy: 0.9728, Validation Accuracy: 0.9695, Loss: 0.0095
Epoch  58 Batch  980/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9673, Loss: 0.0119
Epoch  58 Batch 1000/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9609, Loss: 0.0115
Epoch  58 Batch 1020/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9755, Loss: 0.0068
Epoch  58 Batch 1040/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9631, Loss: 0.0104
Epoch  58 Batch 1060/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9535, Loss: 0.0106
Epoch  59 Batch   20/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9712, Loss: 0.0089
Epoch  59 Batch   40/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9670, Loss: 0.0096
Epoch  59 Batch   60/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9688, Loss: 0.0109
Epoch  59 Batch   80/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9606, Loss: 0.0106
Epoch  59 Batch  100/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9581, Loss: 0.0116
Epoch  59 Batch  120/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9798, Loss: 0.0097
Epoch  59 Batch  140/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9638, Loss: 0.0100
Epoch  59 Batch  160/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9723, Loss: 0.0100
Epoch  59 Batch  180/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9577, Loss: 0.0091
Epoch  59 Batch  200/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9734, Loss: 0.0080
Epoch  59 Batch  220/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9759, Loss: 0.0145
Epoch  59 Batch  240/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9599, Loss: 0.0070
Epoch  59 Batch  260/1077 - Train Accuracy: 0.9661, Validation Accuracy: 0.9592, Loss: 0.0088
Epoch  59 Batch  280/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9663, Loss: 0.0162
Epoch  59 Batch  300/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9719, Loss: 0.0102
Epoch  59 Batch  320/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9446, Loss: 0.0131
Epoch  59 Batch  340/1077 - Train Accuracy: 0.9881, Validation Accuracy: 0.9695, Loss: 0.0117
Epoch  59 Batch  360/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9531, Loss: 0.0067
Epoch  59 Batch  380/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9741, Loss: 0.0089
Epoch  59 Batch  400/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9670, Loss: 0.0125
Epoch  59 Batch  420/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9599, Loss: 0.0083
Epoch  59 Batch  440/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9670, Loss: 0.0133
Epoch  59 Batch  460/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9560, Loss: 0.0104
Epoch  59 Batch  480/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9528, Loss: 0.0093
Epoch  59 Batch  500/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9620, Loss: 0.0086
Epoch  59 Batch  520/1077 - Train Accuracy: 0.9940, Validation Accuracy: 0.9634, Loss: 0.0064
Epoch  59 Batch  540/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9656, Loss: 0.0085
Epoch  59 Batch  560/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9659, Loss: 0.0088
Epoch  59 Batch  580/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9624, Loss: 0.0089
Epoch  59 Batch  600/1077 - Train Accuracy: 0.9810, Validation Accuracy: 0.9652, Loss: 0.0139
Epoch  59 Batch  620/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9751, Loss: 0.0114
Epoch  59 Batch  640/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9698, Loss: 0.0098
Epoch  59 Batch  660/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9677, Loss: 0.0096
Epoch  59 Batch  680/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9595, Loss: 0.0166
Epoch  59 Batch  700/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9652, Loss: 0.0102
Epoch  59 Batch  720/1077 - Train Accuracy: 0.9782, Validation Accuracy: 0.9549, Loss: 0.0130
Epoch  59 Batch  740/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9673, Loss: 0.0107
Epoch  59 Batch  760/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9634, Loss: 0.0115
Epoch  59 Batch  780/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9688, Loss: 0.0147
Epoch  59 Batch  800/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9744, Loss: 0.0105
Epoch  59 Batch  820/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9677, Loss: 0.0083
Epoch  59 Batch  840/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9645, Loss: 0.0143
Epoch  59 Batch  860/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9624, Loss: 0.0129
Epoch  59 Batch  880/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9751, Loss: 0.0099
Epoch  59 Batch  900/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9634, Loss: 0.0129
Epoch  59 Batch  920/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9670, Loss: 0.0112
Epoch  59 Batch  940/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9698, Loss: 0.0100
Epoch  59 Batch  960/1077 - Train Accuracy: 0.9717, Validation Accuracy: 0.9624, Loss: 0.0091
Epoch  59 Batch  980/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9645, Loss: 0.0114
Epoch  59 Batch 1000/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9691, Loss: 0.0114
Epoch  59 Batch 1020/1077 - Train Accuracy: 0.9895, Validation Accuracy: 0.9744, Loss: 0.0077
Epoch  59 Batch 1040/1077 - Train Accuracy: 0.9696, Validation Accuracy: 0.9673, Loss: 0.0097
Epoch  59 Batch 1060/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9482, Loss: 0.0097
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h3><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="#Sentence-to-Sequence">&#182;</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="sd">&#39;&#39;&#39;Prepare the text for the model&#39;&#39;&#39;</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">7</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">vocab_to_int</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;UNK&gt;&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="#Translate">&#182;</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;predictions:0&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;target_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;source_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">target_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">source_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/dev
Input
  Word Ids:      [34, 69, 116, 113, 199, 108, 190]
  English Words: [&#39;he&#39;, &#39;saw&#39;, &#39;a&#39;, &#39;old&#39;, &#39;yellow&#39;, &#39;truck&#39;, &#39;.&#39;]

Prediction
  Word Ids:      [219, 232, 152, 350, 142, 160, 87, 331, 1]
  French Words: il a vu une voiture  l&#39;cole ? &lt;EOS&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="#Imperfect-Translation">&#182;</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
